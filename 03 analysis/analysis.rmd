---
title: "analysis"
author: "Jens Joschinski"
date: "April 5, 2018"
output:     
  md_document:
        variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RCurl)
library(readr)
library(data.table)
library(textreadr)
library(tidyr)
library(dplyr)
library(stringr)
library(magrittr)
library(geomapdata)
library(geosphere)
library(MASS)
library(lme4)
library(nlme)
library(metafor)
```

# issues  
slopes.csv has typo in orius sauteri; and one order and spec missing
tetranychidiae should be thromobiformes
heteroptera->hemiptera  

# General description  
## Aim  
The aim of this project is to correlate climate variability with variability in seasonal timing. Is the slope in seasonal responses a bet-hedging trait, i.e., is it adaptive to spread one's timing in more variable conditions?  


### Overview  

Previous scripts calculated winter variability and winter predictability based on climate station data (30k stations), and various parameters of photoperiodic response curves from published studies (350 populations, 61 studies). This script analyses these datasets.


### Specific description  

The data was generated with R version `r getRversion()`. It requires the datasets "01climate_data/03output/results.txt" and "02studies/02output/slopes.txt", and the locations.txt file from the NOAA server.

# Script  

## General stuff  
### Load the datasets  
```{r loadstuff}
url<-"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
#this dataset is fixed-width delimited, requiring a few additional steps
locations<-read.fwf(
  file=url
  ,sep="!",na.strings=c("NA","-999.9"), #sep = ! because ! does not exist in dataset - > dataset is fixed-width and should have no additional separators
  widths=c(11, 9, 10, 7,2,35)
)
reslist<-read.table("01climate_data/03output/results.txt",na.string = c("NA","-9999","-999.9"))
names(reslist)<-c("ID","meanwinter","sd_winter","nyears","p","A","phi","c","beta")
climate<-merge(locations,reslist,by=1)
rm(locations)
rm(reslist)
names(climate)<-c("ID","lat","lon","alt","no_idea","name","meanwinter","sd_winter", "nyears","p","A","phi","c","beta")

slopes<-read.table("02studies/02output/slopes.txt")
names(slopes)<-c("ID","b","b_se","c","c_se","d","d_se","e","e_se","ID2","study","pop","spec","order","degN","degE","py")
#quick-fixing typos
slopes$spec[slopes$spec=="Orius Sauteri"]<-"Orius sauteri"
slopes$spec[69]<-slopes$spec[68]
slopes$spec[70]<-slopes$spec[68]
slopes$order[69]<-slopes$order[68]
slopes$order[70]<-slopes$order[68]

slopes$order[slopes$order=="Tetranychidae"] <- "Trombidiformes"
slopes$order[slopes$order=="heteroptera"] <- "hemiptera"


climate<-climate[!is.na(climate$meanwinter),] #because these cannot be used anyway
climate$alt[climate$alt == -999.9]<-NA #was somehow not converted to NA during read.table
slopes<-separate(slopes,spec,c("g","s"),sep =" ",remove=FALSE)
slopes<-droplevels(slopes)
slopes$col<-as.numeric(slopes$order)#could find more beautiful way
slopes<-slopes[order(slopes$order,slopes$g,slopes$s,decreasing=T),]
slopes$real_se<-1/slopes$e_se #drc script inversed that, needs to be undone here.
slopes$b<-abs(slopes$b)

#174 data points, 28 studies, 26 species and 20 genera, 9 orders
#3 species are repeated in different studies, 
#one of the studies has three species
#each species is from diff genus except for diptera and tetranychus

 n<-table(slopes$order)#this table shows how many lines per order there are.
```

### functions
slighlity modified functions of forest.rma and forest.default (metafor). Forest.default now returns x-values and cex as well; everything is the same as the original version. Forest.rma now does not whiskers itself but lets user input whiskers size. The other two functions are hidden functions of the same package, which are required for the main function to run.

```{r metafor}

myfor<-function (x, annotate = TRUE, addfit = TRUE, addcred = FALSE, 
          showweights = FALSE, xlim, alim, clim, ylim, at, steps = 5, 
          level = x$level, refline = 0, digits = 2L, width, xlab, slab, 
          mlab, ilab, ilab.xpos, ilab.pos, order, transf, atransf, 
          targs, rows, efac = 1, pch = 15, psize, col, border, lty, 
          cex, cex.lab, cex.axis, annosym, ci.ub,ci.lb,...)
{
  if (!inherits(x, "rma")) 
    stop("Argument 'x' must be an object of class \"rma\".")
  if (inherits(x, "rma.ls")) 
    stop("Method not yet implemented for objects of class \"rma.ls\". Sorry!")
  na.act <- getOption("na.action")
  if (!is.element(na.act, c("na.omit", "na.exclude", "na.fail", 
                            "na.pass"))) 
    stop("Unknown 'na.action' specified under options().")
  if (missing(transf)) 
    transf <- FALSE
  if (missing(atransf)) 
    atransf <- FALSE
  transf.char <- deparse(substitute(transf))
  atransf.char <- deparse(substitute(atransf))
  if (is.function(transf) && is.function(atransf)) 
    stop("Use either 'transf' or 'atransf' to specify a transformation (not both).")
  if (missing(targs)) 
    targs <- NULL
  if (missing(at)) 
    at <- NULL
  if (missing(ilab)) 
    ilab <- NULL
  if (missing(ilab.xpos)) 
    ilab.xpos <- NULL
  if (missing(ilab.pos)) 
    ilab.pos <- NULL
  if (missing(order)) 
    order <- NULL
  if (missing(psize)) 
    psize <- NULL
  if (missing(cex)) 
    cex <- NULL
  if (missing(cex.lab)) 
    cex.lab <- NULL
  if (missing(cex.axis)) 
    cex.axis <- NULL
  if (x$int.only) {
    if (missing(col)) {
      col <- c("black", "gray50")
    }
    else {
      if (length(col) == 1L) 
        col <- c(col, "gray50")
    }
    if (missing(border)) 
      border <- "black"
  }
  else {
    if (missing(col)) 
      col <- "gray"
    if (missing(border)) 
      border <- "gray"
  }
  if (missing(lty)) {
    lty <- c("solid", "dotted", "solid")
  }
  else {
    if (length(lty) == 1L) 
      lty <- c(lty, "dotted", "solid")
    if (length(lty) == 2L) 
      lty <- c(lty, "solid")
  }
  if (length(efac) == 1L) 
    efac <- rep(efac, 3)
  if (length(efac) == 2L) 
    efac <- c(efac[1], efac[1], efac[2])
  if (missing(annosym)) 
    annosym <- c(" [", ", ", "]")
  if (length(annosym) != 3) 
    stop("Argument 'annosym' must be a vector of length 3.")
  measure <- x$measure
  if (inherits(x, "rma.glmm") && showweights) 
    stop("Option 'showweights=TRUE' currently not possible for 'rma.glmm' objects. Sorry!")
  if (length(digits) == 1L) 
    digits <- c(digits, digits)
  level <- ifelse(level > 1, (100 - level)/100, ifelse(level > 
                                                         0.5, 1 - level, level))
  yi <- x$yi.f
  vi <- x$vi.f
  X <- x$X.f
  k <- length(yi)
  if (missing(slab)) {
    if (x$slab.null) {
      slab <- paste("Study", x$slab)
    }
    else {
      slab <- x$slab
    }
  }
  else {
    if (length(slab) == 1 && is.na(slab)) 
      slab <- rep("", k)
  }
  if (length(yi) != length(slab)) 
    stop("Number of outcomes does not correspond to the length of the 'slab' argument.")
  if (is.null(dim(ilab))) 
    ilab <- cbind(ilab)
  if (length(pch) == 1L) 
    pch <- rep(pch, k)
  if (length(pch) != length(yi)) 
    stop("Number of outcomes does not correspond to the length of the 'pch' argument.")
  options(na.action = "na.pass")
  if (x$int.only) {
    pred <- fitted(x)
    pred.ci.lb <- rep(NA_real_, k)
    pred.ci.ub <- rep(NA_real_, k)
  }
  else {
    temp <- predict(x, level = level)
    pred <- temp$pred
    if (addcred) {
      pred.ci.lb <- temp$cr.lb
      pred.ci.ub <- temp$cr.ub
    }
    else {
      pred.ci.lb <- temp$ci.lb
      pred.ci.ub <- temp$ci.ub
    }
  }
  if (inherits(x, "rma.glmm")) {
    weights <- NULL
  }
  else {
    weights <- weights(x)
  }
  options(na.action = na.act)
  if (!is.null(psize)) {
    if (length(psize) == 1L) 
      psize <- rep(psize, k)
    if (length(psize) != length(yi)) 
      stop("Number of outcomes does not correspond to the length of the 'psize' argument.")
  }
  if (!is.null(order)) {
    if (is.character(order)) {
      if (length(order) != 1) 
        stop("Incorrect length of 'order' argument.")
      if (order == "obs") 
        sort.vec <- order(yi)
      if (order == "fit") 
        sort.vec <- order(pred)
      if (order == "prec") 
        sort.vec <- order(vi, yi)
      if (order == "resid") 
        sort.vec <- order(yi - pred, yi)
      if (order == "rstandard") 
        sort.vec <- order(rstandard(x)$z, yi)
      if (order == "abs.resid") 
        sort.vec <- order(abs(yi - pred), yi)
      if (order == "abs.rstandard") 
        sort.vec <- order(abs(rstandard(x)$z), yi)
    }
    else {
      sort.vec <- order
    }
    yi <- yi[sort.vec]
    vi <- vi[sort.vec]
    X <- X[sort.vec, , drop = FALSE]
    slab <- slab[sort.vec]
    ilab <- ilab[sort.vec, , drop = FALSE]
    pred <- pred[sort.vec]
    pred.ci.lb <- pred.ci.lb[sort.vec]
    pred.ci.ub <- pred.ci.ub[sort.vec]
    weights <- weights[sort.vec]
    pch <- pch[sort.vec]
    psize <- psize[sort.vec]
  }
  k <- length(yi)
  if (missing(rows)) {
    rows <- k:1
  }
  else {
    if (length(rows) == 1L) {
      rows <- rows:(rows - k + 1)
    }
  }
  if (length(rows) != length(yi)) 
    stop("Number of outcomes does not correspond to the length of the 'rows' argument.")
  yi <- yi[k:1]
  vi <- vi[k:1]
  X <- X[k:1, , drop = FALSE]
  slab <- slab[k:1]
  ilab <- ilab[k:1, , drop = FALSE]
  pred <- pred[k:1]
  pred.ci.lb <- pred.ci.lb[k:1]
  pred.ci.ub <- pred.ci.ub[k:1]
  weights <- weights[k:1]
  pch <- pch[k:1]
  psize <- psize[k:1]
  rows <- rows[k:1]
  yiviX.na <- is.na(yi) | is.na(vi) | apply(is.na(X), 1, any)
  if (any(yiviX.na)) {
    not.na <- !yiviX.na
    if (na.act == "na.omit") {
      yi <- yi[not.na]
      vi <- vi[not.na]
      X <- X[not.na, , drop = FALSE]
      slab <- slab[not.na]
      ilab <- ilab[not.na, , drop = FALSE]
      pred <- pred[not.na]
      pred.ci.lb <- pred.ci.lb[not.na]
      pred.ci.ub <- pred.ci.ub[not.na]
      weights <- weights[not.na]
      pch <- pch[not.na]
      psize <- psize[not.na]
      rows.new <- rows
      rows.na <- rows[!not.na]
      for (j in seq_len(length(rows.na))) {
        rows.new[rows >= rows.na[j]] <- rows.new[rows >= 
                                                   rows.na[j]] - 1
      }
      rows <- rows.new[not.na]
    }
    if (na.act == "na.fail") 
      stop("Missing values in results.")
  }
  k <- length(yi)
 # ci.lb <- yi - qnorm(level/2, lower.tail = FALSE) * sqrt(vi)
 # ci.ub <- yi + qnorm(level/2, lower.tail = FALSE) * sqrt(vi)
  if (is.function(transf)) {
    if (is.null(targs)) {
      yi <- sapply(yi, transf)
      ci.lb <- sapply(ci.lb, transf)
      ci.ub <- sapply(ci.ub, transf)
      pred <- sapply(pred, transf)
      pred.ci.lb <- sapply(pred.ci.lb, transf)
      pred.ci.ub <- sapply(pred.ci.ub, transf)
    }
    else {
      yi <- sapply(yi, transf, targs)
      ci.lb <- sapply(ci.lb, transf, targs)
      ci.ub <- sapply(ci.ub, transf, targs)
      pred <- sapply(pred, transf, targs)
      pred.ci.lb <- sapply(pred.ci.lb, transf, targs)
      pred.ci.ub <- sapply(pred.ci.ub, transf, targs)
    }
  }
  tmp <- .psort(ci.lb, ci.ub)
  ci.lb <- tmp[, 1]
  ci.ub <- tmp[, 2]
  tmp <- .psort(pred.ci.lb, pred.ci.ub)
  pred.ci.lb <- tmp[, 1]
  pred.ci.ub <- tmp[, 2]
  if (!missing(clim)) {
    clim <- sort(clim)
    if (length(clim) != 2L) 
      stop("Argument 'clim' must be of length 2.")
    ci.lb[ci.lb < clim[1]] <- clim[1]
    ci.ub[ci.ub > clim[2]] <- clim[2]
    pred.ci.lb[pred.ci.lb < clim[1]] <- clim[1]
    pred.ci.ub[pred.ci.ub > clim[2]] <- clim[2]
  }
  if (is.null(psize)) {
    if (is.null(weights)) {
      if (any(vi <= 0, na.rm = TRUE)) {
        psize <- rep(1, k)
      }
      else {
        wi <- 1/sqrt(vi)
        psize <- wi/sum(wi, na.rm = TRUE)
        psize <- (psize - min(psize, na.rm = TRUE))/(max(psize, 
                                                         na.rm = TRUE) - min(psize, na.rm = TRUE))
        psize <- (psize * 1) + 0.5
        if (all(is.na(psize))) 
          psize <- rep(1, k)
      }
    }
    else {
      wi <- weights
      psize <- wi/sum(wi, na.rm = TRUE)
      psize <- (psize - min(psize, na.rm = TRUE))/(max(psize, 
                                                       na.rm = TRUE) - min(psize, na.rm = TRUE))
      psize <- (psize * 1) + 0.5
      if (all(is.na(psize))) 
        psize <- rep(1, k)
    }
  }
  rng <- max(ci.ub, na.rm = TRUE) - min(ci.lb, na.rm = TRUE)
  if (annotate) {
    if (showweights) {
      plot.multp.l <- 2
      plot.multp.r <- 2
    }
    else {
      plot.multp.l <- 1.2
      plot.multp.r <- 1.2
    }
  }
  else {
    plot.multp.l <- 1.2
    plot.multp.r <- 0.4
  }
  if (missing(xlim)) {
    xlim <- c(min(ci.lb, na.rm = TRUE) - rng * plot.multp.l, 
              max(ci.ub, na.rm = TRUE) + rng * plot.multp.r)
    xlim <- round(xlim, digits[2])
  }
  alim.spec <- TRUE
  if (missing(alim)) {
    if (is.null(at)) {
      alim <- range(pretty(x = c(min(ci.lb, na.rm = TRUE), 
                                 max(ci.ub, na.rm = TRUE)), n = steps - 1))
      alim.spec <- FALSE
    }
    else {
      alim <- range(at)
    }
  }
  alim <- sort(alim)
  xlim <- sort(xlim)
  if (xlim[1] > min(yi, na.rm = TRUE)) {
    xlim[1] <- min(yi, na.rm = TRUE)
  }
  if (xlim[2] < max(yi, na.rm = TRUE)) {
    xlim[2] <- max(yi, na.rm = TRUE)
  }
  if (alim[1] < xlim[1]) {
    xlim[1] <- alim[1]
  }
  if (alim[2] > xlim[2]) {
    xlim[2] <- alim[2]
  }
  if (missing(ylim)) {
    if (x$int.only && addfit) {
      ylim <- c(-1.5, k + 3)
    }
    else {
      ylim <- c(0.5, k + 3)
    }
  }
  else {
    ylim <- sort(ylim)
  }
  if (is.null(at)) {
    if (alim.spec) {
      at <- seq(from = alim[1], to = alim[2], length.out = steps)
    }
    else {
      at <- pretty(x = c(min(ci.lb, na.rm = TRUE), max(ci.ub, 
                                                       na.rm = TRUE)), n = steps - 1)
    }
  }
  else {
    at[at < alim[1]] <- alim[1]
    at[at > alim[2]] <- alim[2]
    at <- unique(at)
  }
  at.lab <- at
  if (is.function(atransf)) {
    if (is.null(targs)) {
      at.lab <- formatC(sapply(at.lab, atransf), digits = digits[2], 
                        format = "f", drop0trailing = ifelse(class(digits) == 
                                                               "integer", TRUE, FALSE))
    }
    else {
      at.lab <- formatC(sapply(at.lab, atransf, targs), 
                        digits = digits[2], format = "f", drop0trailing = ifelse(class(digits) == 
                                                                                   "integer", TRUE, FALSE))
    }
  }
  else {
    at.lab <- formatC(at.lab, digits = digits[2], format = "f", 
                      drop0trailing = ifelse(class(digits) == "integer", 
                                             TRUE, FALSE))
  }
  par.mar <- par("mar")
  par.mar.adj <- par.mar - c(0, 3, 1, 1)
  par.mar.adj[par.mar.adj < 0] <- 0
  par(mar = par.mar.adj)
  on.exit(par(mar = par.mar))
  plot(NA, NA, xlim = xlim, ylim = ylim, xlab = "", ylab = "", 
       yaxt = "n", xaxt = "n", xaxs = "i", bty = "n", ...)
  abline(h = ylim[2] - 2, lty = lty[3], ...)
  if (is.numeric(refline)) 
    segments(refline, ylim[1] - 5, refline, ylim[2] - 2, 
             lty = "dotted", ...)
  par.usr <- par("usr")
  height <- par.usr[4] - par.usr[3]
  if (is.null(cex)) {
    lheight <- strheight("O")
    cex.adj <- ifelse(k * lheight > height * 0.8, height/(1.25 * 
                                                            k * lheight), 1)
  }
  if (is.null(cex)) {
    cex <- par("cex") * cex.adj
  }
  else {
    if (is.null(cex.lab)) 
      cex.lab <- cex
    if (is.null(cex.axis)) 
      cex.axis <- cex
  }
  if (is.null(cex.lab)) 
    cex.lab <- par("cex") * cex.adj
  if (is.null(cex.axis)) 
    cex.axis <- par("cex") * cex.adj
  if (addfit && !x$int.only) {
    for (i in seq_len(k)) {
      if (is.na(pred[i])) 
        next
      polygon(x = c(max(pred.ci.lb[i], alim[1]), pred[i], 
                    min(pred.ci.ub[i], alim[2]), pred[i]), y = c(rows[i], 
                                                                 rows[i] + (height/100) * cex * efac[3], rows[i], 
                                                                 rows[i] - (height/100) * cex * efac[3]), col = col, 
              border = border, ...)
    }
  }
  if (addfit && x$int.only) {
    if (inherits(x, "rma.mv") && x$withG && x$tau2s > 1) {
      if (!is.logical(addcred)) {
        if (length(addcred) == 1) 
          addcred <- c(addcred, addcred)
        temp <- predict(x, level = level, tau2.levels = addcred[1], 
                        gamma2.levels = addcred[2])
        addcred <- TRUE
      }
      else {
        if (addcred) {
          stop("Need to specify the level of the inner factor(s) via the 'addcred' argument.")
        }
        else {
          temp <- predict(x, level = level, tau2.levels = 1, 
                          gamma2.levels = 1)
        }
      }
    }
    else {
      temp <- predict(x, level = level)
    }
    beta <- temp$pred
    beta.ci.lb <- temp$ci.lb
    beta.ci.ub <- temp$ci.ub
    beta.cr.lb <- temp$cr.lb
    beta.cr.ub <- temp$cr.ub
    if (is.function(transf)) {
      if (is.null(targs)) {
        beta <- sapply(beta, transf)
        beta.ci.lb <- sapply(beta.ci.lb, transf)
        beta.ci.ub <- sapply(beta.ci.ub, transf)
        beta.cr.lb <- sapply(beta.cr.lb, transf)
        beta.cr.ub <- sapply(beta.cr.ub, transf)
      }
      else {
        beta <- sapply(beta, transf, targs)
        beta.ci.lb <- sapply(beta.ci.lb, transf, targs)
        beta.ci.ub <- sapply(beta.ci.ub, transf, targs)
        beta.cr.lb <- sapply(beta.cr.lb, transf, targs)
        beta.cr.ub <- sapply(beta.cr.ub, transf, targs)
      }
    }
    tmp <- .psort(beta.ci.lb, beta.ci.ub)
    beta.ci.lb <- tmp[, 1]
    beta.ci.ub <- tmp[, 2]
    tmp <- .psort(beta.cr.lb, beta.cr.ub)
    beta.cr.lb <- tmp[, 1]
    beta.cr.ub <- tmp[, 2]
    if (!missing(clim)) {
      beta.ci.lb[beta.ci.lb < clim[1]] <- clim[1]
      beta.ci.ub[beta.ci.ub > clim[2]] <- clim[2]
      beta.cr.lb[beta.cr.lb < clim[1]] <- clim[1]
      beta.cr.ub[beta.cr.ub > clim[2]] <- clim[2]
    }
    if (x$method != "FE" && addcred) {
      segments(max(beta.cr.lb, alim[1]), -1, min(beta.cr.ub, 
                                                 alim[2]), -1, lty = lty[2], col = col[2], ...)
      if (beta.cr.lb >= alim[1]) {
        segments(beta.cr.lb, -1 - (height/150) * cex * 
                   efac[1], beta.cr.lb, -1 + (height/150) * cex * 
                   efac[1], col = col[2], ...)
      }
      else {
        polygon(x = c(alim[1], alim[1] + (1.4/100) * 
                        cex * (xlim[2] - xlim[1]), alim[1] + (1.4/100) * 
                        cex * (xlim[2] - xlim[1]), alim[1]), y = c(-1, 
                                                                   -1 + (height/150) * cex * efac[2], -1 - (height/150) * 
                                                                     cex * efac[2], -1), col = col[2], border = col[2], 
                ...)
      }
      if (beta.cr.ub <= alim[2]) {
        segments(beta.cr.ub, -1 - (height/150) * cex * 
                   efac[1], beta.cr.ub, -1 + (height/150) * cex * 
                   efac[1], col = col[2], ...)
      }
      else {
        polygon(x = c(alim[2], alim[2] - (1.4/100) * 
                        cex * (xlim[2] - xlim[1]), alim[2] - (1.4/100) * 
                        cex * (xlim[2] - xlim[1]), alim[2]), y = c(-1, 
                                                                   -1 + (height/150) * cex * efac[2], -1 - (height/150) * 
                                                                     cex * efac[2], -1), col = col[2], border = col[2], 
                ...)
      }
    }
    polygon(x = c(beta.ci.lb, beta, beta.ci.ub, beta), y = c(-1, 
                                                             -1 + (height/100) * cex * efac[3], -1, -1 - (height/100) * 
                                                               cex * efac[3]), col = col[1], border = border, 
            ...)
    if (missing(mlab)) 
      mlab <- ifelse((x$method == "FE"), "FE Model", "RE Model")
    text(xlim[1], -1, mlab, pos = 4, cex = cex, ...)
  }
  axis(side = 1, at = at, labels = at.lab, cex.axis = cex.axis, 
       ...)
  if (missing(xlab)) 
    xlab <- .setlab(measure, transf.char, atransf.char, gentype = 1)
  mtext(xlab, side = 1, at = min(at) + (max(at) - min(at))/2, 
        line = par("mgp")[1] - 0.5, cex = cex.lab, ...)
  for (i in seq_len(k)) {
    if (is.na(yi[i]) || is.na(vi[i])) 
      next
    if (ci.lb[i] >= alim[2]) {
      polygon(x = c(alim[2], alim[2] - (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[2] - (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[2]), y = c(rows[i], 
                                                           rows[i] + (height/150) * cex * efac[2], rows[i] - 
                                                             (height/150) * cex * efac[2], rows[i]), col = "black", 
              ...)
      next
    }
    if (ci.ub[i] <= alim[1]) {
      polygon(x = c(alim[1], alim[1] + (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[1] + (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[1]), y = c(rows[i], 
                                                           rows[i] + (height/150) * cex * efac[2], rows[i] - 
                                                             (height/150) * cex * efac[2], rows[i]), col = "black", 
              ...)
      next
    }
    segments(max(ci.lb[i], alim[1]), rows[i], min(ci.ub[i], 
                                                  alim[2]), rows[i], lty = lty[1], ...)
    if (ci.lb[i] >= alim[1]) {
      segments(ci.lb[i], rows[i] - (height/150) * cex * 
                 efac[1], ci.lb[i], rows[i] + (height/150) * cex * 
                 efac[1], ...)
    }
    else {
      polygon(x = c(alim[1], alim[1] + (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[1] + (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[1]), y = c(rows[i], 
                                                           rows[i] + (height/150) * cex * efac[2], rows[i] - 
                                                             (height/150) * cex * efac[2], rows[i]), col = "black", 
              ...)
    }
    if (ci.ub[i] <= alim[2]) {
      segments(ci.ub[i], rows[i] - (height/150) * cex * 
                 efac[1], ci.ub[i], rows[i] + (height/150) * cex * 
                 efac[1], ...)
    }
    else {
      polygon(x = c(alim[2], alim[2] - (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[2] - (1.4/100) * cex * 
                      (xlim[2] - xlim[1]), alim[2]), y = c(rows[i], 
                                                           rows[i] + (height/150) * cex * efac[2], rows[i] - 
                                                             (height/150) * cex * efac[2], rows[i]), col = "black", 
              ...)
    }
  }
  text(xlim[1], rows, slab, pos = 4, cex = cex, ...)
  if (!is.null(ilab)) {
    if (is.null(ilab.xpos)) 
      stop("Must specify 'ilab.xpos' argument when adding information with 'ilab'.")
    if (length(ilab.xpos) != ncol(ilab)) 
      stop(paste0("Number of 'ilab' columns (", ncol(ilab), 
                  ") does not match length of 'ilab.xpos' argument (", 
                  length(ilab.xpos), ")."))
    if (!is.null(ilab.pos) && length(ilab.pos) == 1) 
      ilab.pos <- rep(ilab.pos, ncol(ilab))
    for (l in seq_len(ncol(ilab))) {
      text(ilab.xpos[l], rows, ilab[, l], pos = ilab.pos[l], 
           cex = cex, ...)
    }
  }
  if (annotate) {
    if (is.function(atransf)) {
      if (is.null(targs)) {
        if (addfit && x$int.only) {
          annotext <- cbind(sapply(c(yi, beta), atransf), 
                            sapply(c(ci.lb, beta.ci.lb), atransf), sapply(c(ci.ub, 
                                                                            beta.ci.ub), atransf))
        }
        else {
          annotext <- cbind(sapply(yi, atransf), sapply(ci.lb, 
                                                        atransf), sapply(ci.ub, atransf))
        }
      }
      else {
        if (addfit && x$int.only) {
          annotext <- cbind(sapply(c(yi, beta), atransf, 
                                   targs), sapply(c(ci.lb, beta.ci.lb), atransf, 
                                                  targs), sapply(c(ci.ub, beta.ci.ub), atransf, 
                                                                 targs))
        }
        else {
          annotext <- cbind(sapply(yi, atransf, targs), 
                            sapply(ci.lb, atransf, targs), sapply(ci.ub, 
                                                                  atransf, targs))
        }
      }
      tmp <- .psort(annotext[, 2:3])
      annotext[, 2:3] <- tmp
    }
    else {
      if (addfit && x$int.only) {
        annotext <- cbind(c(yi, beta), c(ci.lb, beta.ci.lb), 
                          c(ci.ub, beta.ci.ub))
      }
      else {
        annotext <- cbind(yi, ci.lb, ci.ub)
      }
    }
    if (showweights) {
      if (addfit && x$int.only) {
        annotext <- cbind(c(weights, 100), annotext)
      }
      else {
        annotext <- cbind(weights, annotext)
      }
    }
    annotext <- formatC(annotext, format = "f", digits = digits[1])
    if (missing(width)) {
      width <- apply(annotext, 2, function(x) max(nchar(x)))
    }
    else {
      if (length(width) == 1L) 
        width <- rep(width, ncol(annotext))
    }
    for (j in seq_len(ncol(annotext))) {
      annotext[, j] <- formatC(annotext[, j], width = width[j])
    }
    if (showweights) {
      annotext <- cbind(annotext[, 1], "%   ", annotext[, 
                                                        2], annosym[1], annotext[, 3], annosym[2], annotext[, 
                                                                                                            4], annosym[3])
    }
    else {
      annotext <- cbind(annotext[, 1], annosym[1], annotext[, 
                                                            2], annosym[2], annotext[, 3], annosym[3])
    }
    annotext <- apply(annotext, 1, paste, collapse = "")
    if (addfit && x$int.only) {
      text(x = xlim[2], c(rows, -1), labels = annotext, 
           pos = 2, cex = cex, ...)
    }
    else {
      text(x = xlim[2], rows, labels = annotext, pos = 2, 
           cex = cex, ...)
    }
  }
  for (i in seq_len(k)) {
    if (is.na(yi[i])) 
      next
    if (yi[i] >= alim[1] && yi[i] <= alim[2]) 
      points(yi[i], rows[i], pch = pch[i], cex = cex * 
               psize[i], ...)
  }
  if (x$int.only && addfit) 
    abline(h = 0, lty = lty[3], ...)
  res <- list(xlim = par("usr")[1:2], alim = alim, at = at, 
              ylim = ylim, rows = rows, cex = cex, cex.lab = cex.lab, 
              cex.axis = cex.axis,yi)
  invisible(res)
}

.psort <- function(x,y) {
  
  ### t(apply(xy, 1, sort)) would be okay, but problematic if there are NAs;
  ### either they are removed completely (na.last=NA) or they are always put
  ### first/last (na.last=FALSE/TRUE); but we just want to leave the NAs in
  ### their position!
  
  if (is.null(x) || length(x) == 0) ### need to catch this
    return(NULL)
  
  if (missing(y)) {
    if (is.matrix(x)) {
      xy <- x
    } else {
      xy <- rbind(x) ### in case x is just a vector
    }
  } else {
    xy <- cbind(x,y)
  }
  
  n <- nrow(xy)
  
  for (i in seq_len(n)) {
    if (anyNA(xy[i,]))
      next
    xy[i,] <- sort(xy[i,])
  }
  
  colnames(xy) <- NULL
  
  return(xy)
  
}


.setlab <- function(measure, transf.char, atransf.char, gentype) {
  if (gentype == 1)
    lab <- "Observed Outcome"
  if (gentype == 2)
    lab <- "Overall Estimate" ### need this for forest.cumul.rma() function
  
  
  #
  
  if (!is.null(measure)) {
    
  
    if (is.element(measure, c("RR","MPRR"))) {
      if (transf.char == "FALSE" && atransf.char == "FALSE") {
        lab <- "Log Risk Ratio"
      } else {
        lab <- "Transformed Log Risk Ratio"
        if (atransf.char == "exp" || atransf.char == "transf.exp.int")
          lab <- "Risk Ratio (log scale)"
        if (transf.char == "exp" || transf.char == "transf.exp.int")
          lab <- "Risk Ratio"
      }
    }
    if (is.element(measure, c("OR","PETO","D2OR","D2ORN","D2ORL","MPOR","MPORC","MPPETO"))) {
      if (transf.char == "FALSE" && atransf.char == "FALSE") {
        lab <- "Log Odds Ratio"
      } else {
        lab <- "Transformed Log Odds Ratio"
        if (atransf.char == "exp" || atransf.char == "transf.exp.int")
          lab <- "Odds Ratio (log scale)"
        if (transf.char == "exp" || transf.char == "transf.exp.int")
          lab <- "Odds Ratio"
      }
    }
    if (is.element(measure, c("RD","MPRD"))) {
      if (transf.char == "FALSE" && atransf.char == "FALSE") {
        lab <- "Risk Difference"
      } else {
        lab <- "Transformed Risk Difference"
      }
    }
    if (measure == "AS") {
      if (transf.char == "FALSE" && atransf.char == "FALSE") {
        lab <- "Arcsine Transformed Risk Difference"
      } else {
        lab <- "Transformed Arcsine Transformed Risk Difference"
      }
    }
    if (measure == "PHI") {
      if (transf.char == "FALSE" && atransf.char == "FALSE") {
        lab <- "Phi Coefficient"
      } else {
        lab <- "Transformed Phi Coefficient"
      }
    }
    if (measure == "YUQ") {
      if (transf.char == "FALSE" && atransf.char == "FALSE") {
        lab <- "Yule's Q"
      } else {
        lab <- "Transformed Yule's Q"
      }
    }
    if (measure == "YUY") {
      if (transf.char == "FALSE" && atransf.char == "FALSE") {
        lab <- "Yule's Y"
      } else {
        lab <- "Transformed Yule's Y"
      }
    }
  }
} 
#####

mydeffor<-function (x, vi, sei, ci.lb, ci.ub, annotate = TRUE, showweights = FALSE, 
    xlim, alim, clim, ylim, at, steps = 5, level = 95, refline = 0, 
    digits = 2L, width, xlab, slab, ilab, ilab.xpos, ilab.pos, 
    subset, transf, atransf, targs, rows, efac = 1, pch = 15, 
    psize, col, lty, cex, cex.lab, cex.axis, annosym, ...) 
{
    na.act <- getOption("na.action")
    if (!is.element(na.act, c("na.omit", "na.exclude", "na.fail", 
        "na.pass"))) 
        stop("Unknown 'na.action' specified under options().")
    if (missing(transf)) 
        transf <- FALSE
    if (missing(atransf)) 
        atransf <- FALSE
    transf.char <- deparse(substitute(transf))
    atransf.char <- deparse(substitute(atransf))
    if (is.function(transf) && is.function(atransf)) 
        stop("Use either 'transf' or 'atransf' to specify a transformation (not both).")
    if (missing(targs)) 
        targs <- NULL
    if (missing(at)) 
        at <- NULL
    if (missing(ilab)) 
        ilab <- NULL
    if (missing(ilab.xpos)) 
        ilab.xpos <- NULL
    if (missing(ilab.pos)) 
        ilab.pos <- NULL
    if (missing(subset)) 
        subset <- NULL
    if (missing(psize)) 
        psize <- NULL
    if (missing(col)) 
        col <- NULL
    if (missing(cex)) 
        cex <- NULL
    if (missing(cex.lab)) 
        cex.lab <- NULL
    if (missing(cex.axis)) 
        cex.axis <- NULL
    if (missing(lty)) {
        lty <- c("solid", "solid")
    }
    else {
        if (length(lty) == 1L) 
            lty <- c(lty, "solid")
    }
    if (length(efac) == 1L) 
        efac <- rep(efac, 2)
    if (missing(annosym)) 
        annosym <- c(" [", ", ", "]")
    if (length(annosym) != 3) 
        stop("Argument 'annosym' must be a vector of length 3.")
    if (length(digits) == 1L) 
        digits <- c(digits, digits)
    level <- ifelse(level > 1, (100 - level)/100, ifelse(level > 
        0.5, 1 - level, level))
    yi <- x
    if (is.null(attr(yi, "measure"))) {
        measure <- "GEN"
    }
    else {
        measure <- attr(yi, "measure")
    }
    if (hasArg(ci.lb) && hasArg(ci.ub)) {
        if (length(ci.lb) != length(ci.ub)) 
            stop("Length of 'ci.lb' and 'ci.ub' do not match.")
        if (missing(vi) && missing(sei)) {
            vi <- ((ci.ub - ci.lb)/(2 * qnorm(level/2, lower.tail = FALSE)))^2
        }
        else {
            if (missing(vi)) 
                vi <- sei^2
        }
        if (length(ci.lb) != length(vi)) 
            stop("Length of 'vi' (or 'sei') does not match length of ('ci.lb', 'ci.ub') pairs.")
    }
    else {
        if (missing(vi)) {
            if (missing(sei)) {
                stop("Must specify either 'vi', 'sei', or ('ci.lb', 'ci.ub') pairs.")
            }
            else {
                vi <- sei^2
                ci.lb <- yi - qnorm(level/2, lower.tail = FALSE) * 
                  sei
                ci.ub <- yi + qnorm(level/2, lower.tail = FALSE) * 
                  sei
            }
        }
        else {
            ci.lb <- yi - qnorm(level/2, lower.tail = FALSE) * 
                sqrt(vi)
            ci.ub <- yi + qnorm(level/2, lower.tail = FALSE) * 
                sqrt(vi)
        }
    }
    if (length(yi) != length(vi)) 
        stop("Length of 'yi' does not match the length of 'vi', 'sei', or the ('ci.lb', 'ci.ub') pairs.")
    k <- length(yi)
    if (missing(slab)) {
        if (!is.null(attr(yi, "slab"))) {
            slab <- attr(yi, "slab")
        }
        else {
            slab <- paste("Study", seq_len(k))
        }
    }
    else {
        if (length(slab) == 1 && is.na(slab)) 
            slab <- rep("", k)
    }
    if (length(yi) != length(slab)) 
        stop("Number of outcomes does not correspond to the length of the 'slab' argument.")
    if (is.null(dim(ilab))) 
        ilab <- cbind(ilab)
    if (length(pch) == 1L) 
        pch <- rep(pch, k)
    if (length(pch) != length(yi)) 
        stop("Number of outcomes does not correspond to the length of the 'pch' argument.")
    if (!is.null(psize)) {
        if (length(psize) == 1L) 
            psize <- rep(psize, k)
        if (length(psize) != length(yi)) 
            stop("Number of outcomes does not correspond to the length of the 'psize' argument.")
    }
    if (!is.null(col)) {
        if (length(col) == 1L) 
            col <- rep(col, k)
        if (length(col) != length(yi)) 
            stop("Number of outcomes does not correspond to the length of the 'col' argument.")
    }
    else {
        col <- rep("black", k)
    }
    if (!is.null(subset)) {
        yi <- yi[subset]
        vi <- vi[subset]
        ci.lb <- ci.lb[subset]
        ci.ub <- ci.ub[subset]
        slab <- slab[subset]
        ilab <- ilab[subset, , drop = FALSE]
        pch <- pch[subset]
        psize <- psize[subset]
        col <- col[subset]
    }
    k <- length(yi)
    if (missing(rows)) {
        rows <- k:1
    }
    else {
        if (length(rows) == 1L) 
            rows <- rows:(rows - k + 1)
    }
    if (length(rows) != length(yi)) 
        stop("Number of outcomes does not correspond to the length of the 'rows' argument.")
    yi <- yi[k:1]
    vi <- vi[k:1]
    ci.lb <- ci.lb[k:1]
    ci.ub <- ci.ub[k:1]
    slab <- slab[k:1]
    ilab <- ilab[k:1, , drop = FALSE]
    pch <- pch[k:1]
    psize <- psize[k:1]
    col <- col[k:1]
    rows <- rows[k:1]
    yivi.na <- is.na(yi) | is.na(vi)
    if (any(yivi.na)) {
        not.na <- !yivi.na
        if (na.act == "na.omit") {
            yi <- yi[not.na]
            vi <- vi[not.na]
            ci.lb <- ci.lb[not.na]
            ci.ub <- ci.ub[not.na]
            slab <- slab[not.na]
            ilab <- ilab[not.na, , drop = FALSE]
            pch <- pch[not.na]
            psize <- psize[not.na]
            col <- col[not.na]
            rows.new <- rows
            rows.na <- rows[!not.na]
            for (j in seq_len(length(rows.na))) {
                rows.new[rows >= rows.na[j]] <- rows.new[rows >= 
                  rows.na[j]] - 1
            }
            rows <- rows.new[not.na]
        }
        if (na.act == "na.fail") 
            stop("Missing values in results.")
    }
    k <- length(yi)
    if (is.function(transf)) {
        if (is.null(targs)) {
            yi <- sapply(yi, transf)
            ci.lb <- sapply(ci.lb, transf)
            ci.ub <- sapply(ci.ub, transf)
        }
        else {
            yi <- sapply(yi, transf, targs)
            ci.lb <- sapply(ci.lb, transf, targs)
            ci.ub <- sapply(ci.ub, transf, targs)
        }
    }
    tmp <- .psort(ci.lb, ci.ub)
    ci.lb <- tmp[, 1]
    ci.ub <- tmp[, 2]
    if (!missing(clim)) {
        clim <- sort(clim)
        if (length(clim) != 2L) 
            stop("Argument 'clim' must be of length 2.")
        ci.lb[ci.lb < clim[1]] <- clim[1]
        ci.ub[ci.ub > clim[2]] <- clim[2]
    }
    if (showweights) {
        weights <- 1/vi
        weights <- 100 * weights/sum(weights, na.rm = TRUE)
    }
    if (is.null(psize)) {
        if (any(vi <= 0, na.rm = TRUE)) {
            psize <- rep(1, k)
        }
        else {
            wi <- 1/sqrt(vi)
            psize <- wi/sum(wi, na.rm = TRUE)
            psize <- (psize - min(psize, na.rm = TRUE))/(max(psize, 
                na.rm = TRUE) - min(psize, na.rm = TRUE))
            psize <- (psize * 1) + 0.5
            if (all(is.na(psize))) 
                psize <- rep(1, k)
        }
    }
    rng <- max(ci.ub, na.rm = TRUE) - min(ci.lb, na.rm = TRUE)
    if (annotate) {
        if (showweights) {
            plot.multp.l <- 2
            plot.multp.r <- 2
        }
        else {
            plot.multp.l <- 1.2
            plot.multp.r <- 1.2
        }
    }
    else {
        plot.multp.l <- 1.2
        plot.multp.r <- 0.4
    }
    if (missing(xlim)) {
        xlim <- c(min(ci.lb, na.rm = TRUE) - rng * plot.multp.l, 
            max(ci.ub, na.rm = TRUE) + rng * plot.multp.r)
        xlim <- round(xlim, digits[2])
    }
    alim.spec <- TRUE
    if (missing(alim)) {
        if (is.null(at)) {
            alim <- range(pretty(x = c(min(ci.lb, na.rm = TRUE), 
                max(ci.ub, na.rm = TRUE)), n = steps - 1))
            alim.spec <- FALSE
        }
        else {
            alim <- range(at)
        }
    }
    alim <- sort(alim)
    xlim <- sort(xlim)
    if (xlim[1] > min(yi, na.rm = TRUE)) {
        xlim[1] <- min(yi, na.rm = TRUE)
    }
    if (xlim[2] < max(yi, na.rm = TRUE)) {
        xlim[2] <- max(yi, na.rm = TRUE)
    }
    if (alim[1] < xlim[1]) {
        xlim[1] <- alim[1]
    }
    if (alim[2] > xlim[2]) {
        xlim[2] <- alim[2]
    }
    if (missing(ylim)) {
        ylim <- c(0.5, k + 3)
    }
    else {
        ylim <- sort(ylim)
    }
    if (is.null(at)) {
        if (alim.spec) {
            at <- seq(from = alim[1], to = alim[2], length.out = steps)
        }
        else {
            at <- pretty(x = c(min(ci.lb, na.rm = TRUE), max(ci.ub, 
                na.rm = TRUE)), n = steps - 1)
        }
    }
    else {
        at[at < alim[1]] <- alim[1]
        at[at > alim[2]] <- alim[2]
        at <- unique(at)
    }
    at.lab <- at
    if (is.function(atransf)) {
        if (is.null(targs)) {
            at.lab <- formatC(sapply(at.lab, atransf), digits = digits[2], 
                format = "f", drop0trailing = ifelse(class(digits) == 
                  "integer", TRUE, FALSE))
        }
        else {
            at.lab <- formatC(sapply(at.lab, atransf, targs), 
                digits = digits[2], format = "f", drop0trailing = ifelse(class(digits) == 
                  "integer", TRUE, FALSE))
        }
    }
    else {
        at.lab <- formatC(at.lab, digits = digits[2], format = "f", 
            drop0trailing = ifelse(class(digits) == "integer", 
                TRUE, FALSE))
    }
    par.mar <- par("mar")
    par.mar.adj <- par.mar - c(0, 3, 1, 1)
    par.mar.adj[par.mar.adj < 0] <- 0
    par(mar = par.mar.adj)
    on.exit(par(mar = par.mar))
    plot(NA, NA, xlim = xlim, ylim = ylim, xlab = "", ylab = "", 
        yaxt = "n", xaxt = "n", xaxs = "i", bty = "n", col = "black", 
        ...)
    abline(h = ylim[2] - 2, lty = lty[2], col = "black", ...)
    if (is.numeric(refline)) 
        segments(refline, ylim[1] - 5, refline, ylim[2] - 2, 
            lty = "dotted", col = "black", ...)
    par.usr <- par("usr")
    height <- par.usr[4] - par.usr[3]
    if (is.null(cex)) {
        lheight <- strheight("O")
        cex.adj <- ifelse(k * lheight > height * 0.8, height/(1.25 * 
            k * lheight), 1)
    }
    if (is.null(cex)) {
        cex <- par("cex") * cex.adj
    }
    else {
        if (is.null(cex.lab)) 
            cex.lab <- cex
        if (is.null(cex.axis)) 
            cex.axis <- cex
    }
    if (is.null(cex.lab)) 
        cex.lab <- par("cex") * cex.adj
    if (is.null(cex.axis)) 
        cex.axis <- par("cex") * cex.adj
    axis(side = 1, at = at, labels = at.lab, cex.axis = cex.axis, 
        col = "black", ...)
    if (missing(xlab)) 
        xlab <- .setlab(measure, transf.char, atransf.char, gentype = 1)
    mtext(xlab, side = 1, at = min(at) + (max(at) - min(at))/2, 
        line = par("mgp")[1] - 0.5, cex = cex.lab, col = "black", 
        ...)
    for (i in seq_len(k)) {
        if (is.na(yi[i]) || is.na(ci.lb[i]) || is.na(ci.ub[i])) 
            next
        if (ci.lb[i] >= alim[2]) {
            polygon(x = c(alim[2], alim[2] - (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[2] - (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[2]), y = c(rows[i], 
                rows[i] + (height/150) * cex * efac[2], rows[i] - 
                  (height/150) * cex * efac[2], rows[i]), col = col[i], 
                border = col[i], ...)
            next
        }
        if (ci.ub[i] <= alim[1]) {
            polygon(x = c(alim[1], alim[1] + (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[1] + (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[1]), y = c(rows[i], 
                rows[i] + (height/150) * cex * efac[2], rows[i] - 
                  (height/150) * cex * efac[2], rows[i]), col = col[i], 
                border = col[i], ...)
            next
        }
        segments(max(ci.lb[i], alim[1]), rows[i], min(ci.ub[i], 
            alim[2]), rows[i], lty = lty[1], col = col[i], ...)
        if (ci.lb[i] >= alim[1]) {
            segments(ci.lb[i], rows[i] - (height/150) * cex * 
                efac[1], ci.lb[i], rows[i] + (height/150) * cex * 
                efac[1], col = col[i], ...)
        }
        else {
            polygon(x = c(alim[1], alim[1] + (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[1] + (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[1]), y = c(rows[i], 
                rows[i] + (height/150) * cex * efac[2], rows[i] - 
                  (height/150) * cex * efac[2], rows[i]), col = col[i], 
                border = col[i], ...)
        }
        if (ci.ub[i] <= alim[2]) {
            segments(ci.ub[i], rows[i] - (height/150) * cex * 
                efac[1], ci.ub[i], rows[i] + (height/150) * cex * 
                efac[1], col = col[i], ...)
        }
        else {
            polygon(x = c(alim[2], alim[2] - (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[2] - (1.4/100) * cex * 
                (xlim[2] - xlim[1]), alim[2]), y = c(rows[i], 
                rows[i] + (height/150) * cex * efac[2], rows[i] - 
                  (height/150) * cex * efac[2], rows[i]), col = col[i], 
                border = col[i], ...)
        }
    }
    text(xlim[1], rows, slab, pos = 4, cex = cex, col = col, 
        ...)
    if (!is.null(ilab)) {
        if (is.null(ilab.xpos)) 
            stop("Must specify 'ilab.xpos' argument when adding information with 'ilab'.")
        if (length(ilab.xpos) != ncol(ilab)) 
            stop(paste0("Number of 'ilab' columns (", ncol(ilab), 
                ") does not match length of 'ilab.xpos' argument (", 
                length(ilab.xpos), ")."))
        if (!is.null(ilab.pos) && length(ilab.pos) == 1) 
            ilab.pos <- rep(ilab.pos, ncol(ilab))
        for (l in seq_len(ncol(ilab))) {
            text(ilab.xpos[l], rows, ilab[, l], pos = ilab.pos[l], 
                cex = cex, ...)
        }
    }
    if (annotate) {
        if (is.function(atransf)) {
            if (is.null(targs)) {
                annotext <- cbind(sapply(yi, atransf), sapply(ci.lb, 
                  atransf), sapply(ci.ub, atransf))
            }
            else {
                annotext <- cbind(sapply(yi, atransf, targs), 
                  sapply(ci.lb, atransf, targs), sapply(ci.ub, 
                    atransf, targs))
            }
            tmp <- .psort(annotext[, 2:3])
            annotext[, 2:3] <- tmp
        }
        else {
            annotext <- cbind(yi, ci.lb, ci.ub)
        }
        if (showweights) 
            annotext <- cbind(weights, annotext)
        annotext <- formatC(annotext, format = "f", digits = digits[1])
        if (missing(width)) {
            width <- apply(annotext, 2, function(x) max(nchar(x)))
        }
        else {
            if (length(width) == 1L) 
                width <- rep(width, ncol(annotext))
        }
        for (j in seq_len(ncol(annotext))) {
            annotext[, j] <- formatC(annotext[, j], width = width[j])
        }
        if (showweights) {
            annotext <- cbind(annotext[, 1], "%   ", annotext[, 
                2], annosym[1], annotext[, 3], annosym[2], annotext[, 
                4], annosym[3])
        }
        else {
            annotext <- cbind(annotext[, 1], annosym[1], annotext[, 
                2], annosym[2], annotext[, 3], annosym[3])
        }
        annotext <- apply(annotext, 1, paste, collapse = "")
        text(x = xlim[2], rows, labels = annotext, pos = 2, cex = cex, 
            col = col, ...)
    }
    for (i in seq_len(k)) {
        if (is.na(yi[i])) 
            next
        if (yi[i] >= alim[1] && yi[i] <= alim[2]) 
            points(yi[i], rows[i], pch = pch[i], cex = cex * 
                psize[i], col = col[i], ...)
    }
    res <- list(xlim = par("usr")[1:2], alim = alim, at = at, 
        ylim = ylim, rows = rows, cex = cex, cex.lab = cex.lab, 
        cex.axis = cex.axis,yi,psize)
    invisible(res)
}
```


### statistical approaches  
The "slopes" dataset contains different estimates (e.g. slope and inflection point) of 174 populations (population is the replicate here) in 30 studies, for 27 species, 21 genera and 10 orders. The correct statistical approach should be: 

estimate ~ climate data, random = (study/species/genus/order), 

with the estimate weighted by the inverse of its standard error. One could argue that study can be erased because it is almost entirely covered by species. I will try to keep it in though, because random effects with nearly 0 explained variance have no effect anyway. The only package (i am aware of) that can do the correct weighting is metafor, and it now also supports nested random terms.

What significance tests (if any) should be reported?
p-values become difficult to calculate in this analysis, because it is nested, unbalanced and weighted, so conditional F-tests are no option (GLMM-Faq by ben bolker explains that well). likelihood-ratio test should work, though it might be inaccurate for small sample sizes. Using a bootstrap version that builds its own Chisquare-like distribution works only for lmer. P is problematic to defend for meta-analyses anyway, so I will not report it. Instead I will report the estimate of the coefficient with confidence interval (Wald-Type,because profile loglik and bootstrap are not available in metafor),I² + confidence interval, pseudo-R², a forest plot, and a plot of prediction + credible intervals. All models will be tested on the easier correlation of latitude and critical day length, and if working, applied to the correlation with predictability/variability.

Generally all outcome statistics are inaccurate, because they expect that variance of each point is known, but I only provide a coarse estimate of vairance that is based on a very low within-population sample size (~4-10 points to get a slope estimate). that needs to be discussed.


## Critical day length and latitude  
### forest plots of CDL  

This forest plot is just to get an overview how the dose-response curve modelling worked; it is not done on the actual meta-analytic model. The default option from package metafor does not allow colour-coding by order/species.

```{r forest_plots}
notsonice<-function(){#this one can be erased
slopes<-slopes[order(slopes$order,slopes$g,slopes$s,slopes$study),]
slopes$real_se<-1/slopes$e_se #drc script inversed that, needs to be undone here.
plot(y=1:nrow(slopes), x=slopes$e, xlim=c(8,21), pch=22, cex=0.8, main = "slopes plot of CDL estimates", xlab = "Critical day length", yaxt="n", ylab="", bg=slopes$col, col=NA)
arrows(x0=slopes$e, y0=1:nrow(slopes), x1=slopes$e+slopes$real_se, length=0, col=1, lwd=1.5)
arrows(x0=slopes$e, y0=1:nrow(slopes), x1=slopes$e-slopes$real_se, length=0, col=1, lwd=1.5)
abline(h=cumsum( as.numeric(table(slopes$order)))+0.5,lty=2,lwd=0.5)#draw line for diff orders
}

#alternative using the slopes.default(or rather my slightly modified version of that)

x<-mydeffor(x=slopes$e,sei=slopes$real_se,annotate=F,pch=22,col=1,bg=1:3,xlim=c(10,20),slab=NA,cex=1,rows=nrow(slopes):1, main = "Forest plot of CDL estimates (from DRC)",xlab="Critical day length") #rows=nrow:1 because it plots the data in reverse order
points(x=x[[9]],y=1:nrow(slopes),col=1,bg=slopes$col[nrow(slopes):1],pch=22,cex=x[[10]]+0.1)
#draw line for diff orders
cums<-cumsum(as.numeric(n))
abline(h=cums+0.5,lty=2,lwd=0.5)#draw line for diff orders

#print labels on left side, 1 for each order
#first, calculate y-value: midpoint of each order
cums<-c(0,cums)
c2<-NA
for(i in 1:(length(cums)-1)){
  c2[i]<-mean(c(cums[i],cums[i+1]))
}
text(x=5,y=c2,labels=names(n),pos=4,cex=0.8)
#text(x=5.5,y=cumsum(as.numeric(table(forest$order))),labels=c(1:7))
#need to play with colours so that each order has diff colour, but species within order also differ slightly
#also consider relevel orders so that large groups (diptera) are at bottom
```

### "influence" plot  
This plot gave a good indication of s.e. of the slope estimates and distribution of cdls. But the s.e. does not go directly into the model, the weights are 1/s.e., and s.e. seems to be really small in some cases. Making a similar plot with "influence" instead of "error"

```{r inverse_forest}
#hist(slopes$e_se,breaks=100) #despite its name this is not s.e. but inverse of s.e.
#truncate highest 5%
slopes$truncse<-1/slopes$real_se #actually that is influence, will be reversed in next lines
#length(slopes$e_se)*0.05 ~9
#length(slopes$e_se[slopes$e_se>260]) 9
slopes$truncse[slopes$truncse>260]<-260
slopes$truncse<-1/slopes$truncse
#alternative: exponential decline model
slopes$expse<-exp(slopes$real_se)

#plot untransformed s.e.
plot(NA,xlim=c(0,nrow(slopes)),ylim=c(0,2500),main = "influence of data points with untransformed s.e.")
segments(x0=1:nrow(slopes),y0=rep(0,nrow(slopes)),x1=1:nrow(slopes),y1=1/slopes$real_se,col=slopes$col,lwd=1.5)

#plot exp(s.e)
plot(NA,xlim=c(0,nrow(slopes)),ylim=c(0,1),main = "influence of data points with exp(s.e.)",xaxt="n",xlab="",ylab = "Influence")
segments(x0=1:nrow(slopes),y0=rep(0,nrow(slopes)),x1=1:nrow(slopes),y1=1/slopes$expse,col=slopes$col,lwd=1.5)

#plot truncated s.e.
plot(NA,xlim=c(0,nrow(slopes)),ylim=c(0,260),xaxt="n",xlab="",ylab = "Influence",main = "influence of data points with truncated s.e.)")
segments(x0=1:nrow(slopes),y0=rep(0,nrow(slopes)),x1=1:nrow(slopes),y1=1/slopes$truncse,col=slopes$order,lwd=1.5)

```

The exponential transform homogenized s.e. a lot!


### The model for latitude - CDL

The critical day length (day length at which 50 % of all offspring switch to diapause) should correlate with latitude. Earlier studies quote rates of 1-1.5 hours per 5°N. Let's see if that holds for the data in this meta-analysis.


#### a simple (but wrong) rma model (to test metafor) 
```{r rma}
rmamod<-rma(yi=e,vi=expse,mods = degN,data=slopes,method="REML",weighted=T,test="knha")
summary(rmamod)
confint(rmamod)

#plot cdl~degN with CI and credible intervals
ps<-predict.rma(rmamod)

#need to make dataframe from 1:degN and back to 1 to draw polygon(CI and CR)
normal<- data.frame(slopes$degN,ps$cr.lb,ps$ci.lb)
names(normal)<-c("degN","cr","ci")
normal<-normal[order(normal$degN),]
reversed<-data.frame(slopes$degN,ps$cr.ub,ps$ci.ub)
names(reversed)<-c("degN","cr","ci")
reversed<-reversed[order(reversed$degN),]
reversed<-reversed[nrow(reversed):1,]
combined<-rbind(normal,reversed)
names(combined)<-c("degN","cr","ci")

plot(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA, bg=slopes$col)
polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$degN, y=combined$ci,col="darkgrey",border=NA)
points(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA,bg=slopes$col)

#comparing that to a lme
#summary(lme(e~degN,random= ~1|ID,data=slopes)) #similar bot not exactly same (due to lack of weighting)
#summary(lme(e~degN,random= ~1|ID,data=slopes, weights= ~expse)) #nearly same

plot(rmamod)#residuals look fine
infl<-influence(rmamod)
#plot(infl)
#qqnorm(rmamod)#looks fine
```


#### the actual model
```{r nested_rma}
rmamod_nested<-rma.mv(yi = e ~ degN, V = expse, random = ~1|order/g/s/study, data = slopes,test="t")
summary(rmamod_nested) # species has no variance explained
profile(rmamod_nested, sigma2=1)#order
profile(rmamod_nested, sigma2=2)#order/g
profile(rmamod_nested, sigma2=3)#order/g/s #reaches maximum when set to 0
profile(rmamod_nested, sigma2=4)#order/g/s/study
```

species explains nothing because in most cases each study has 1 species. Only in  4 species there are 2 studies, though in 1 study there are 3 species. removing study from the model ignores that the "2 studies of 1 species cases" should cluster (not reasonable), but also treats the 3 species within 1 study as independent (which is reasonable). Removing species rightly expects that studies of 1 species cluster (reasonable), but expects also that the 3 species of one study cluster (not reasonable). they can considered as equal, but because meta-analyses are expected to have study as random I prefer to kick out species. 
Profile plots of the reduced models:
#### alternative models  
```{r profplots}
rmamod_rednested<-rma.mv(yi = e ~ degN, V = expse, random = ~1|order/g/study,data = slopes)
profile(rmamod_rednested, sigma2=1)#order
profile(rmamod_rednested, sigma2=2)#order/g #not much but okay
profile(rmamod_rednested, sigma2=3)#order/g/study 

#comparing to lme and model without study
rmamod_rednested2<-rma.mv(yi = e ~ degN, V = expse, random = ~1|order/g/s,data = slopes)
profile(rmamod_rednested2, sigma2=1)#order
profile(rmamod_rednested2, sigma2=2)#order/g #better
profile(rmamod_rednested2, sigma2=3)#order/g/s
```

#### results  
Both are fine, so I stick to the one without species
```{r degN_results}
rmamod_nested<-rmamod_rednested
summary(rmamod_nested)
#comparing to lmes
summary(lme(e~degN, random =~ 1|order/g/study,data=slopes,weights=~expse)) #very similar
#summary(lme(e~degN ,random=~ 1|order/g/s/study,data=slopes, weights= ~expse))

#1. estimate +ci
confint(rmamod_nested,fixed=T,random=F)
#2. I² 
W <- diag(1/slopes$expse)
X <- model.matrix(rmamod_nested)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W #generalized calculation of I² as described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#overall I² (using sum of sigmas)

100 * sum(rmamod_nested$sigma2) / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P)))
#I² of each level
round(100 * rmamod_nested$sigma2 / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P))),4)
#heterogeneity makes up 57% of overall variance, order,genus,study have 20,8, and 29%


#3. forest plot #this version plots predictions + CI as whiskers
notneeded<-function(){
  fore<-data.frame(ps$pred,ps$ci.lb,ps$ci.ub,r2$order,r2$g,r2$s,r2$study,r2$col,r2$degN,r2$e)
fore<-fore[order(fore$r2.order,fore$r2.g,fore$r2.s,fore$r2.study,decreasing=F),]
fore$ord<-1:nrow(fore)
plot(y=1:nrow(forest), x=fore$ps.pred, xlim=c(8,21), pch=22, cex=0.8, main = "Forest plot of CDL estimates", xlab = "Critical day length", yaxt="n", ylab="", bg=fore$r2.col, col=NA)
abline(v=0,lty=3,col="darkgrey")
arrows(x0=fore$ps.ci.ub, y0=1:nrow(forest), x1=fore$ps.ci.lb, length=0, col=1, lwd=1.5)
abline(h=cumsum( as.numeric(table(fore$r2.order)))+0.5,lty=2,lwd=0.5)#draw line for diff orders
}

#forest plot sorted by order 
yi<-rmamod_nested$yi
vicorr<-slopes[nrow(slopes):1,"real_se"]

ci.ub<-yi + qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.lb<-yi - qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.ub<-ci.ub[length(ci.ub):1]
ci.lb<-ci.lb[length(ci.lb):1]
x<-myfor(rmamod_nested,addcred=T,addfit=T,cex.axis=1,cex.lab=2,cex=0.5,xlim=c(6,25),alim=c(8,23),slab=NA,annotate=F,ci.ub=ci.ub,ci.lb=ci.lb,order=1:174, main = "Forest plot, sorted by phylogeny",xlab = "CDL")
#this plot shows: original CDL as black square, credible interval of fitted value as grey polygon, whiskers based on original s.e. (standard function would use exp(s.e.))

#needs cex of each point
text(x=7,y=c2,labels=names(n),pos=4,cex=0.8)
abline(h=cums+0.5,lty=2,lwd=0.5)#draw line for diff orders
points(rmamod_nested$yi,174:1,bg=slopes$col,cex=0.8,pch=22)


#forest plot sorted by degN
yi<-rmamod_nested$yi
yi<-yi[order(slopes$degN)]
vicorr<-slopes[nrow(slopes):1,"real_se"]
vicorr<-vicorr[order(slopes$degN)]
ci.ub<-yi + qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.lb<-yi - qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.ub<-ci.ub[length(ci.ub):1]
ci.lb<-ci.lb[length(ci.lb):1]
x<-myfor(rmamod_nested,addcred=T, addfit=T, cex.axis=1, cex.lab=2, cex=0.5, xlim=c(6,25), alim=c(8,23), slab=NA, annotate=F, ci.ub=ci.ub, ci.lb=ci.lb, order=order(slopes$degN),main = "Forest plot, sorted by latitude",xlab = "CDL")
points(yi,174:1,bg=slopes$col[order(slopes$degN)],cex=0.8,pch=22)


#4. pseudo-R^2
pseudo_nested<-rma.mv(yi = e ~ 1, V = expse, random = ~1|order/g/study,data = slopes,test="t")
rsq<-(sum(pseudo_nested$sigma2)-sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2)
#0.60



#6. plot prediction + credible interval
ps<-predict.rma(rmamod_nested)

normal<- data.frame(slopes$degN,ps$cr.lb,ps$ci.lb)
names(normal)<-c("degN","cr","ci")
normal<-normal[order(normal$degN),]
reversed<-data.frame(slopes$degN,ps$cr.ub,ps$ci.ub)
names(reversed)<-c("degN","cr","ci")
reversed<-reversed[order(reversed$degN),]
reversed<-reversed[nrow(reversed):1,]
combined<-rbind(normal,reversed)
names(combined)<-c("degN","cr","ci")

plot(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA, bg=slopes$col,main = "Delay in photoperiodic response vs latitude", xlab = "Latitude (°N)", ylab = "Critical photoperiod")
legend("topleft",pch = 21, pt.bg = 1:7,legend=unique(slopes$order)[7:1],cex=0.8)
polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$degN, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$degN,y=ps$pred,lwd=2)
points(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA,bg=slopes$col)
ci.lb<-ci.lb[length(ci.lb):1]
ci.ub<-ci.ub[length(ci.ub):1]
segments(x0=slopes$degN[order(slopes$degN)],x1=slopes$degN[order(slopes$degN)],y0=ci.lb,y1=ci.ub)
#segments(x0=slopes$degN,x1=slopes$degN,y0=slopes$e+slopes$real_se,y1=slopes$e-slopes$real_se)
axis(1)
s_est<-confint(rmamod_nested,fixed=T,random=F)$fixed[2,1]*5
s_est<-round(s_est,2)
rsq=round(rsq,2)
#5 degrees latitude ~ 1 hour
text(50,20,paste("slope = ",s_est, " hours/5°N\npseudo-R² = ",rsq),cex=0.8)

```

#### alternative plot of results  
making the same plot as last one, but with lines for each study
```{r CDL_studylines}
plot(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA, bg=slopes$col,main = "Delay in photoperiodic response vs latitude", xlab = "Latitude (°N)", ylab = "Critical photoperiod")
legend("topleft",pch = 21, pt.bg = 1:7,legend=unique(slopes$order)[7:1],cex=0.8)
polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$degN, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$degN,y=ps$pred,lwd=2)
points(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA,bg=slopes$col)
axis(1)
for(i in 1:length(unique(slopes$study))){
  sub<-slopes[slopes$study==unique(slopes$study)[i],]
  studmod<-rma.mv(yi = e ~ degN, V = expse, data = sub)
  sub$pred<-predict(studmod)$pred
  lines(sub$pred~sub$degN,col=unique(sub$col),lwd=0.5)
}
#segments(x0=slopes$degN[order(slopes$degN)],x1=slopes$degN[order(slopes$degN)],y0=ci.lb,y1=ci.ub)
s_est<-confint(rmamod_nested,fixed=T,random=F)$fixed[2,1]*5
s_est<-round(s_est,2)
rsq=round(rsq,2)
#5 degrees latitude ~ 1 hour
text(50,20,paste("slope = ",s_est, " hours/5°N\npseudo-R² = ",rsq),cex=0.8)
```

The estimate of 1 h per 5° N is not too bad, overall diapause becomes 50 min earlier per 5°.



## Climate data

The things so far tested only CDL vs latitude, implying that mean winter is a function of latitude. A better way would be to test CDL directly vs winter onset. And then there is of course the question how slopes correlate with climate variables. So the next step is to look  at the climate data. 

### overview
This section correlates the climate variables against each other, and plots them on a global map.

#### mean winter and latitude  

```{r clim_M}
plot(climate$meanwinter~climate$lat,pch=22,cex=0.1, main ="Mean winter onset vs. latitude")
hist(slopes$degN,breaks=100)
```

It is possibly a bad idea to use any climate above 70°N. The highest latitude in the studies was 69.05 °N. The apparent cap at ~25°N is because winter is not defined for warm climates (winter never arrives). The lowest latitude in the studies is at 18.3°N. 
#### Refined overview:  

```{r minus70}
climate<-climate[climate$lat<=70,]
plot(climate$meanwinter~climate$lat,pch=22,cex=0.1, main ="Mean winter onset vs. latitude")
M<-lm(climate$meanwinter~climate$lat)
```

#### expected CDL shifts
Mean winter decreases by 2.6 days per ° latitude = 13 days per 5°, so an organism needs to react to a day length equal to 13 days earlier in the year per 5°N. The correct calculation of day length at a given latitude for a given day is difficult: https://en.wikipedia.org/wiki/Sunrise_equation
luckily there is a package that solves that.

```{r climate_CDL}
M<-lm(climate$meanwinter~climate$lat)
#expected_dl = daylength(latitude,day)
#with day = day from regression on M +182 days because the "year" calculated from climate data starts in july
slopes$expdl<-daylength(slopes$degN,
              182+coef(M)[1]+coef(M)[2]*slopes$degN
)
#the switch to diapause usually takes some time, e.g. sexual offspring must be produced and mature. lets try 1 - 3 weeks
slopes$expdl7<-daylength(slopes$degN, 182+coef(M)[1]+coef(M)[2]*slopes$degN-7)
slopes$expdl14<-daylength(slopes$degN,182+coef(M)[1]+coef(M)[2]*slopes$degN-14)
slopes$expdl21<-daylength(slopes$degN,182+coef(M)[1]+coef(M)[2]*slopes$degN-21)
plot(slopes$expdl~slopes$degN,main = "how the CDL should vary with latitude",xlab ="latitude",ylab ="expected CDL")
points(slopes$expdl7~slopes$degN,col=2)
points(slopes$expdl14~slopes$degN,col=3)
points(slopes$expdl21~slopes$degN,col=4)
```

#### combining these two  
integrating this into the curve of CDL vs latitude (mostly copy of above code)

```{r CDL_and_expected}

plot(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA, bg=slopes$col,main = "Delay in photoperiodic response vs latitude", xlab = "Latitude (°N)", ylab = "Critical photoperiod")
legend("topleft",pch = 21, pt.bg = 1:7,legend=unique(slopes$order)[7:1],cex=0.8)
polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$degN, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$degN,y=ps$pred,lwd=2)
points(x=slopes$degN,y=slopes$e,pch=21,cex=0.8,col=NA,bg=slopes$col)
segments(x0=slopes$degN[order(slopes$degN)],x1=slopes$degN[order(slopes$degN)],y0=ci.lb,y1=ci.ub)
#segments(x0=slopes$degN,x1=slopes$degN,y0=slopes$e+slopes$real_se,y1=slopes$e-slopes$real_se)
axis(1)
s_est<-confint(rmamod_nested,fixed=T,random=F)$fixed[2,1]*5
s_est<-round(s_est,2)
rsq=round(rsq,2)
#5 degrees latitude ~ 1 hour
text(50,20,paste("slope = ",s_est, " hours/5°N\npseudo-R² = ",rsq),cex=0.8)

points(x=slopes$degN, y = slopes$expdl,cex=0.3)
points(slopes$expdl21~slopes$degN,col=4,cex=0.3)

plot(slopes$e~slopes$expdl,main = "Correlation of Critical day length and expected CDL",xlab ="expected by climate data",ylab="CDL from studies")
abline(lm(slopes$e~slopes$expdl))
summary(lm(slopes$e~slopes$expdl))
```


#### some histograms

```{r hist, include = FALSE}
hist(climate$alt)
climate$sq_alt <-sqrt(climate$alt) #few NAs producded
hist(climate$sq_alt,breaks=100)

hist(climate$meanwinter,breaks=100)
hist(climate$sd_winter,breaks=100)
climate$capped_sd<-climate$sd_winter
climate$capped_sd[climate$capped_sd>50]<-50

hist(climate$nyears,breaks=50)

hist(climate$beta,breaks=100)#this is considerably less than in vasseur & Yodzis!
hist(climate$p)
hist(climate$p[climate$p<5],breaks=100) #99.99 %
```

#### histograms for nls regression  
```{r nls_hist, include= F}
p<-climate
hist(p$A)
hist(p$phi)
hist(p$c)
```

### Visualisation

#### global view of nls results
```{r nls ,include =F}

p$c[p$c<(-100)]<-(-100)
p$c[p$c>200]<-200
p$c<-p$c+abs(min(p$c,na.rm=T))
p$A[p$A>250]<-250
p<-p[!is.na(p$c),]
plot(p$lat~p$lon,bg = rgb(p$c,0,p$c,maxColorValue = max(p$c)),col=NA,pch=22,cex=0.3,main = "mean temperature from nls regression (intercept)")
plot(p$lat~p$lon,bg = rgb(p$A,0,p$A,maxColorValue = max(p$A)),cex=0.3,pch=22,col=NA,main ="difference between summer and witner from nls regression (amplitude)")
plot(p$lat~p$lon,bg=rgb(p$phi,0,p$phi,maxColorValue = max(p$phi)),cex=0.3,pch=22,col=NA,main = "midsummer from nls regression (phase angle)")
```

####  mean winter, sd(winter), predictability, beta  

```{r visualisation}
#png("mean-winter.png")
p<-climate
p<-p[!is.na(p$meanwinter),]
plot(p$lat~p$lon,bg = rgb(p$meanwinter,p$meanwinter,0,maxColorValue = max(p$meanwinter)),cex=0.3,pch=22,col=NA, main ="mean winter onset",xlab="",ylab="")
#dev.off()

p<-climate
p<-p[!is.na(p$capped_sd),]
p$capped_sd[p$capped_sd>20]<-20
p<-p[p$nyears>8,]
#png("sd-winter.png")
plot(p$lat~p$lon,bg = rgb(p$capped_sd,p$capped_sd,0,maxColorValue = max(p$capped_sd)),cex=0.3,pch=22,col=NA, main ="sd winter onset, capped at 20",xlab="",ylab="")
#dev.off()


p<-climate[climate$nyears>25,]
p<-p[!is.na(p$beta),]
p$beta[p$beta>1.2]<-1.2 #0.42% of all data
p$beta[p$beta>1]<-1
p$beta[p$beta<0]<-0 #1.99%


#png("predictability-beta.png")
plot(p$lat~p$lon,bg = rgb(1,max(p$beta)-p$beta,max(p$beta)-p$beta,maxColorValue =1),cex=0.3,pch=22,col=NA, main ="predictability (beta)",xlab="",ylab="")
#dev.off()
#or to have the same colour:
plot(p$lat~p$lon,bg = rgb(p$beta,p$beta,0,maxColorValue = max(p$beta+0.001)),cex=0.3,pch=22,col=NA, main ="predictability (beta)",xlab="",ylab="")
#dev.off()


p<-climate[climate$nyears>25,]
p<-p[!is.na(p$p),]
p<-p[p$p<5,] #99.7%
#range(p$unpredictability)
#png("predictability-winter.png")
plot(p$lat~p$lon,bg = rgb(p$p,p$p,0,maxColorValue = max(p$p+0.001)),cex=0.3,pch=22,col=NA, main ="predictability (sd slopes)",sub="dark low standard deviation in slopes",xlab="",ylab="")
#dev.off()
```

#### correlations of sd/predictabiltiy with environmental variables

```{r corr_climate}
p<-climate
p$A[p$A>250]<-250
p$p[p$p>5]<-5
plot(p$capped_sd~p$lat,pch=22,cex=0.1)
plot(p$capped_sd~p$sq_alt,pch=22,cex=0.1)
plot(p$capped_sd~p$A,pch=22,cex=0.1)
plot(p$capped_sd~p$meanwinter,pch=22,cex=0.1)

plot(p$p~p$lat,pch=22,cex=0.1)
plot(p$p~p$sq_alt,pch=22,cex=0.1)
plot(p$p~p$A,pch=22,cex=0.1)
plot(p$p~p$meanwinter,pch=22,cex=0.1)

p$beta[p$beta<0]<-0
p$beta[p$beta>1]<-1
plot(p$beta~p$lat,pch=22,cex=0.1)
plot(p$beta~p$sq_alt,pch=22,cex=0.1)
plot(p$beta~p$A,pch=22,cex=0.1)
plot(p$beta~p$meanwinter,pch=22,cex=0.1)

#summary(lm(p$p~p$lat+p$lon+p$sq_alt))
#summary(lm(p$beta~p$lat+p$lon+p$alt))
#summary(lm(p$capped_sd~p$lat+p$lon+p$sq_alt))

```
#### correlation of variability/predictability with each other  

```{r corr_responses}
plot(p$capped_sd~p$p,pch=22,cex=0.1)
plot(p$capped_sd~p$beta,pch=22,cex=0.1)
plot(p$p~p$beta,pch=22,cex=0.1)
```

## combining empirical data and climate

Empirical studies were not necessarily done close to a climate station. To estimate climate at a given study location, I take the average of the 5 closest stations, weighted by euclidian distance. 
### combining  

```{r combine}
slopes$meanwinter<-NA
slopes$sd_winter<-NA
slopes$unpredictability<-NA
slopes$nyears<-NA
slopes$beta<-NA 

for ( i in 1:nrow(slopes)){
  #reduce to +-5 °
  sub<-climate[between(climate$lat,slopes[i,"degN"]-5,slopes[i,"degN"]+5)& between(climate$lon,slopes[i,"degE"]-5,slopes[i,"degE"]+5),]
  
  sub$diffN<-sub$lat-slopes[i,"degN"] #calculate distance in latitude
  sub$diffE<-sub$lon-slopes[i,"degE"] #same for longitude
  sub$diff<-sqrt(sub$diffN^2+sub$diffE^2) #euclidian distance
      #test whether this works
#  plot(sub$lat~sub$lon,pch=22,bg=rgb(1,sub$diff,1,maxColorValue = max(sub$diff)))


  sub<-arrange(sub,diff)[1:5,] #sort and take 5 lowest values
  

  
  slopes$meanwinter[i]<-weighted.mean(sub$meanwinter,1/sub$diff)
  slopes$sd_winter[i]<-weighted.mean(sub$sd_winter,1/sub$diff)
  slopes$p[i]<-weighted.mean(sub$p,1/sub$diff)
  slopes$nyears[i]<-weighted.mean(sub$nyears,1/sub$diff)
  slopes$beta[i]<-weighted.mean(sub$beta,1/sub$diff)

}

slopes<-slopes[!is.na(slopes$meanwinter),]
```

### visualising
```{r maps}
#empty map
p<-climate
p<-p[!is.na(p$meanwinter),]
plot(p$lat~p$lon,bg = rgb(0.8,0.8,0.8,maxColorValue =1),cex=0.3,pch=22,col=NA, main ="Study locations",xlab="",ylab="")
points(slopes$degN~slopes$degE,pch=22,bg=1,cex=0.2)

#test whether euclidian distance did something bad
plot(p$lat~p$lon,bg = rgb(p$meanwinter,p$meanwinter,0,maxColorValue = max(p$meanwinter)),cex=0.3,pch=22,col=NA, main ="mean winter onset",xlab="",ylab="")
points(slopes$degN~slopes$degE,pch=22,bg=rgb(slopes$meanwinter,slopes$meanwinter,0,maxColorValue = max(p$meanwinter)),cex=0.5,col=NA)
#points are invisible, so the yblend perfectly with the other data


#visualizing variability/predictability of study locations


slopes$temp<-slopes$meanwinter
plot(p$lat~p$lon,bg = rgb(0.8,0.8,0.8),cex=0.3,pch=22,col=NA, main ="mean winter",xlab="",ylab="")
points(slopes$degN~slopes$degE,pch=22,bg=rgb(slopes$temp,slopes$temp,0,maxColorValue = max(slopes$temp)),cex=0.5,col=NA)

slopes$temp<-slopes$sd_winter
slopes$temp[slopes$temp>50]<-50
plot(p$lat~p$lon,bg = rgb(0.8,0.8,0.8),cex=0.3,pch=22,col=NA, main ="sd(winter)",xlab="",ylab="")
points(slopes$degN~slopes$degE,pch=22,bg=rgb(slopes$temp,slopes$temp,0,maxColorValue = max(slopes$temp)),cex=0.5,col=NA)

slopes$temp<-slopes$p
plot(p$lat~p$lon,bg = rgb(0.8,0.8,0.8),cex=0.3,pch=22,col=NA, main ="predictability(slopes)",xlab="",ylab="")
points(slopes$degN~slopes$degE,pch=22,bg=rgb(slopes$temp,slopes$temp,0,maxColorValue = max(slopes$temp)),cex=0.5,col=NA)

slopes$temp<-slopes$beta
slopes$temp[slopes$temp<0]<-0
plot(p$lat~p$lon,bg = rgb(0.8,0.8,0.8),cex=0.3,pch=22,col=NA, main ="predictability (beta)",xlab="",ylab="")
points(slopes$degN~slopes$degE,pch=22,bg=rgb(slopes$temp,slopes$temp,0,maxColorValue = max(slopes$temp)),cex=0.5,col=NA)

slopes$temp<-slopes$b
plot(p$lat~p$lon,bg = rgb(0.8,0.8,0.8),cex=0.3,pch=22,col=NA, main ="b",xlab="",ylab="")
points(slopes$degN~slopes$degE,pch=22,bg=rgb(slopes$temp,slopes$temp,0,maxColorValue = max(slopes$temp)),cex=0.8,col=NA)
```


## correlation of CDL with mean winter onset
```{r}
cdl_nested<-rma.mv(yi = e ~ meanwinter, V = expse, random = ~1|order/g/s/study, data = slopes,test="t")
summary(rmamod_nested)
cdl_rednested<-rma.mv(yi = e ~ meanwinter, V = expse, random = ~1|order/g/study,data = slopes)
summary(cdl_rednested)
cdl_rednested2<-rma.mv(yi = e ~ meanwinter, V = expse, random = ~1|order/g/s,data = slopes)
summary(cdl_rednested2)
```
```{r cdl_results}
rmamod_nested<-cdl_rednested
summary(rmamod_nested)
#comparing to lmes
summary(lme(e~meanwinter, random =~ 1|order/g/study,data=slopes,weights=~expse)) #very similar
#summary(lme(e~degN ,random=~ 1|order/g/s/study,data=slopes, weights= ~expse))

#1. estimate +ci
confint(rmamod_nested,fixed=T,random=F)
#2. I² 
W <- diag(1/slopes$expse)
X <- model.matrix(rmamod_nested)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W #generalized calculation of I² as described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#overall I² (using sum of sigmas)

100 * sum(rmamod_nested$sigma2) / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P)))
#I² of each level
round(100 * rmamod_nested$sigma2 / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P))),4)
#heterogeneity makes up 55% of overall variance, genus,study have 9.5 and 46%


#3. forest plot #this version plots predictions + CI as whiskers

#forest plot sorted by order 
yi<-rmamod_nested$yi
vicorr<-slopes[nrow(slopes):1,"real_se"]

ci.ub<-yi + qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.lb<-yi - qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.ub<-ci.ub[length(ci.ub):1]
ci.lb<-ci.lb[length(ci.lb):1]
x<-myfor(rmamod_nested,addcred=T,addfit=T,cex.axis=1,cex.lab=2,cex=0.5,xlim=c(6,25),alim=c(8,23),slab=NA,annotate=F,ci.ub=ci.ub,ci.lb=ci.lb,order=1:170, main = "Forest plot, sorted by phylogeny",xlab = "mean winter")
#this plot shows: original CDL as black square, credible interval of fitted value as grey polygon, whiskers based on original s.e. (standard function would use exp(s.e.))

#needs cex of each point
text(x=7,y=c2,labels=names(n),pos=4,cex=0.8)
abline(h=cums+0.5,lty=2,lwd=0.5)#draw line for diff orders
points(rmamod_nested$yi,170:1,bg=slopes$col,cex=0.8,pch=22)


#forest plot sorted by mean winter
yi<-rmamod_nested$yi
yi<-yi[order(slopes$meanwinter)]
vicorr<-slopes[nrow(slopes):1,"real_se"]
vicorr<-vicorr[order(slopes$meanwinter)]
ci.ub<-yi + qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.lb<-yi - qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.ub<-ci.ub[170:1]
ci.lb<-ci.lb[170:1]
x<-myfor(rmamod_nested,addcred=T, addfit=T, cex.axis=1, cex.lab=2, cex=0.5, xlim=c(6,25), alim=c(8,23), slab=NA, annotate=F, ci.ub=ci.ub, ci.lb=ci.lb, order=order(slopes$meanwinter),main = "Forest plot, sorted by mean winter",xlab = "MEan winter")
points(yi,170:1,bg=slopes$col[order(slopes$meanwinter)],cex=0.8,pch=22)


#4. pseudo-R^2
pseudo_nested<-rma.mv(yi = e ~ 1, V = expse, random = ~1|order/g/study,data = slopes,test="t")
rsq<-(sum(pseudo_nested$sigma2)-sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2)
#0.60



#6. plot prediction + credible interval
ps<-predict.rma(rmamod_nested)

normal<- data.frame(slopes$meanwinter,ps$cr.lb,ps$ci.lb)
names(normal)<-c("meanwinter","cr","ci")
normal<-normal[order(normal$meanwinter),]
reversed<-data.frame(slopes$meanwinter,ps$cr.ub,ps$ci.ub)
names(reversed)<-c("meanwinter","cr","ci")
reversed<-reversed[order(reversed$meanwinter),]
reversed<-reversed[nrow(reversed):1,]
combined<-rbind(normal,reversed)
names(combined)<-c("meanwinter","cr","ci")

plot(x=slopes$meanwinter,y=slopes$e,pch=21,cex=0.8,col=NA, bg=slopes$col,main = "Delay in photoperiodic response vs winter onset", xlab = "Mean winter onset [julian date?]", ylab = "Critical photoperiod")
legend("topright",pch = 21, pt.bg = 1:7,legend=unique(slopes$order)[7:1],cex=0.8)
polygon(x=combined$meanwinter, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$meanwinter, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$meanwinter,y=ps$pred,lwd=2)
points(x=slopes$meanwinter,y=slopes$e,pch=21,cex=0.8,col=NA,bg=slopes$col)
ci.lb<-ci.lb[length(ci.lb):1]
ci.ub<-ci.ub[length(ci.ub):1]
segments(x0=slopes$meanwinter[order(slopes$meanwinter)],x1=slopes$meanwinter[order(slopes$meanwinter)],y0=ci.lb,y1=ci.ub)
#segments(x0=slopes$meanwinter,x1=slopes$meanwinter,y0=slopes$e+slopes$real_se,y1=slopes$e-slopes$real_se)
axis(1)
s_est<-confint(rmamod_nested,fixed=T,random=F)$fixed[2,1]*5
s_est<-round(s_est,2)
rsq=round(rsq,2)
#5 degrees latitude ~ 1 hour
text(50,20,paste("slope = ",s_est, " hours/5°N\npseudo-R² = ",rsq),cex=0.8)
#points(slopes$expdl~slopes$meanwinter,col=2)
#points(slopes$expdl7~slopes$meanwinter,col=3)
#points(slopes$expdl14~slopes$meanwinter,col=4)
#points(slopes$expdl21~slopes$meanwinter,col=5)

points(slopes$expdl14~slopes$meanwinter,col=4,pch=21,cex=0.2)
#testing how that relates with expected day length (need to check formula, is it correctly calculated?)
cdl_cor<-rma.mv(yi = e ~ expdl14, V = expse, random = ~1|order/g/study,data = slopes)
summary(cdl_cor)
#r2 can re-use pseudonested (e~1,random = order/g/study)
rsq<-(sum(pseudo_nested$sigma2)-sum(cdl_cor$sigma2))/sum(pseudo_nested$sigma2)

ps<-predict.rma(cdl_cor)
normal<- data.frame(slopes$expdl14,ps$cr.lb,ps$ci.lb)
names(normal)<-c("expdl14","cr","ci")
normal<-normal[order(normal$expdl14),]
reversed<-data.frame(slopes$expdl14,ps$cr.ub,ps$ci.ub)
names(reversed)<-c("expdl14","cr","ci")
reversed<-reversed[order(reversed$expdl14),]
reversed<-reversed[nrow(reversed):1,]
combined<-rbind(normal,reversed)
names(combined)<-c("expdl14","cr","ci")

s_est<-confint(cdl_cor,fixed=T,random=F)$fixed[2,1]
s_est<-round(s_est,2)
rsq=round(rsq,2)

plot(slopes$e~slopes$expdl14,pch=21,cex=1.2,bg=1,xlab = "Expected day length", ylab = "Empirical day length",cex.axis=1.2,main = "Empirical vs. expected day length",cex.lab=1.2)
polygon(x=combined$expdl14, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$expdl14, y=combined$ci,col="darkgrey",border=NA)
points(slopes$e~slopes$expdl14,pch=21,cex=1.2,bg=1)
lines(x=slopes$expdl14,y=ps$pred,lwd=2)
diff_from_pred<-confint(cdl_cor,fixed=T,random=F)$fixed[1,1]+10*0.8381538-10 #prediction on x=10 minus 10
#text(14,12,paste("slope = ",s_est, "\ndifference= ",diff_from_pred,"\npseudo-R² = ",rsq),cex=0.8,pos=4)
text(13.5,10,paste("Pseudo-R² = ",rsq),cex=1.2,pos=4)
#this plot could be used as inlay for preceding plot
```


## slope and winter variability/predictability
This is the main part of the study. slopes is expected to correlate with variability and predictability. predictability is here defined as sd(slopes) of temperature right before winter onset. The colour of noise approach is considered exploratory and in a different section.


### forest plot of slopes estimates
```{r forest_slopes}
slopes$real_ses<-1/slopes$b_se
x<-mydeffor(x=slopes$b,sei=slopes$real_ses,annotate=F,pch=22,col=1,xlim=c(-100,500),alim=c(-80,500),bg=1:3,slab=NA,cex=1,rows=nrow(slopes):1, main = "Forest plot of slope estimates (from DRC)",xlab="Slopes") #rows=nrow:1 because it plots the data in reverse order
points(x=x[[9]],y=1:nrow(slopes),col=1,bg=slopes$col[nrow(slopes):1],pch=22,cex=x[[10]]+0.1)
#draw line for diff orders
cums<-cumsum(as.numeric(n))
abline(h=cums+0.5,lty=2,lwd=0.5)#draw line for diff orders

#print labels on left side, 1 for each order
#first, calculate y-value: midpoint of each order
cums<-c(0,cums)
c2<-NA
for(i in 1:(length(cums)-1)){
  c2[i]<-mean(c(cums[i],cums[i+1]))
}
text(x=-75,y=c2,labels=names(n),pos=4,cex=0.8)
hist(slopes$real_ses,breaks=100)
```

```{r inversify}
#plot inverse of untransformed s.e.
plot(NA,xlim=c(0,nrow(slopes)),ylim=c(0,3),main = "influence of data points with untransformed s.e.")
segments(x0=1:nrow(slopes),y0=rep(0,nrow(slopes)),x1=1:nrow(slopes),y1=1/slopes$real_ses,col=slopes$col,lwd=1.5)
abline(h=0.15,lty=3)
abline(h=1.5)
abline(h=0.015)
#there are 3 studies that have less than 1/10th of the median influence, nad thre are 6 studies that are more than 10 times as influential as the median. both are okay I think

#alternative: sqrt-transformed ses
slopes$expses<-sqrt(slopes$real_ses) # nope that does not make sense
#keeps the name because easier coding

#plot exp(s.e)
plot(NA,xlim=c(0,nrow(slopes)),ylim=c(0,1),main = "influence of data points with exp(s.e.)",xaxt="n",xlab="",ylab = "Influence")
segments(x0=1:nrow(slopes),y0=rep(0,nrow(slopes)),x1=1:nrow(slopes),y1=1/slopes$expse,col=slopes$col,lwd=1.5)
#this weighs the studies with nearly infinte s.e. way too strongly (40%!)

```

The standard errors are fine as they are. 

### model slopes ~ variability * predictability
```{r slopemodels}
slopes_vp.f<-rma.mv(yi = b ~ sd_winter * p, V = real_ses, random = ~1|order/g/s/study, data = slopes,test="t")

summary(slopes_vp.f) # species has no variance explained
profile(slopes_vp.f, sigma2=1)#order
profile(slopes_vp.f, sigma2=2)#order/g
profile(slopes_vp.f, sigma2=3)#order/g/s #reaches maximum when set to 0
profile(slopes_vp.f, sigma2=4)#order/g/s/study

slopes_vp.s<-rma.mv(yi = b ~ sd_winter * p, V = real_ses, random = ~1|order/g/study, data = slopes,test="t")

summary(slopes_vp.s) # species has no variance explained
profile(slopes_vp.s, sigma2=1)#order
profile(slopes_vp.s, sigma2=2)#order/g
profile(slopes_vp.s, sigma2=3)#order/g/s #reaches maximum when set to 0
profile(slopes_vp.s, sigma2=4)#order/g/s/study
```


### results (without plotting)
The same model as for CDL can be used
```{r slope_results}
rmamod_nested<-slopes_vp.s
summary(rmamod_nested)
#comparing to lmes
summary(lme(b~sd_winter*p, random =~ 1|order/g/study,data=slopes,weights=~real_ses))#different (better) df estimate, different coefs but same direction

#1. estimate +ci
confint(rmamod_nested,fixed=T,random=F)
#2. I² 
W <- diag(1/slopes$real_ses)
X <- model.matrix(rmamod_nested)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W #generalized calculation of I² as described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#overall I² (using sum of sigmas)

100 * sum(rmamod_nested$sigma2) / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P)))
#I² of each level
round(100 * rmamod_nested$sigma2 / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P))),4)
#99% heterogeneity, 79% due to genus. though not sure whehter calculation works for interaction


#3. forest plot #this version plots predictions + CI as whiskers
#forest plot sorted by order 
yi<-rmamod_nested$yi
vicorr<-slopes[nrow(slopes):1,"real_ses"]

ci.ub<-yi + qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.lb<-yi - qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.ub<-ci.ub[length(ci.ub):1]
ci.lb<-ci.lb[length(ci.lb):1]
#this time there was no transformation of s.e. so the normal forest plot function can be used 

forest.rma(rmamod_nested,addcred=T,addfit=T,cex.axis=1,cex.lab=2,cex=1,slab=NA,annotate=F,order=1:170, xlim=c(-90,300),main = "Forest plot, sorted by phylogeny",xlab = "slope",alim=c(-100,350))

#needs cex of each point
text(x=-30,y=c2,labels=names(n),pos=4,cex=0.8)
abline(h=cums+0.5,lty=2,lwd=0.5)#draw line for diff orders
points(rmamod_nested$yi,170:1,bg=slopes$col,cex=1,pch=22)

#4. pseudo-R^2
pseudo_nested.s<-rma.mv(yi = b ~ 1, V = real_ses, random = ~1|order/g/study,data = slopes,test="t")
rsq<-(sum(pseudo_nested.s$sigma2)-sum(rmamod_nested$sigma2))/sum(pseudo_nested.s$sigma2)
#0
```

### plot result, seperately for b~v, b~p models

```{r}
vmod<-rma.mv(yi = b ~ sd_winter, V = real_ses, random = ~1|order/g/study, data = slopes,test="t") #actually the full model would sort of work here, but keeping this for consistency
summary(vmod)

#6. plot prediction + credible interval
ps<-predict.rma(vmod)

normal<- data.frame(slopes$sd_winter,ps$cr.lb,ps$ci.lb)
names(normal)<-c("sd_winter","cr","ci")
normal<-normal[order(normal$sd_winter),]
reversed<-data.frame(slopes$sd_winter,ps$cr.ub,ps$ci.ub)
names(reversed)<-c("sd_winter","cr","ci")
reversed<-reversed[order(reversed$sd_winter),]
reversed<-reversed[nrow(reversed):1,]
combined<-rbind(normal,reversed)
names(combined)<-c("sd_winter","cr","ci")

plot(x=slopes$sd_winter,y=slopes$b,pch=21,cex=0.8,col=NA, bg=slopes$col,main = "Physiological determination vs. winter variability", xlab = "Sd (winter onset)", ylab = "slope of diapause timing")
legend("topleft",pch = 21, pt.bg = 1:7,legend=unique(slopes$order)[7:1],cex=0.8)
polygon(x=combined$sd_winter, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$sd_winter, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$sd_winter,y=ps$pred,lwd=2,col="lightgray")
points(x=slopes$sd_winter,y=slopes$b,pch=21,cex=0.8,col=NA,bg=slopes$col)
#ci.lb<-ci.lb[length(ci.lb):1]
#ci.ub<-ci.ub[length(ci.ub):1]
#segments(x0=slopes$sd_winter[order(slopes$sd_winter)],x1=slopes$sd_winter[order(slopes$sd_winter)],y0=ci.lb,y1=ci.ub)

#segments(x0=slopes$sd_winter,x1=slopes$sd_winter,y0=slopes$b+slopes$real_ses,y1=slopes$b-slopes$real_ses)
axis(1)
s_est<-confint(vmod,fixed=T,random=F)$fixed[2,1]
s_est<-round(s_est,2)
rsq<-(sum(pseudo_nested.s$sigma2)-sum(vmod$sigma2))/sum(pseudo_nested.s$sigma2)
rsq=round(rsq,2)
text(25,250,paste("slope = ",s_est, " \npseudo-R² = ",rsq),cex=0.8)

##################

pmod<-rma.mv(yi = b ~ p, V = real_ses, random = ~1|order/g/study, data = slopes,test="t") 
summary(pmod)

#6. plot prediction + credible interval
ps<-predict.rma(pmod)

normal<- data.frame(slopes$p,ps$cr.lb,ps$ci.lb)
names(normal)<-c("p","cr","ci")
normal<-normal[order(normal$p),]
reversed<-data.frame(slopes$p,ps$cr.ub,ps$ci.ub)
names(reversed)<-c("p","cr","ci")
reversed<-reversed[order(reversed$p),]
reversed<-reversed[nrow(reversed):1,]
combined<-rbind(normal,reversed)
names(combined)<-c("p","cr","ci")

plot(x=slopes$p,y=slopes$b,pch=21,cex=0.8,col=NA, bg=slopes$col,main = "Physiological determination vs. winter predictability", xlab = "Unpredictability(slopes)", ylab = "slope of diapause timing")
legend("topright",pch = 21, pt.bg = 1:7,legend=unique(slopes$order)[7:1],cex=0.8)
polygon(x=combined$p, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$p, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$p,y=ps$pred,lwd=2,col="lightgray")
points(x=slopes$p,y=slopes$b,pch=21,cex=0.8,col=NA,bg=slopes$col)
#ci.lb<-ci.lb[length(ci.lb):1]
#ci.ub<-ci.ub[length(ci.ub):1]
#segments(x0=slopes$p[order(slopes$p)],x1=slopes$p[order(slopes$p)],y0=ci.lb,y1=ci.ub)

#segments(x0=slopes$p,x1=slopes$p,y0=slopes$b+slopes$real_ses,y1=slopes$b-slopes$real_ses)
axis(1)
s_est<-confint(vmod,fixed=T,random=F)$fixed[2,1]
s_est<-round(s_est,2)
rsq<-(sum(pseudo_nested.s$sigma2)-sum(pmod$sigma2))/sum(pseudo_nested.s$sigma2)
rsq=round(rsq,2)
text(1.2,300,paste("slope = ",s_est, " \npseudo-R² = ",rsq),cex=0.8)
```

## exploratory stuff
### correlation of d with winter variability/predictability

```{r d}
#get studies with meaningful d estimate
x<-slopes[slopes$study %in% c("1","5","6","6b","22","27","33","35","37","45","53","55","56","60"),]
x<-droplevels(x)
plot(x$d~x$sd_winter,pch=22,bg=x$study)
plot(x$d~x$p,pch=22,bg=x$study)

dmod<-rma.mv(yi = b ~ sd_winter, V = real_ses, random = ~1|order/g/study, data = slopes,test="t") 
```


#### forest plot and inversion  
```{r forest}
x$real_ses<-1/x$d_se
dfe<-mydeffor(x=x$d,sei=x$real_ses,annotate=F,pch=22,col=1,xlim=c(0,1.2),alim=c(0,1.2),bg=1:3,slab=NA,cex=1,rows=nrow(x):1, main = "Forest plot of upper limit estimates (from DRC)",xlab="d") #rows=nrow:1 because it plots the data in reverse order
points(x=dfe[[9]],y=1:nrow(x),col=1,bg=x$col[nrow(x):1],pch=22,cex=dfe[[10]]+0.1)
#draw line for diff orders

#plot inverse of untransformed s.e.
plot(NA,xlim=c(0,nrow(x)),ylim=c(0,30000),main = "influence of data points with untransformed s.e.")
segments(x0=1:nrow(x),y0=rep(0,nrow(x)),x1=1:nrow(x),y1=1/x$real_ses,col=x$col,lwd=1.5)

#alternative
x$expses<-exp(x$real_ses) 
plot(NA,xlim=c(0,nrow(x)),ylim=c(0,1.3),main = "influence of data points transformed s.e.")
segments(x0=1:nrow(x),y0=rep(0,nrow(x)),x1=1:nrow(x),y1=1/x$expses,col=x$col,lwd=1.5)
```


```{r}
x<-x[order(x$sd_winter),]
 plot(x$d~x$sd_winter,pch=22,bg=x$study,type="p")
for(i in unique(x$study)){
  a<-x[x$study==i,]
 
  lines(a$sd_winter,a$d,col=a$study)
}
 
 x<-x[order(x$p),]
 plot(x$d~x$p,pch=22,bg=x$study,type="p")
for(i in unique(x$study)){
  a<-x[x$study==i,]
 
  lines(a$p,a$d,col=a$study)
}
```

not much of a pattern here
```{r}
plot(slopes$b~slopes$beta)
```

not much of a pattern either
