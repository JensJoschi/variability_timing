---
title: "analysis"
author: "Jens Joschinski"
date: "April 5, 2018"
output:     
  md_document:
        variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RCurl)
library(readr)
library(data.table)
library(textreadr)
library(tidyr)
library(dplyr)
library(stringr)
library(magrittr)
library(geomapdata)
library(geosphere)
library(MASS)
library(lme4)
library(nlme)
library(metafor)
library(maps)
library(ggplot2)
```


# General description  
## Project aim  
The aim of this project is to correlate means and variance of diapause timing with climate means and climate predictability.

## Script overview  

Previous scripts calculated winter onset means and predictability based on climate station data (30k stations), and various parameters of photoperiodic response curves from published studies (~175 populations,28 studies). This script analyses these datasets.


### Specific description  

The data was generated with R version `r getRversion()` (3.44). It requires the datasets "01climate_data/03output/results.txt" and "02studies/02output/slopes_clean.txt", and the locations.txt file from the NOAA server.

In this script we do:
1. maps of winter onset and winter predictability (day length and 2x temperature)

2a. correlate critical day length (CDL) with latitude. This is not quite as the hypotheses, but allows comparison to historical data
2b. correlate day length of mean winter onset with latitude. also for comparison with historical data.

3. correlate critical day (CD) as interaction of mean winter onset and day length predictability
4. Between-treatments variance was correlated with day length predictability 5. Within-treatment variance was correlated with an interaction of day length and temperature predictabilities 
 
### statistical approaches  
The correct statistical approach should be:

estimate ~ climate data, random = (study/species/genus/order), 

with the estimate weighted by the inverse of its variance. The funnel plots showed however that inverse variance does not work, so I take the number of points on the sloped part as sample-size weighing (see manuscript and drc script). This goes in metafor with rma.mv(yi,V,W= sample_size), but is not so straight-forward. Testing with fake data how it works:

```{r test_weighing}
yi<-rnorm(120,1)
ID<-rep(1:12,each = 10)
group<-rep(1:4,each=30)
yi<-yi*ID+5*group

vi<-1/(1:120)^20 #weights would range from 1 - 10^20, if using that the model should crash
vi2<-sample(1:10,120,replace=T) #much more reasonable weights...
vi2[which(yi == min(yi))]<-0.2 #... but the lowest estimate gets very high weight, which should cause underestimation of yi

w<-rep(1,120) #using that would cause an unweighted analysis
w2<-sample(1:3,120,replace=T)
data<-data.frame(yi,vi,vi2,as.factor(ID),as.factor(group),w,w2)

M_unw<-rma.mv (yi, V=w, random = ~1|group/ID, data = data,test="t") #works and gives reasonable yi estimate
#M_crash<-rma.mv (yi, vi, random = ~1|group/ID, data = data,test="t") #does not work, which is good
#M_nocfrash<-M_crash<-rma.mv (yi, vi, W=w, random = ~1|group/ID, data = data,test="t") #does not work, which is strange
M_invvar2<-rma.mv (yi, vi2, random = ~1|group/ID, data = data,test="t") #works, but estimate is lower than real yi

M_userw<-rma.mv (yi, V= vi2, W= w,random = ~1|group/ID, data = data,test="t") #recovers unweighted case because weights are now overriding V
M_userw2<-rma.mv (yi, V= w, W= w,random = ~1|group/ID, data = data,test="t") #recovers unweighted case because weights are now overriding V
```
So I will use V = 1 and W = 1/sample_size.


What significance tests (if any) should be reported?
p-values become difficult to calculate in this analysis, because it is nested, unbalanced and weighted, so conditional F-tests are no option (GLMM-Faq by ben bolker explains that well). likelihood-ratio test should work, though it might be inaccurate for small sample sizes. Using a bootstrap version that builds its own Chisquare-like distribution works only for lmer. P is problematic to defend for meta-analyses anyway, so I will not report it. Instead I will report the estimate of the coefficient with confidence interval (Wald-Type,because profile loglik and bootstrap are not available in metafor),I² + confidence interval, pseudo-R², a forest plot, and a plot of prediction + credible intervals. 

Generally all outcome statistics are inaccurate, because they expect that variance of each point is known, but I only provide a coarse estimate of vairance that is based on a very low within-population sample size (~4-10 points to get a slope estimate). that needs to be discussed.


# Script  

## Overview of studies  

```{r load_slopes}
slopes<-read.table("02studies/02output/slopes_clean.txt",header=T,sep="\t")

table(slopes$region)
paste(n_distinct(slopes$order),"orders")
paste(n_distinct(slopes$genus),"genera")
paste(n_distinct(slopes$spec),"species")


#one of the studies has three species
slopes$ID[slopes$ID=="kimura_geogr_2"]<-"kimura_geogr_1"
slopes$ID[slopes$ID=="kimura_BJLS_2"]<-"kimura_BJLS"
slopes$ID[slopes$ID=="kimura_BJLS_3"]<-"kimura_BJLS"
slopes$ID[slopes$ID=="kimura_BJLS_4"]<-"kimura_BJLS"
slopes$ID<-droplevels(slopes$ID)
paste(nrow(slopes),"populations")
paste(n_distinct(slopes$ID),"studies")

slopes$col<-hsv((as.numeric(slopes$order)-1)/8,1,1) # 8 different colors, 1 per invertebrate order
slopes$col2<-hsv((as.numeric(slopes$order)-1)/8,0.5,1)
slopes<-slopes[order(slopes$order),]
```

## climate data  
As climate dataset I chose the parameters (5 days below 10°C), a combination that is close to e.g. halkett 2004, and results in a mean winter onset in mid-october (when many animals start their diapause)

```{r load}
url<-"ghcnd-stations.txt"
#"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
#this dataset is fixed-width delimited, requiring a few additional steps
locations<-read.fwf(
  file=url
  ,sep="!",na.strings=c("NA","-999.9"), #sep = ! because ! does not exist in dataset - > dataset is fixed-width and should have no additional separators
  widths=c(11, 9, 10, 7,2,35)
)
#reslist<-read.table("01climate_data/03output/results.txt",na.string = c("NA","-9999","-999.9"))  <-- this is with old thres of 5°C
reslist<-read.table("01climate_data/03output/results_100-5.txt",na.string = c("NA","-9999","-999.9"))
names(reslist)<-c("ID","meanwinter","sd_winter","p","nyears","ndays_300","ndays_350","ndays_365")
reslist<-reslist[1:26804,] #the same data was appended twice
climate<-merge(locations,reslist,by=1)
rm(reslist)
names(climate)<-c("ID","lat","lon","alt","name","no_idea","meanwinter","sd_winter", "p",  "nyears" ,  "ndays_300"  ,"ndays_350",  "ndays_365" )

climate<-climate[!is.na(climate$meanwinter),] #because these cannot be used anyway
beta<-read.table("01climate_data/03output/beta.txt",header=T)
climate<-merge(climate,beta,by=1)

climate<-climate[climate$lat<70,]
#calculate day length:
#Day length changes not only with latitude but also with day of year
#The correct calculation of day length at a given latitude for a given day is difficult: https://en.wikipedia.org/wiki/Sunrise_equation
#luckily there is a package that solves that.

climate$dl <- daylength(climate$lat,climate$meanwinter+182)
```


## maps  

### map of winter onset  
```{r w_on}
x<-climate$meanwinter
x<-x-min(x)
x<-x/(max(x)) #values between 0 and 1
#large values (winter is late in year, high number) should be red
#range should be: 192,0,0 (red) to 30,100,200 (blue)

r<- x * 162
r <- r + 30
g<-100 - (x * 100)
b<-200 - (x * 200)

#mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
svg("w_on_10C5d.svg",width = 14 ,height = 7,pointsize=12)
mp <- ggplot() + 
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 0), title=element_blank(), axis.text=element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), plot.margin = unit(c(0,0,0,0),units= "cm")) #or rgb(30,100,200,maxColorValue = 255)

mp+ 
  borders("world", colour="gray50", fill="gray50")+
  geom_point(aes(x=climate$lon, y=climate$lat), col = rgb(r,g,b,maxColorValue = 255), size=0.4)+
  geom_point(aes(x=slopes$degE,y=slopes$degN), col = 1, size=0.6)
dev.off()
```

### map of day length at winter onset

```{r w_dl}
x<-climate$dl
length(x[x>16])/length(x)
x[x>16]<-16
x<-24-x #x is night length now, high values = short days
#high values should be red ( winter very late in year, under very short days)

x<-x-min(x)
x<-x/(max(x)) #values between 0 and 1

r<- x * 162
r <- r + 30
g<-100 - (x * 100)
b<-200 - (x * 200)


svg("w_dl_10C5d.svg",width = 14 ,height = 7,pointsize=12)
mp <- ggplot() + 
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 0), title=element_blank(), axis.text=element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), plot.margin = unit(c(0,0,0,0),units= "cm")) #or rgb(30,100,200,maxColorValue = 255)

mp+ 
  borders("world", colour="gray50", fill="gray50")+
  geom_point(aes(x=climate$lon, y=climate$lat), col = rgb(r,g,b,maxColorValue = 255), size=0.4)+
  geom_point(aes(x=slopes$degE,y=slopes$degN), col = 1, size=0.6)
dev.off()
```
### Map of winter predictability(by day length)

Variability defined as standard deeviation of winter onset. 
```{r w_p_dl}
x<-climate$sd_winter
x[x>30]<-30 #capped to make plotting sensible
x<-x-min(x)
x<-x/(max(x)) #values between 0 and 1
#large values (high standard deviation) should be red

r<- x * 162
r <- r + 30
g<-100 - (x * 100)
b<-200 - (x * 200)

#mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
svg("w_sd_10C5d.svg",width = 14 ,height = 7,pointsize=12)
mp <- ggplot() + 
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 0), title=element_blank(), axis.text=element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), plot.margin = unit(c(0,0,0,0),units= "cm")) #or rgb(30,100,200,maxColorValue = 255)

mp+ 
  borders("world", colour="gray50", fill="gray50")+
  geom_point(aes(x=climate$lon, y=climate$lat), col = rgb(r,g,b,maxColorValue = 255), size=0.4)+
    geom_point(aes(x=slopes$degE,y=slopes$degN), col = 1, size=0.6)
dev.off()
```

### predictability by temperature 
This way of calculating winter unpredictability is the standard deviation in slopes of a temperature regression, 30 days before winter onset of each year
```{r w_p_t}
x<-climate[!is.na(climate$p),]
nrow(x[x$p>4,])/nrow(x)
x$p[x$p>4]<-4 #capped to make plotting sensible
x$p<-x$p-min(x$p)

x$p<-x$p/(max(x$p)) #values between 0 and 1
#large values (high standard deviation) should be red



r<- x$p * 162
r <- r + 30
g<-100 - (x$p * 100)
b<-200 - (x$p * 200)


svg("w_p_10C5d.svg",width = 14 ,height = 7,pointsize=12)
mp <- ggplot() + 
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 0), title=element_blank(), axis.text=element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), plot.margin = unit(c(0,0,0,0),units= "cm")) #or rgb(30,100,200,maxColorValue = 255)

mp+ 
  borders("world", colour="gray50", fill="gray50")+
  geom_point(aes(x=x$lon, y=x$lat), col = rgb(r,g,b,maxColorValue = 255), size=0.4)+
    geom_point(aes(x=slopes$degE,y=slopes$degN), col = 1, size=0.6)
dev.off()
```


### predictability as colour of noise  
```{r w_p_beta}
x<-climate[!is.na(climate$beta),]
nrow(x[x$beta>2,])/nrow(x)
x$beta[x$beta>2]<-2 #capped to make plotting sensible
x$beta[x$beta<(-2)]<-(-2) #capped to make plotting sensible
x$beta<-x$beta-min(x$beta)

x$beta<-x$beta/(max(x$beta)) #values between 0 and 1
#large values (high standard deviation) should be red



r<- x$beta * 162
r <- r + 30
g<-100 - (x$beta * 100)
b<-200 - (x$beta * 200)


svg("w_b_10C5d.svg",width = 14 ,height = 7,pointsize=12)
mp <- ggplot() + 
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 0), title=element_blank(), axis.text=element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), plot.margin = unit(c(0,0,0,0),units= "cm")) #or rgb(30,100,200,maxColorValue = 255)

mp+ 
  borders("world", colour="gray50", fill="gray50")+
  geom_point(aes(x=x$lon, y=x$lat), col = rgb(r,g,b,maxColorValue = 255), size=0.4)+
    geom_point(aes(x=slopes$degE,y=slopes$degN), col = 1, size=0.6)
dev.off()
```

### how do these climate pics change with parameters?  
The following chunk correlates day length at winter onset with latitude, for a variety of parameter combinations (currently commented out). It also saves the slope estimates
```{r sensitivity}
threshlist <-seq(0,150,5)
t2list <-c(5,10,15)
Z<-1
coeflist<-rep(NA,length(threshlist)*length(t2list))


for(threloop in 1:length(threshlist)){
  threshold<-threshlist[threloop]
  for (t2loop in 1:length(t2list)){
    t2<-t2list[t2loop]
    reslist<-read.table(paste("01climate_data/03output/results_",threshold,"-",t2,".txt",sep=""))
    names(reslist)<-c("ID","meanwinter","sd_winter","p","nyears","ndays_300","ndays_350","ndays_365")
    climate<-merge(locations,reslist,by=1)
rm(reslist)
names(climate)<-c("ID","lat","lon","alt","name","no_idea","meanwinter","sd_winter",   "p", "nyears" , "ndays_300"  ,"ndays_350",  "ndays_365" )

climate<-climate[!is.na(climate$meanwinter),] 
climate<-climate[climate$lat<70,]
climate<-climate[climate$lat>20,]


climate$expdl<-daylength(climate$lat,climate$meanwinter+182)
coeflist[Z]<-coef(lm(climate$expdl~climate$lat))[2]

#png(paste("results_",threshold,"-",t2,".png",sep=""))
#plot(climate$expdl~climate$lat,pch=22,bg=1,col=NA,cex=0.1)
#abline(lm(climate$expdl~climate$lat),col=2)
#text(x=min(climate$lat)+5,y= min(climate$expdl)+1,paste("slope:",round(coeflist[Z],2)*5))
#text(x=60,y=min(climate$expdl)+1,paste("median winter:",182+round(median(climate$meanwinter))))
#dev.off()

Z<-Z+1
}}

svg("slope_par.svg",pointsize=12)
par(mar=c(5,5,3,2)+0.1)
plot(x=threshlist/10, y=coeflist[seq(1,length(threshlist)*length(t2list),length(t2list))]*5, xlab="T threshold (°C)", ylab="Slope coefficient (h/5°N)", bty="n", type="l", lwd=3, yaxt="n", cex.lab=1.5, cex.axis=1.5,ylim=range(coeflist)*5)
for (lin in 1:length(t2list)){
  lines(x=threshlist/10,y=coeflist[seq(lin,length(threshlist)*length(t2list),length(t2list))]*5,col=col_def[lin],lwd=3,lty=lin)
}
axis(2,at=c(-0.5,0,0.5,1,1.5), cex.axis=1.5)
dev.off()
```


## Danilevskys rule  
### correlation day length at winter onset with latitude  

Danilevsky argued that organisms change their day length response by 1 hour per 5°N. Is that correct? Given the climate data, what is the optimal diapause shift with latitude?

```{r cor}
restore<-climate
climate<-climate[climate$lat>20,]

svg("corr_dl_lat_10C5d.svg")
par(mar=c(5,5,3,2)+0.1)
plot(climate$dl~climate$lat,pch=22,cex=0.2,xlab = "Latitude",ylab = "Day length at winter onset",main="",col=NA,bg=1,bty="n",yaxt="n",cex.axis=1.5,cex.lab=1.5)
axis(2,at=c(4,8,12,16,20,24),cex.axis=1.5)
M<-lm(climate$dl~climate$lat)
lines(x=c(20,70),y=coef(M)[1]+c(20,70)*coef(M)[2],lwd=4,col="darkgrey")
#text(60,8,"R² = 0.54")
dev.off()
coef(M)[2]*5

#logs<-boxcox(M,lambda=seq(-5,5,0.1))
#logs$x[which(logs$y==max(logs$y))]
pw<-climate$dl^(-4.5)
M2<-lm(pw~climate$lat)
plot(climate$dl~climate$lat,pch=22,cex=0.2,xlab = "Latitude",ylab = "Day length at winter onset",main="",col=NA,bg=1,bty="n",yaxt="n")
points(x=seq(0,70,length.out=1000),y=(coef(M2)[1]+seq(0,70,length.out = 1000)*coef(M2)[2])^(1/(-4.5)),col=2)

svg("concept.svg")
par(mar=c(5,5,3,2)+0.1)
plot(daylength(0,1:365), xlab="Julian day", ylab = "Day length", cex.axis=1.5, cex.lab=1.5, bty = "n", main="", type="l", lwd=3, ylim=c(0,24), col=hsv(0.6,1,1), xaxt="n", yaxt="n")
axis(1,at=seq(0,365,by=60),cex.axis=1.5)
axis(2,at=seq(0,24,by=2),cex.axis=1.5)

points(x=climate$meanwinter+182,y=climate$dl,cex=0.1,col=hsv(0.6,1-0.5*(climate$lat-min(climate$lat))/(max(climate$lat)-min(climate$lat)),1))#"darkgray"

lines(daylength(20,1:365),lwd=3,col=hsv(0.6,0.9,1))
lines(daylength(40,1:365),lwd=3,col=hsv(0.6,0.8,1))
lines(daylength(50,1:365),lwd=3,col=hsv(0.6,0.7,1))
lines(daylength(60,1:365),lwd=3,col=hsv(0.6,0.6,1))
lines(daylength(70,1:365),lwd=3,col=hsv(0.6,0.5,1))
points(x=rep(180,5),y=daylength(c(20,40,50,60,70),180),bg=1,pch=21)
dev.off()
climate<-restore
```
The optimal response is 0.81 h /5 degrees latitude. the curve is exponential though



### Critical day length and latitude  

Danilevsky quotes rates of 1-1.5 hours per 5°N. Let's see if that holds for the data in this meta-analysis.

#### the full model  
```{r cdl_lat_full}
#rmamod_nested<-rma.mv(yi = e ~ degN, V=rep(1,nrow(slopes)), W = npoints, random = ~1|order/genus/spec/ID, data = slopes,test="t")
rmamod_nested<-rma.mv(yi = e ~ degN, V=1/npoints, random = ~1|order/genus/spec/ID/popid, data = slopes,test="t")
summary(rmamod_nested) # species has no variance explained
profile(rmamod_nested, sigma2=1)#order
profile(rmamod_nested, sigma2=2)#order/g
profile(rmamod_nested, sigma2=3)#order/g/s #very flat
profile(rmamod_nested, sigma2=4)#order/g/s/study
profile(rmamod_nested, sigma2=5)#order/g/s/study
```

Species explains nothing because in most cases each species is replicated once (one study per species). Only 5 species occur multiple (2-3) times, usually in studies from the same authors (except O.sauteri and 1 T.urticae). To complicate things, 2 studies have 2/4 species. It is probably best to remove ID from the random structure.


#### alternative models  
```{r profplots}
#model without species
reduced<-rma.mv(yi = e ~ degN, V=1/npoints, random = ~1|order/genus/ID/popid,data = slopes)

profile(reduced, sigma2=1)#order
profile(reduced, sigma2=2)#order/g 
profile(reduced, sigma2=3)#order/g/study 
profile(reduced, sigma2=4)#order/g/study/pop

#model without study
reduced2<-rma.mv(yi = e ~ degN, V=1/npoints, random = ~1|order/genus/spec/popid,data = slopes)

profile(reduced2, sigma2=1)#order
profile(reduced2, sigma2=2)#order/g 
profile(reduced2, sigma2=3)#order/g/spec 
profile(reduced2, sigma2=4)#order/g/spec 
```

#### results  
I stick to the one without study.
estimates and conf intervals will be done with metafor package. I² makes no sense because I use sample size weighing approach. For R² I can report the nakagawa-R² (from metafor), a conditional or a marginal R². I use metafor for the conditional(?, ignores randoms), and lme for the marginal(?) pseudo-R² 
```{r degN_results}

#summary statistics
quantile(slopes$degN)
#     0%      25%      50%      75%     100% 
#25.22806 36.08056 41.15000 51.84167 67.10000 
mean(slopes$degN) #44.42637


weighted.mean(slopes$e,slopes$npoints)# 14.00758
x<-daylength(44.42637,1:360)
which(x<14.05&x>13.95) #day 229 at 44.43 °N


#modelling
rmamod_nested<-reduced2
nullmod<-rma.mv(yi = e ~ 1, V=1/npoints, random = ~1|order/genus/spec/popid, data = slopes)
coef(nullmod)#same as weighted mean

summary(rmamod_nested)

#1. estimate +ci
confint(rmamod_nested,fixed=T,random=F)
#0.2020 ( 0.1846 - 0.2193)
#=60.60 (55.38- 65.79) min

#generalized calculation of I² is described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#but it makes no sense in sample-size weighing approach

#4. pseudo-R^2
rsq<-(sum(nullmod$sigma2)-sum(rmamod_nested$sigma2))/sum(nullmod$sigma2)
rsq #0.5393216
#partial rsquares
parsq<-(nullmod$sigma2-rmamod_nested$sigma2)/nullmod$sigma2
#parsq not sensible because 0 variance explained by genus in nullmod

#alternative R2 - ignoring random
summary(lm(rmamod_nested$yi~fitted(rmamod_nested), weights = 1/rmamod_nested$vi))$adj.r.squared #0.73

#blup-based
lme<-lme(e ~ degN, random =~ 1|order/genus/spec, data=slopes, weights=~npoints, method="REML")
#level order
summary(lm(slopes$e~fitted(lme, level = 1)))$adj.r.squared#0.84
#genus
summary(lm(slopes$e~fitted(lme, level = 2)))$adj.r.squared#0.89
#species
summary(lm(slopes$e~fitted(lme, level = 3)))$adj.r.squared#0.90


n<-table(slopes$order)
names(n)<- paste(names(n)," (", n, ")", sep = "")
```
```{r}
ps<-predict(lme)
#library effects
```


#### plot  
```{r degN_plot}
#1. caculate pi and ci
ps<-predict.rma(rmamod_nested)
ub<-data.frame(slopes$degN, ps$cr.ub, ps$ci.ub)
names(ub)<-c("degN","cr","ci")
ub<-ub[order(ub$degN),]
lb<-data.frame(slopes$degN, ps$cr.lb, ps$ci.lb)
names(lb)<-c("degN","cr","ci")
lb<-lb[order(lb$degN),]
combined<-rbind(ub, lb[nrow(lb):1,])

#2. plot data
svg("CDL_lat.svg", width=10, pointsize=12)
par(mar = c(5,5,0,0) +0.1)
plot(x=slopes$degN, y=slopes$e, pch=21, cex=2*slopes$npoints/10, col=1, bg=slopes$col, main = "", xlab = "Latitude (°N)", ylab = "Critical photoperiod (h)",bty="n", xaxt="n", cex.axis = 1.5, cex.lab=1.5)


legend("topleft",legend=names(n)[8:1], col=rep(1,8), pt.bg=hsv((7:0)/8,1,1), pch=21, bty="n", ncol=1,cex=1.5)
#3. add CI and CR
polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)
#polygon(x=combined$degN, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$degN,y=ps$pred,lwd=2)
points(x=slopes$degN,y=slopes$e,pch=21,col=1,bg=slopes$col,cex=2*slopes$npoints/10)

axis(1,at=c(0,20,30,40,50,60,70,80),cex.axis=1.5, cex.lab = 1.5)

s_est<-confint(rmamod_nested,fixed=T,random=F)$fixed[2,1]*5
s_est<-round(s_est,2)
rsq=round(rsq,2)
#5 degrees latitude ~ 59 minutes
#text(50,20,paste("slope = ",s_est, " hours/5°N\npseudo-R² = ",rsq),cex=0.8)
dev.off()
```

#### alternative plot of results  

making the same plot as last one, but with lines for each order
```{r degN_plot_order}
svg("CDL_lat_order.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)

plot(x=slopes$degN, y=slopes$e, pch=21, cex=2*slopes$npoints/10, col=1, bg=slopes$col, main = "", xlab = "Latitude (°N)", ylab = "Critical photoperiod (h)",bty="n", xaxt="n", cex.axis = 1.5, cex.lab=1.5)

legend("topleft",legend=names(n)[8:1], col=rep(1,8), pt.bg=hsv((7:0)/8,1,1), pch=21, bty="n", ncol=1,cex=1.5)
#3. add CI and CR
lines(sort(slopes$degN), ub$cr, lwd=1.5, lty=3)
lines(sort(slopes$degN),lb$cr, lwd=1.5, lty=3)
#polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)

lines(x=slopes$degN,y=ps$pred,lwd=2)


axis(1,at=c(0,20,30,40,50,60,70,80),cex.axis=1.5, cex.lab = 1.5)

for(i in 1:length(unique(slopes$order))){
  sub<-slopes[slopes$order==unique(slopes$order)[i],]
  studmod<-rma.mv(yi = e ~ degN,V=1/npoints, data = sub,random = ~1|genus/ID)
  sub$pred<-predict(studmod)$pred
  #lines(sub$pred~sub$degN,col=sub$col[1],lwd=1.5 )
 lines(sub$pred~sub$degN,col=sub$col[1],lwd=1 + round(5* table(slopes$order)[i]/max(table(slopes$order))))
  
  ps<-predict.rma(studmod)
  ub<-data.frame(sub$degN,ps$cr.ub,ps$ci.ub)
  names(ub)<-c("degN","cr","ci")
  ub<-ub[order(ub$degN),]
  lb<-data.frame(sub$degN,ps$cr.lb,ps$ci.lb)
  names(lb)<-c("degN","cr","ci")
  lb<-lb[order(lb$degN),]
  combined<-rbind(ub,lb[nrow(lb):1,])
  polygon(x=combined$degN, y=combined$ci,col=hsv((as.numeric(sub$order[1])-1)/8,1,1,alpha=0.5*sqrt(table(slopes$order)[i]/max(table(slopes$order)))),border=NA)#or alpha =0.25
  print(sub$order[1])
  print (coef(studmod)[2]*5*60)
}
points(x=slopes$degN ,y=slopes$e, pch=21, col=1, bg=slopes$col, cex=2*slopes$npoints/10)


dev.off()
```

The estimate of 1 h per 5° N is not too bad, overall diapause becomes 49 min earlier per 5°.




## combining empirical data and climate

Empirical studies were not necessarily done close to a climate station. To estimate climate at a given study location, I take the average of the 5 closest stations, weighted by euclidian distance. 

```{r combine}
slopes$meanwinter<-NA
slopes$sd_winter<-NA
slopes$p<-NA
slopes$nyears<-NA
slopes$beta<-NA 

for ( i in 1:nrow(slopes)){
  #reduce to +-5 °
  sub<-climate[between(climate$lat,slopes[i,"degN"]-5,slopes[i,"degN"]+5)& between(climate$lon,slopes[i,"degE"]-5,slopes[i,"degE"]+5),]
  
  sub$diffN<-sub$lat-slopes[i,"degN"] #calculate distance in latitude
  sub$diffE<-sub$lon-slopes[i,"degE"] #same for longitude
  sub$diff<-sqrt(sub$diffN^2+sub$diffE^2) #euclidian distance

  sub<-arrange(sub,diff)[1:5,] #sort and take 5 lowest values
  

  
  slopes$meanwinter[i]<-weighted.mean(sub$meanwinter,1/sub$diff)
  slopes$sd_winter[i]<-weighted.mean(sub$sd_winter,1/sub$diff)
  slopes$p[i]<-weighted.mean(sub$p,1/sub$diff)
  slopes$nyears[i]<-weighted.mean(sub$nyears,1/sub$diff)
  slopes$beta[i]<-weighted.mean(sub$beta,1/sub$diff)

}

slopes<-slopes[!is.na(slopes$meanwinter),]
```

## correlation critical day ~ w_on * p
### calculate critical julian day
```{r critical_day}
slopes$cd<-NA
for ( i in 1:nrow(slopes)){
  x<-daylength(slopes[i,12],180:360)
  slopes$cd[i]<-which.min(abs(slopes[i,27]-x))+179
}
```

### the models
```{r}
weighting <- slopes$npoints
mod<-rma.mv(yi = cd, mods = ~ meanwinter*sd_winter , V=1/weighting, random = ~1|(order/genus/spec),data = slopes)

profile(reduced2, sigma2=1)#order
profile(reduced2, sigma2=2)#order/g 
profile(reduced2, sigma2=3)#order/g/spec 

red<-rma.mv(yi = cd ~ meanwinter+sd_winter, V=1/weighting, random = ~1|(order/genus/spec),data = slopes)
red2<-rma.mv(yi = cd ~ meanwinter, V=1/weighting, random = ~1|order/genus/spec,data = slopes)
red3<-rma.mv(yi = cd ~ sd_winter, V=1/weighting, random = ~1|order/genus/spec,data = slopes)

nullmod      <-rma.mv(yi = cd,          V=1/weighting, random = ~1|(order/genus/spec), data = slopes)

lmemod<- lme(cd ~ meanwinter * sd_winter, random =~ 1|order/genus/spec, data=slopes, weights=~npoints, method="ML")
lmemod2<- lme(cd ~ meanwinter + sd_winter, random =~ 1|order/genus/spec, data=slopes, weights=~npoints, method="ML")
lmemod3<- lme(cd ~ meanwinter             , random =~ 1|order/genus/spec, data=slopes, weights=~npoints, method="ML")
lmemod4<- lme(cd ~              sd_winter, random =~ 1|order/genus/spec, data=slopes, weights=~npoints, method="ML")
lmenull<-lme(cd ~              1, random =~ 1|order/genus/spec, data=slopes, weights=~npoints, method="ML")
anova(lmemod,lmemod2)
anova(lmemod2,lmemod3)
anova(lmemod2,lmemod4)

plot(slopes$cd~slopes$meanwinter,pch=21,bg=slopes$order,ylim=c(150,350))
for(i in 1:length(unique(slopes$order))){
  x<-slopes$meanwinter[slopes$order==unique(slopes$order)[i]]
  y<-fitted(lmemod2)[slopes$order==unique(slopes$order)[i]]
points(x,y,col=i,cex=1.5)}
plot(fitted(red)~slopes$meanwinter,col=slopes$order,ylim=c(200,350))
plot(fitted(lmemod2)~slopes$meanwinter,pch=21,bg=slopes$order,ylim=c(150,350))
new<-rma.mv(yi = cd,V=ese, mods= ~ meanwinter, random =~ 1|order,data = slopes)
```

#### cd vs w_on  
```{r cdwon_results}
#summary statistics
quantile(slopes$meanwinter)
#  0%       25%       50%       75%      100% 
# 36.32246  95.82095 119.08168 138.79421 203.65533 
mean(slopes$meanwinter) #115.2439
weighted.mean(slopes$cd,slopes$npoints)# 239.2126

#1. estimate +ci
confint(mod,fixed=T,random=F)

#4. pseudo-R^2
rsq<-(sum(nullmod$sigma2)-sum(mod$sigma2))/sum(nullmod$sigma2)
rsq #0
#alternative R2
summary(lm(mod$yi~fitted(mod), weights = 1/mod$vi))$adj.r.squared

parsq<-(nullmod$sigma2-mod$sigma2)/nullmod$sigma2
parsq
n<-table(slopes$order)
names(n)<- paste(names(n)," (", n, ")", sep = "")
```

#### plot cd ~ meanwinter

```{r cdwon}
svg("cd_won.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)

ps<-predict.rma(red2)
ub<-data.frame(slopes$meanwinter, ps$cr.ub, ps$ci.ub)
names(ub)<-c("meanwinter","cr","ci")
ub<-ub[order(ub$meanwinter),]
lb<-data.frame(slopes$meanwinter, ps$cr.lb, ps$ci.lb)
names(lb)<-c("meanwinter","cr","ci")
lb<-lb[order(lb$meanwinter),]
combined<-rbind(ub, lb[nrow(lb):1,])

plot(x=slopes$meanwinter, y=slopes$cd, pch=21, cex=2*slopes$npoints/10, col=1, bg=slopes$col, main = "", xlab = "Winter onset", ylab = "Critical day",bty="n", xaxt="n", cex.axis = 1.5, cex.lab=1.5)

legend("topleft",legend=names(n)[8:1], col=rep(1,8), pt.bg=hsv((7:0)/8,1,1), pch=21, bty="n", ncol=1,cex=1.5)
#3. add CI and CR
lines(sort(slopes$meanwinter), ub$cr, lwd=1.5, lty=3)
lines(sort(slopes$meanwinter),lb$cr, lwd=1.5, lty=3)
#polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)

lines(x=slopes$meanwinter,y=ps$pred,lwd=2)


axis(1,at=seq(30,210,length.out=7),cex.axis=1.5, cex.lab = 1.5)

for(i in 1:length(unique(slopes$order))){
  sub<-slopes[slopes$order==unique(slopes$order)[i],]
  studmod<-rma.mv(yi = cd ~ meanwinter, V=1/npoints, data = sub,random = ~1|genus/spec)
  sub$pred<-predict(studmod)$pred
  #lines(sub$pred~sub$degN,col=sub$col[1],lwd=1.5 )
 lines(sub$pred~sub$meanwinter,col=sub$col[1],lwd=1 + round(5* table(slopes$order)[i]/max(table(slopes$order))))
  
  ps<-predict.rma(studmod)
  ub<-data.frame(sub$meanwinter,ps$cr.ub,ps$ci.ub)
  names(ub)<-c("meanwinter","cr","ci")
  ub<-ub[order(ub$meanwinter),]
  lb<-data.frame(sub$meanwinter,ps$cr.lb,ps$ci.lb)
  names(lb)<-c("meanwinter","cr","ci")
  lb<-lb[order(lb$meanwinter),]
  combined<-rbind(ub,lb[nrow(lb):1,])
  polygon(x=combined$meanwinter, y=combined$ci,col=hsv((as.numeric(sub$order[1])-1)/8,1,1,alpha=0.5*sqrt(table(slopes$order)[i]/max(table(slopes$order)))),border=NA)#or alpha =0.25
  print(sub$order[1])
  print (coef(studmod)[2]*5*60)
}
points(x=slopes$meanwinter ,y=slopes$cd, pch=21, col=1, bg=slopes$col, cex=2*slopes$npoints/10)


dev.off()
```




### within vs between treat variance  
```{r varwithbet}
par(mfrow=c(1,1))
x<-(slopes$sd_winter>14)+1
plot(y=slopes$within,x=slopes$between,pch=21,col=NA,bg=x,xlab = "between-treatment variance",ylab="within-treatment variance")
points(y=slopes$within[x==2], x = slopes$between[x==2],pch=21,bg=2)

x<-(slopes$sd_winter-min(slopes$sd_winter))/(max(slopes$sd_winter)-min(slopes$sd_winter))
plot(y=slopes$within,x=slopes$between,pch=21,col=NA,bg=hsv(1,1-x,1),xlab = "between-treatment variance",ylab="within-treatment variance",ylim = c(0,250))

logcurve<-function(x,b,c,d,e){(d-c)/(1+exp(-b*(x-e)))+c}
x<-seq(12-4, 12+4, length.out =1000)

w<-rep(NA,100)
bet<-rep(NA,100)
for ( i in 0:999){
 y_a<-logcurve(x,b=i/20,c= 0,d=1,e=12)
    w[i]<-sum(y_a*(1-y_a))
    bet[i]<- (sd(y_a)/(sqrt(length(y_a))))^2
}
segments(x0 = bet[1:999],y0 = w[1:999],x1 = bet[2:1000],y1 = w[2:1000],lwd=3,col="grey") #this line shows varying slopes for c,d = 0,1; it is also the outer parameter space

for ( i in 0:999){
 y_a<-logcurve(x,b=100,c= 0,d=i/1000,e=12)
    w[i]<-sum(y_a*(1-y_a))
    bet[i]<- (sd(y_a)/(sqrt(length(y_a))))^2
}
segments(x0 = bet[1:999],y0 = w[1:999],x1 = bet[2:1000],y1 = w[2:1000],lwd=3,col="grey") # this line shows varing d for max slope


for ( i in 0:999){
 y_a<-logcurve(x,b=100,c= 0.5-(5*i/1000),d=0.5+(5*i/1000),e=12)
    w[i]<-sum(y_a*(1-y_a))
    bet[i]<- (sd(y_a)/(sqrt(length(y_a))))^2
}
#segments(x0 = bet[1:999],y0 = w[1:999],x1 = bet[2:1000],y1 = w[2:1000],lwd=3,col="grey") # this line shows varing range for max slope

x<-(slopes$sd_winter-min(slopes$sd_winter))/(max(slopes$sd_winter)-min(slopes$sd_winter))
#points(y=slopes$within,x=slopes$between,pch=21,col=NA,bg=hsv(1,1-x,1))
#points(points(w_a~bet_a,col=4,pch=22,bg=4))
#text(x=bet_a+0.00001,y= w_a, "C")
#points(points(w_b~bet_b,col=4,pch=22,bg=4))
#text(x=bet_b+0.00001,y= w_b, "B")
#points(points(w_c~bet_c,col=4,pch=22,bg=4))
#text(x=bet_c+0.00001,y= w_c, "D")
#points(points(w_d~bet_d,col=4,pch=22,bg=4))
#text(x=bet_d-0.00001,y= w_d, "A")

x<-seq(12-4, 12+4, length.out =1000)
plot(y=slopes$within,x=slopes$between,pch=21,col=NA,bg=1,xlab = "between-treatment variance",ylab="within-treatment variance",ylim = c(0,250))
for( i in 0:10){
  for (j in 0:10){
    for (k in 0:10){
      y_a<-logcurve(x,b=i*2,c=j/10,d=k/10,e=12)
    points(y= sum(y_a*(1-y_a)), x = (sd(y_a)/(sqrt(length(y_a))))^2, pch=21,bg=1)
    }
  }
}

x<-(slopes$sd_winter-min(slopes$sd_winter))/(max(slopes$sd_winter)-min(slopes$sd_winter))
points(y=slopes$within,x=slopes$between,pch=21,col=NA,bg=hsv(1,1-x,1))

x<-seq(12-4, 12+4, length.out =1000)
y_a<-logcurve(x,b=0,c=0.5,d=0.5,e=12)
y_b<-logcurve(x,b=100,c=0.1,d=0.9,e=12)
y_c<-logcurve(x,b=0,c=0,d=0.1,e=12)
y_d<-logcurve(x,b=100,c=0,d=1,e=12)

w_a<-sum(y_a*(1-y_a))
w_b<-sum(y_b*(1-y_b))
w_c<-sum(y_c*(1-y_c))
w_d<-sum(y_d*(1-y_d))

bet_a <- (sd(y_a)/(sqrt(length(y_a))))^2
bet_b <- (sd(y_b)/(sqrt(length(y_b))))^2
bet_c <- (sd(y_c)/(sqrt(length(y_c))))^2
bet_d <- (sd(y_d)/(sqrt(length(y_d))))^2



par(mfrow=c(2,2),mar=c(2,2,2,2))
plot(y_a~x,type="l",ylim=c(0,1),lwd=2)
text(13,0.1,paste("within:",round(w_a,2)))
text(13,0,paste("between:",round(bet_a,5)))
plot(y_b~x,type="l",ylim=c(0,1),lwd=2)
text(13,0.1,paste("within:",round(w_b,2)))
text(13,0,paste("between:",round(bet_b,5)))
plot(y_c~x,type="l",ylim=c(0,1),lwd=2)
text(13,0.1,paste("within:",round(w_c,2)))
text(13,0,paste("between:",round(bet_c,5)))
plot(y_d~x,type="l",ylim=c(0,1),lwd=2)
text(13,0.1,paste("within:",round(w_d,2)))
text(13,0,paste("between:",round(bet_d,5)))

```

## correlation of CDL with mean winter onset

The following chunk is mostly a copy of the earlier analysis of cdl~latitude. Only this time it is the cdl ~dl at winter onset

```{r profile_xpdl}
slopes$expdl<-daylength(slopes$degN,slopes$meanwinter+182)
slopes$var_e<-1/slopes$invvar_e
cdl_cor<-rma.mv(yi = e ~ expdl, V = var_e, random = ~1|order/genus/ID,data = slopes)
summary(cdl_cor)
profile(cdl_cor, sigma2=1)#order
profile(cdl_cor, sigma2=2)#order/g #linear increase no maximum
profile(cdl_cor, sigma2=3)#order/g/study 
#this does not work. simplified model required
cdl_cor2<-rma.mv(yi = e ~ expdl, V = var_e, random = ~1|order/ID,data = slopes) 
profile(cdl_cor2,sigma2=1)
profile(cdl_cor2,sigma2=2)
```

```{r xpdl_results}

#1. estimate +ci
confint(cdl_cor2,fixed=T,random=F)

#2. I² 
W <- diag(1/slopes$var_e)
X <- model.matrix(cdl_cor2)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W #generalized calculation of I² as described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#overall I² (using sum of sigmas)

100 * sum(cdl_cor2$sigma2) / (sum(cdl_cor2$sigma2) + (cdl_cor2$k-cdl_cor2$p)/sum(diag(P)))
#I² of each level
round(100 * cdl_cor2$sigma2 / (sum(cdl_cor2$sigma2) + (cdl_cor2$k-cdl_cor2$p)/sum(diag(P))),4)
#heterogeneity is apparently 99.93%, 10%due to order and 89.6% due to ID


#4. pseudo-R^2
pseudo_nested<-rma.mv(yi=e~1, V = var_e, random = ~1|order/ID,data = slopes) 
rsq<-(sum(pseudo_nested$sigma2)-sum(cdl_cor2$sigma2))/sum(pseudo_nested$sigma2)
#0.68

#plot (as inlay for cdl~degN fig)
ps<-predict.rma(cdl_cor2)
normal<- data.frame(slopes$expdl,ps$cr.lb,ps$ci.lb)
names(normal)<-c("expdl14","cr","ci")
normal<-normal[order(normal$expdl),]
reversed<-data.frame(slopes$expdl,ps$cr.ub,ps$ci.ub)
names(reversed)<-c("expdl14","cr","ci")
reversed<-reversed[order(reversed$expdl),]
reversed<-reversed[nrow(reversed):1,]
combined<-rbind(normal,reversed)
names(combined)<-c("expdl14","cr","ci")


svg("inlay_e_expdl.svg",pointsize=12,width=10)
plot(slopes$e~slopes$expdl,pch=21,cex=1.2,bg=1,xlab = "Expected day length", ylab = "Empirical day length",cex.axis=1.2,main = "",cex.lab=1.2,bty="n")
polygon(x=combined$expdl, y=combined$cr,col="lightgrey",border=NA)
polygon(x=combined$expdl, y=combined$ci,col="darkgrey",border=NA)
points(slopes$e~slopes$expdl,pch=21,cex=1.2,bg=1)
lines(x=slopes$expdl,y=ps$pred,lwd=2)
#this plot could be used as inlay for CDL~degN plot
dev.off()

#plot (as unique fig)
names(n)<- paste(unique(slopes$order)," (", table(slopes$order), ")", sep = "")

svg("CDL_xpdl.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)


plot(x=slopes$expdl,y=slopes$e,pch=22,cex=1.3,col=NA, bg=slopes$col,main = "", xlab = "Day length at winter onset", ylab = "Critical photoperiod (h)",bty="n",xaxt="n",cex.lab=1.5,cex.axis=1.5)

legend("bottomright",legend=names(n)[1:8],col=rep(1,8),pt.bg=hsv((7:0)/8,1,1)[8:1],pch=22,bty="n",ncol=1,cex=1.3,y.intersp=0.8)

#3. add CI and CR
#points(x=slopes$expdl,y=slopes$e,pch=22,cex=1.3,col=NA,bg=slopes$col)

cv<-qnorm(0.05/2,lower.tail=F)*slopes$ese
segments(x0=slopes$expdl,x1=slopes$expdl,y0=slopes$e-cv,y1=slopes$e+cv,col="darkgray")
axis(1,at=c(10,12,14,16,18))

for(i in 1:length(unique(slopes$order))){
  sub<-slopes[slopes$order==unique(slopes$order)[i],]
  studmod<-rma.mv(yi = e ~ expdl, V = var_e, data = sub,random = ~1|ID)
  sub$pred<-predict(studmod)$pred
  lines(sub$pred~sub$expdl,col=sub$col[1],lwd=1 + round(5* table(slopes$order)[i]/max(table(slopes$order))))
  
  ps<-predict.rma(studmod)
  ub<-data.frame(sub$expdl,ps$cr.ub,ps$ci.ub)
  names(ub)<-c("degN","cr","ci")
  ub<-ub[order(ub$degN),]
  lb<-data.frame(sub$expdl,ps$cr.lb,ps$ci.lb)
  names(lb)<-c("degN","cr","ci")
  lb<-lb[order(lb$degN),]
  combined<-rbind(ub,lb[nrow(lb):1,])
  polygon(x=combined$degN, y=combined$ci,col=hsv((as.numeric(sub$order[1])-1)/8,1,1,alpha=0.2),border=NA)
 # print(sub$order[1])
 # print (coef(studmod)[2]*5*60)
}
dev.off()
```



## slope and winter variability/predictability
slopes is expected to correlate with variability and predictability. predictability is here defined as sd(slopes) of temperature right before winter onset.


```{r forest_b}
#mostly copy of forest plot cdl.

#code snippet to make cex of each point proportional to inverse of variance
wi <- 1/sqrt(1/slopes$invvar_b)
psize <- wi/sum(wi, na.rm = TRUE)
psize <- (psize - min(psize, na.rm = TRUE))/(max(psize, na.rm = TRUE) - min(psize, na.rm = TRUE))
psize <- (psize * 1) + 0.5


#make gaps between orders
#first, calculate y-value: midpoint of each order
n<-table(slopes$order)
cums<-cumsum(as.numeric(n))
cums<-c(0,cums)
cums<-nrow(slopes)-cums
c2<-NA
for(i in 1:(length(cums)-1)){
  c2[i]<-mean(c(cums[i],cums[i+1]))
}

#idea: get a vector "s" of form 1,2,3,4,4.1,4.2,4.3,5 if the gap is inserted at 4
#then plot data between 1:length(s), with data only on non-decimal places
gaplength=10
s<-nrow(slopes):1
for(i in 1:8){
s<-c(s,seq(cums[i+1]+0.2,cums[i+1]+0.9,length.out=gaplength))
}
s<-s[order(s,decreasing=F)]
vec <- which(s%%1==0)


#start plotting

svg("forest_b.svg",pointsize=12,height=7,width=7/3)
par(mar=c(5,1,0,1)+0.1)
xlim<-c(0,230)
plot(x=slopes$b, y=vec[length(vec):1], pch=slopes$pch, bg=slopes$col, cex=psize, xlim=xlim, xlab="Slope of reaction norm", bty="n", yaxt="n", ylab="", cex.lab=1, cex.axis=1)

#4. lines for confidence intervals (calculation from forest.default)
cv<-qnorm(0.05/2,lower.tail=F)*slopes$bse
ci_l<-slopes$b-cv
ci_u<-slopes$b+cv
num<-nrow(slopes)

for (i in 1: nrow(slopes)){
  lines(x=c(ci_l[num-i+1],ci_u[num-i+1]),y=c(vec[i],vec[i]))
  if (ci_l[num-i+1] < xlim[1]){
    arrows(xlim[1],vec[i],xlim[1]-10,vec[i],col=1,xpd=T,length = 1/nrow(slopes) * 10)
  }
   if (ci_u[num-i+1] > xlim[2]){
    arrows(xlim[2],vec[i],xlim[2]+10,vec[i],col=1,xpd=T,length = 1/nrow(slopes) * 10)
  }
}

#5. points again so they are in foreground
points(x=slopes$b,y=vec[length(vec):1],bg=slopes$col,pch=slopes$pch,cex=psize,col=1)

#6. legend



#printing of legend
#points(x= rep(5.1,8),y=c2,pch=22,bg=hsv((1:8-1)/8,1,1),cex=0.8)
#text(x=5,y=c2,labels=names(n),pos=4,bty="n",cex=0.8)

#diamonds
m_b<-mean(slopes$b)
se<-sd(slopes$b)/sqrt(nrow(slopes))
m_v<-qnorm(0.05/2,lower.tail=F)*se
polygon(x=c(m_e-m_v, m_e, m_e+m_v, m_e),y=c(-18,-15,-18,-21),xpd=T,lwd=2,col="darkgrey")

#by order
gaps <- which(s%%1!=0)[seq(gaplength/2,gaplength*8,gaplength)]

for(i in 1:length(unique(slopes$order))){
sub<-slopes[slopes$order ==unique(slopes$order)[i],]
m_e<-mean(sub$b)
se<-sd(sub$b)/sqrt(nrow(sub))
m_v<-qnorm(0.05/2,lower.tail=F)*se
polygon(x=c(m_e-m_v, m_e, m_e+m_v, m_e), y=c(gaps[9-i],gaps[9-i]+2,gaps[9-i],gaps[9-i]-2), xpd=T, lwd=1, col=unique(slopes$col2)[i])
}

dev.off()

```

### mean timing vs sd(winter), ~ p and slopes ~ lat  (makes no sense, but just to be sure)
```{r nonsense}

rmamod_nested<-rma.mv(yi = e ~ sd_winter, V = var_e, random = ~1|order/genus/ID, data = slopes,test="t")
pseudo_nested<-rma.mv(yi = e ~ 1, V =var_e , random = ~1|order/genus/ID,data = slopes,test="t")
paste("Rsquare e~sd: ", (sum(pseudo_nested$sigma2) - sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2))
#0

rmamod_nested<-rma.mv(yi = e ~ p, V = var_e, random = ~1|order/genus/ID, data = slopes,test="t")
paste("Rsquare e~p: ", (sum(pseudo_nested$sigma2) - sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2))
#0

slopes$var_b<-1/slopes$invvar_b
rmamod_nested<-rma.mv(yi = b ~ degN, V = var_b, random = ~1|order/genus/spec/ID, data = slopes,test="t")
pseudo_nested<-rma.mv(yi = b ~ 1, V =var_b , random = ~1|order/genus/ID,data = slopes,test="t")
paste("Rsquare slope~latitude: ", (sum(pseudo_nested$sigma2) - sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2))
#0
```


## the real slope model  
```{r b_var}
slopes$var_b<-1/slopes$invvar_b
rmamod_nested<-rma.mv(yi = b ~ sd_winter, V = var_b, random = ~1|order/genus/spec/ID, data = slopes,test="t")
rmamod_rednested<-rma.mv(yi = b ~ sd_winter, V = var_b, random = ~1|order/genus/ID,data = slopes)
rmamod_rednested2<-rma.mv(yi = b ~ sd_winter, V = var_b, random = ~1|order/genus/spec,data = slopes) 
rmamod_nested<-rmamod_rednested #ok in this case order also explains nearly no variance. Leave it in for consistency anyway

#1. estimate +ci
confint(rmamod_nested,fixed=T,random=F)

#2. I² 
W <- diag(1/slopes$var_b)
X <- model.matrix(rmamod_nested)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W #generalized calculation of I² as described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#overall I² (using sum of sigmas)

100 * sum(rmamod_nested$sigma2) / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P)))
#I² of each level
round(100 * rmamod_nested$sigma2 / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P))),4)
#heterogeneity is 0%, 91%, and 9% due to order/genus/ID


#4. pseudo-R^2
pseudo_nested<-rma.mv(yi = b ~ 1, V =var_b , random = ~1|order/genus/ID,data = slopes,test="t")
rsq<-(sum(pseudo_nested$sigma2)-sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2)
#0.06


#6. plot prediction + credible interval
#6.1. caculate pi and ci
ps<-predict.rma(rmamod_nested)
ub<-data.frame(slopes$sd_winter,ps$cr.ub,ps$ci.ub)
names(ub)<-c("degN","cr","ci")
ub<-ub[order(ub$degN),]
lb<-data.frame(slopes$sd_winter,ps$cr.lb,ps$ci.lb)
names(lb)<-c("degN","cr","ci")
lb<-lb[order(lb$degN),]
combined<-rbind(ub,lb[nrow(lb):1,])

#2. plot data
plot(x=slopes$sd_winter,y=slopes$b,pch=slopes$pch,cex=0.8,col=NA, bg=slopes$col,main = "", xlab = "Winter variability", ylab = "Slope estimate",bty="n",xaxt="n")
legend("topleft",legend=names(n)[8:1],col=rep(1,8),pt.bg=hsv((7:0)/8,1,1),pch=22,bty="n",ncol=1,cex=0.8)
#3. add CI and CR
polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)
#polygon(x=combined$degN, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$sd_winter,y=ps$pred,lwd=2)
points(x=slopes$sd_winter,y=slopes$b,pch=slopes$pch,cex=0.8,col=NA,bg=slopes$col)

segments(x0=slopes$sd_winter, x1=slopes$sd_winter, y0=slopes$b-1.96*slopes$bse, y1=slopes$b+1.96*slopes$bse)
axis(1)

s_est<-confint(rmamod_nested,fixed=T,random=F)$fixed[2,1]*5
s_est<-round(s_est,2)
rsq=round(rsq,2)
#5 degrees latitude ~ 1 hour
#text(50,20,paste("slope = ",s_est, " hours/5°N\npseudo-R² = ",rsq),cex=0.8)

```

```{r plot_b_var}

names(n)<- paste(unique(slopes$order)," (", table(slopes$order), ")", sep = "")

svg("b_var.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)


plot(x=slopes$sd_winter, y=slopes$b, pch=22, cex=1.5, col=NA,  bg=slopes$col, main = "",  xlab = "Winter variabliity", ylab = "Slope estimate",bty="n",xaxt="n",cex.lab=1.5,cex.axis=1.5,ylim = c(0,330))

legend("topright",legend=names(n)[1:8],col=rep(1,8),pt.bg=hsv((7:0)/8,1,1)[8:1],pch=22,bty="n",ncol=1,cex=1.3,y.intersp=0.8)

#3. add CI and CR
points(x=slopes$sd_winter,y=slopes$b,pch=22,cex=1.5,col=NA,bg=slopes$col)

cv<-qnorm(0.05/2,lower.tail=F)*slopes$bse
segments(x0=slopes$sd_winter, x1=slopes$sd_winter, y0=slopes$b-cv, y1=slopes$b+cv, col="darkgray")
axis(1,cex.axis=1.5)

for(i in 1:length(unique(slopes$order))){
  sub<-slopes[slopes$order==unique(slopes$order)[i],]
  studmod<-rma.mv(yi = b ~ sd_winter, V = var_b, data = sub,random = ~1|genus/ID)
  sub$pred<-predict(studmod)$pred
  lines(sub$pred~sub$sd_winter,col=sub$col[1],lwd=1 + round(5* table(slopes$order)[i]/max(table(slopes$order))))
  
  ps<-predict.rma(studmod)
  ub<-data.frame(sub$sd_winter,ps$cr.ub,ps$ci.ub)
  names(ub)<-c("degN","cr","ci")
  ub<-ub[order(ub$degN),]
  lb<-data.frame(sub$sd_winter,ps$cr.lb,ps$ci.lb)
  names(lb)<-c("degN","cr","ci")
  lb<-lb[order(lb$degN),]
  combined<-rbind(ub,lb[nrow(lb):1,])
  polygon(x=combined$degN, y=combined$ci,col=hsv((as.numeric(sub$order[1])-1)/8,1,1,alpha=0.2),border=NA)
  print(sub$order[1])
  print (coef(studmod)[2])
}



dev.off()
```

```{r b_p}
restore<-slopes
slopes<-slopes[!is.na(slopes$p),]
rmamod_nested<-rma.mv(yi = b ~ p, V = var_b, random = ~1|order/genus/spec/ID, data = slopes,test="t")
rmamod_rednested<-rma.mv(yi = b ~ p, V = var_b, random = ~1|order/genus/ID,data = slopes)
rmamod_rednested2<-rma.mv(yi = b ~ p, V = var_b, random = ~1|order/genus/spec,data = slopes) 
rmamod_nested<-rmamod_rednested #ok in this case order also explains nearly no variance. Leave it in for consistency anyway

#1. estimate +ci
confint(rmamod_nested,fixed=T,random=F)

#2. I² 
W <- diag(1/slopes$var_b)
X <- model.matrix(rmamod_nested)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W #generalized calculation of I² as described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#overall I² (using sum of sigmas)

100 * sum(rmamod_nested$sigma2) / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P)))
#I² of each level
round(100 * rmamod_nested$sigma2 / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P))),4)
#heterogeneity is 0%, 92%, and 8% due to order/genus/ID


#4. pseudo-R^2
pseudo_nested<-rma.mv(yi = b ~ 1, V =var_b , random = ~1|order/genus/ID,data = slopes,test="t")
rsq<-(sum(pseudo_nested$sigma2)-sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2)
# 0.02505739  


#6. plot prediction + credible interval
#6.1. caculate pi and ci
ps<-predict.rma(rmamod_nested)
ub<-data.frame(slopes$p,ps$cr.ub,ps$ci.ub)
names(ub)<-c("degN","cr","ci")
ub<-ub[order(ub$degN),]
lb<-data.frame(slopes$p,ps$cr.lb,ps$ci.lb)
names(lb)<-c("degN","cr","ci")
lb<-lb[order(lb$degN),]
combined<-rbind(ub,lb[nrow(lb):1,])

#2. plot data
plot(x=slopes$p,y=slopes$b,pch=slopes$pch,cex=0.8,col=NA, bg=slopes$col,main = "", xlab = "Winter predictability", ylab = "Slope estimate",bty="n",xaxt="n")
legend("topright",legend=names(n)[8:1],col=rep(1,8),pt.bg=hsv((7:0)/8,1,1),pch=22,bty="n",ncol=1,cex=0.8)
#3. add CI and CR
polygon(x=combined$degN, y=combined$cr,col="lightgrey",border=NA)
#polygon(x=combined$degN, y=combined$ci,col="darkgrey",border=NA)
lines(x=slopes$p,y=ps$pred,lwd=2)
points(x=slopes$p,y=slopes$b,pch=slopes$pch,cex=0.8,col=NA,bg=slopes$col)

segments(x0=slopes$p, x1=slopes$p, y0=slopes$b-1.96*slopes$bse, y1=slopes$b+1.96*slopes$bse)
axis(1)

s_est<-confint(rmamod_nested,fixed=T,random=F)$fixed[2,1]*5
s_est<-round(s_est,2)
rsq=round(rsq,2)
#5 degrees latitude ~ 1 hour
#text(50,20,paste("slope = ",s_est, " hours/5°N\npseudo-R² = ",rsq),cex=0.8)

```

```{r plot_b_p}

svg("b_p.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)


plot(x=slopes$p, y=slopes$b, pch=22, cex=1.5, col=NA,  bg=slopes$col, main = "",  xlab = "Winter unpredictabliity", ylab = "Slope estimate",bty="n",xaxt="n",cex.lab=1.5,cex.axis=1.5,ylim = c(0,330),xaxt="n")
axis(1,at=c(0, 0.5, 1, 1.5, 2, 2.5),cex.axis=1.5)
legend("topright",legend=names(n)[1:8],col=rep(1,8),pt.bg=hsv((7:0)/8,1,1)[8:1],pch=22,bty="n",ncol=1,cex=1.3,y.intersp=0.8)

#3. add CI and CR
points(x=slopes$p,y=slopes$b,pch=22,cex=1.5,col=NA,bg=slopes$col)

cv<-qnorm(0.05/2,lower.tail=F)*slopes$bse
segments(x0=slopes$p, x1=slopes$p, y0=slopes$b-cv, y1=slopes$b+cv, col="darkgray")
axis(1,cex.axis=1.5)

for(i in 1:length(unique(slopes$order))){
  sub<-slopes[slopes$order==unique(slopes$order)[i],]
  studmod<-rma.mv(yi = b ~ p, V = var_b, data = sub,random = ~1|genus/ID)
  sub$pred<-predict(studmod)$pred
  lines(sub$pred~sub$p,col=sub$col[1],lwd=1 + round(5* table(slopes$order)[i]/max(table(slopes$order))))
  
  ps<-predict.rma(studmod)
  ub<-data.frame(sub$p,ps$cr.ub,ps$ci.ub)
  names(ub)<-c("degN","cr","ci")
  ub<-ub[order(ub$degN),]
  lb<-data.frame(sub$p,ps$cr.lb,ps$ci.lb)
  names(lb)<-c("degN","cr","ci")
  lb<-lb[order(lb$degN),]
  combined<-rbind(ub,lb[nrow(lb):1,])
  polygon(x=combined$degN, y=combined$ci, col=hsv((as.numeric(sub$order[1])-1)/8,1,1,alpha=0.2),border=NA)
  print(sub$order[1])
  print (coef(studmod)[2])
}



dev.off()
```

### model slopes ~ variability * predictability

```{r interaction}
rmamod_nested<-rma.mv(yi = b ~ sd_winter*p, V = var_b, random = ~1|order/genus/spec/ID, data = slopes,test="t")
pseudo_nested<-rma.mv(yi = b ~ 1, V =var_b , random = ~1|order/genus/ID,data = slopes,test="t")
rsq<-(sum(pseudo_nested$sigma2)-sum(rmamod_nested$sigma2))/sum(pseudo_nested$sigma2)
rsq#0.07
```


```{r slope_results}
slopesbackup<-slopes
slopes<-slopes[!is.na(slopes$b),]
slopes<-slopes[!is.na(slopes$p),]
rmamod_nested<-slopes_vp.s
summary(rmamod_nested)
#comparing to lmes
summary(lme(b~sd_winter*p, random =~ 1|order/g/study,data=slopes,weights=~real_ses))#different (better) df estimate, different coefs but same direction

#1. estimate +ci
confint(rmamod_nested,fixed=T,random=F)
#2. I² 
W <- diag(1/slopes$real_ses)
X <- model.matrix(rmamod_nested)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W #generalized calculation of I² as described in http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
#overall I² (using sum of sigmas)

100 * sum(rmamod_nested$sigma2) / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P)))
#I² of each level
round(100 * rmamod_nested$sigma2 / (sum(rmamod_nested$sigma2) + (rmamod_nested$k-rmamod_nested$p)/sum(diag(P))),4)
#99% heterogeneity, 79% due to genus. though not sure whehter calculation works for interaction


#3. forest plot #this version plots predictions + CI as whiskers
#forest plot sorted by order 
yi<-rmamod_nested$yi
vicorr<-slopes[nrow(slopes):1,"real_ses"]

ci.ub<-yi + qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.lb<-yi - qnorm(0.05/2, lower.tail = FALSE) * sqrt(vicorr)
ci.ub<-ci.ub[length(ci.ub):1]
ci.lb<-ci.lb[length(ci.lb):1]
#this time there was no transformation of s.e. so the normal forest plot function can be used 

forest.rma(rmamod_nested,addcred=T,addfit=T,cex.axis=1,cex.lab=2,cex=1,slab=NA,annotate=F,order=1:170, xlim=c(-90,300),main = "Forest plot, sorted by phylogeny",xlab = "slope",alim=c(-100,350))

#needs cex of each point
text(x=-30,y=c2,labels=names(n),pos=4,cex=0.8)
abline(h=cums+0.5,lty=2,lwd=0.5)#draw line for diff orders
points(rmamod_nested$yi,159:1,bg=slopes$col,cex=1,pch=22)

#4. pseudo-R^2
pseudo_nested.s<-rma.mv(yi = b ~ 1, V = real_ses, random = ~1|order/g/study,data = slopes,test="t")
rsq<-(sum(pseudo_nested.s$sigma2)-sum(rmamod_nested$sigma2))/sum(pseudo_nested.s$sigma2)
#0
```


## exploratory stuff
### correlation of d with winter variability/predictability

```{r d}
#get studies with meaningful d estimate
x<-slopes[slopes$ID %in% c("kurota","urbanski","kimura_geogr_1","yoshida","shimizu","paolucci","gotoh","koveos"),]
x<-droplevels(x)
plot(x$d~x$sd_winter,pch=22,bg=x$ID,col=NA)
plot(x$d~x$p,pch=22,bg=x$ID,col=NA)
d<-NA
for (i in (1:8)){
  sub<-x[x$ID == unique(x$ID)[i],]
  d<-c(d,sub$d/max(sub$d))
}
x$d<-d[-1]
dmod<-rma.mv(yi = d ~ sd_winter, V = dse^2, random = ~1|order/g/ID, data = x,test="t") 
```



