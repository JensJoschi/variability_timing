---
title: "read slopes"
author: "Jens Joschinski"
date: "March 15, 2018"
output: 
  md_document:
  variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
library(tidyverse)
library(textreadr)
library(drc)
library(sandwich)
library(lmtest)
library(plyr)
library(geosphere)
```
# issues  
clean up that mess!

# General description  
## Aim  
The aim of this project is to correlate climate variability with variability in seasonal timing. Is the slope in seasonal responses a bet-hedging trait, i.e., is it adaptive to spread one's timing in more variable conditions?  


### Overview  
I searched in the web of Science database for studies that measure photoperiodic response curves of invertebrates (folder 02studies/00raw) and extracted the x- and y-coordinates of the points within these curves (folder 02studies/01extracted_data). After adding metadata (latitudes, longitudes,sample sizes, "extracted.xlsx"") I copied a subset of the data into a csv file. The script now calculates the slope and other parameters of the photopeirodic response curve. It uses dose-response curves analysis with package "drc".  

### Specific description  

The data was generated with R version `r getRversion()`. Slope estimates derived with package drc, `r citation('drc')`.

The script fits dose-response curves for all populations, seperately for each study. DRCs can estimate the upper and lower limit (range of diapause responses, usually from 0-100%), the inflection point (critical day length, where 50% of the population are in diapause), and the slope of the curve. I am mostly interested in slope of the curve, but also want to extract the critical day length. But the upper and lower limit have to be estimated as well. From a glimpse at the data it can be seen that the upper and lower limit are not always 0 and 100%, and there are several ways to fit the model. 

Intuitively one would expect that all populations of one species (and hence also all pops that have been sampled in a study) have the same lower and upper limit. One could therefore estimate a global upper and lower limit, and then slope and inflection point for each population (requires 2 degrees of freedom + 2 df per population). As alternative one could however also imagine a conservative bet-hedging strategy, in which a population never reaches 0% diapause to ensure survival in variable climates. In this case, the lower limit varies by populations, while the upper is fixed (requires 1 df + 3 df per population). The opposite situation, in which populationsut vary in their upper limit while the lower limit is fixed (1df + 3 per pop), is counterintuitive, as it is essentially the opposite of conservative bet-hedging. This strategy could mean that some offspring never diapause, even under winter conditions, hoping that a harsh winter climate never arrives (see skewed distribution in halkett 2004, amnat). The last possible version is that both upper and lower limit vary by population. This makes four models (sorted by plausibility): 

1. upper and lower parameter fixed at study mean (requires 2 df plus 2 df per population)
2. upper parameter fixed (requires 1 df plus 3 per population)
3. lower parameter fixed (requires 1df plus 3 per population)
4. both limits vary (requires 4 df per population)

This script first determines the available df to see if options 2-4 are available. Then it fits all models that are allowed, and compares by AIC which one is best. If there are ties (delta AIC <2), the most plausible model (sorted as above) is used. 


### Script  

This script should not be executed completely, becaues it will cause some convergence failure. Also, all models need to be examined by hand (summary may show that some values are actually NA because errors occured without warning). It is rather a description of the methods than an actual executable script.

#### function to decide between models  
This function works on a subset of the data, which has one study with all its popultaions.


```{r choosefun}
choosemodel<-function(input){
  aics <- c(NA,NA,NA,NA) #will store AIcs of up to four possible models 
  #idea: 
  #if df = enough for model 1 {
    #do model 1
    #if df = also enough for model2/3 {
      #do model 2
      #do model 3
      # if df = also enough for model 4{
        #do model 4
    #}}}
  #compare AIC of all recorded models
  
  #is model 1 possible? (2 df + 2 per pop)
  estimates <- nrow(input)
  pops<-unique(input$pops_with_Dia)
  if (length(unique(input$pops_with_Dia))>1){print(paste("something went wrong in study ",ipnut$study[1],"\n"))}
  res_df <- estimates - (2 + 2*pops)

  if (res_df>3){ #keep all aics NA if res_df are insufficient even for simplest model
    drm1<- drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA), lowerl=c(NA,0,NA,NA), weights=n2,  pmodels=data.frame(line.ID,1,1,line.ID)) 
    #this model calculates dose response curve, weighing each point by its sample size (if the information was given) and constraining the range between 0 and 1. Upper and lower limit are estimated by global mean, slope and inflection point by population. 
    aics[1]<-AIC(drm1)
    
    
    #are model 2 and 3 also possible?
    #only runs if first model was calculated, because it takes even more dfs
    res_df<-estimates - (1+ 3* pops)
    if (res_df >3){
       drm2<-drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA), lowerl=c(NA,0,NA,NA), weights=n2, pmodels=data.frame(line.ID,line.ID,1,line.ID))        # upper limit is fixed, but lower limit varies among pops
       aics[2]<-AIC(drm2)
       
       drm3<-drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA), lowerl=c(NA,0,NA,NA), weights=n2, pmodels=data.frame(line.ID,1,line.ID,line.ID))
       #lower limit is fixed, but upper limit varies among pops
       aics[3] <- AIC(drm3)
       
       
       #is model 4 possible?
       #only runs if first three models were calculated
       res_df <- estimates - (4*pops)
       if (res_df>3){
          drm4<-drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA),lowerl=c(NA,0,NA,NA), weights=n2)
          aics[4]<-AIC(drm4)
       }#end model 4
    }#end model 2,3
  }#end model 1
  
  if(sum(is.na(aics))<4){
    diff <- aics[1] - aics
    if(max(diff,na.rm=T)<2){
      final<-drm1
      choice = 1
    } else{
      diff<-data.frame(diff,c(1:4))
      names(diff)<-c("delta","model")
      diff<-diff[order(diff$delta,decreasing = T),]
      if (diff[1,1]-diff[diff$model==2,"delta"]<2){
        final <- drm2
        choice = 2
      } else if (diff[1,1]-diff[diff$model ==3,"delta"]<2){
        final<-drm3
        choice = 3
      } else {
        final<-drm4
        choice = 4
      }
    }
  } else{
      final <-NA
      choice = NA
  }
  return(list(final,choice,drm1,drm2,drm3,drm4,aics))
}
```

### load data  

```{r load_data}
data<-read.table("02studies/01extracted_data/forslopes.csv", header=T,sep=";")
data<-separate(data,col=1, into = c("study","pop"), sep ="-",remove=FALSE)
length(unique(data$study)) #38 studies that can be used for slope calculation
length(unique(data$line.ID)) #203 populations

r<-data.frame(NA,NA,NA,NA,NA,NA,NA,NA,NA)
names(r)<-c("name","b","b_rel","c","c_rel","d","d_rel","e","e_rel") #the results will be stored in a file with these columns
```


### get slope estimates

```{r estimate_slopes}
#notes
#study 1 - i=1->model3
#5-2->3
#6-3->3
#6b-4->4, with aicdiff to model 3 of 2.03
#8-5->conv failed with drm1 and drm2 (lower limits <0), could only be fixed by removing both box constraints and resulted in several NA in coef estimates; mod3 worked well and was reasonable
#9-6 has wrong pops with dia (should be 4, not 7). corrected. models 1-3 have missing data in coef, #only way to rectify is removing population UW, then only possible model is drm1. works though. 
#11-7->3,4,1 in this order. But only because missing value causes strange estimate of upper boundary. Used drm1 anyway.
#15-8 impossible to say whether pops reach max value. also only 4df at drm1. so  needs to be excluded
#17-9->1, 3. 1 is more realistic. drm2 would be better but kicks out 1 pop and gets higher AIC
#18-10->2, drm3 and drm 4 do not work (which is fine). lockwood is problematic in all models, but removing causes convergence problems. Left in for modelling, but did not report estimates. 
#19-11 remove dataset because no points on slope part
#20-12->3
#21-13->3
#22-14->3
#23-15->3
#24-16->3 moscow is missing; Ticino4 is there. sth is wrong with this study. removed
#27-17->4. Petroskoi F needs to be removed because cannot be estimated
#29-18->2 4 did not converge, but 4 is better anyway
#30-19->1,3 both are fine
#31-20 too few df for drm2-4, drm1 is unrealistic (3 points per pop), unclear whether pops reach final upper limit.exclude
#33-21->3 4 has coefs NA (3 is better anyway) 
#35-22->3 N not described, needs to get arbitrary value ->100; dl <9 becomes non-log, removed; ishigaki may not have reached upper limit,removed
#36-23 not enough df (3 estimates per pop)
#37-24->3,4 drm2 does not converge because unrealistic; TUR removed because does not go to 0
#38-25 data to dirty for analyis. Removed
#40-26->4
#41-27 model overfitted. remove
#42-28 ->2. needed to remove box constraints though
#43-29 remove because overfitted
#44-30 remove because not enough data (2 or 3 pops did not reach upper limit)
#45-31 ->3 needed to remove KCH because non-diapausing
#46-32 ->3
#47-33 ->1 removed Akita because non-diapausing
#48-34 walton, alabama wrong on y axis
#49-35 ->3 removed O
#50-36 not enough df
#51-37 ->1 removed all slope ="n", 11 pops left
#52-38 not enough df
#53-39 dls smaller 16 not in raw data
#54-40 not enough df
#55-41 ->3 4 has better AIC but range (c) =0:0.07. box-constraints were removed
#56-42 ->3
#57-43 ->1 remove slope ="n"

for (i in 1:length(unique(data$study))){
  sub<-data[data$study==unique(data$study)[i],] #calculate dose response curves for each study   seperately
  sub<-droplevels(sub)
  sub$n2<-round(sub$n2)
  #sub$perc[sub$perc<0]<-0
  #sub$perc[sub$perc>100]<-100
  sub$number<-round(sub$n2 * sub$perc/100)
  sub$number[sub$number>sub$n2]<-sub$n2[sub$number>sub$n2]
  sub$number[sub$number<0]<-0
  sub$pops_with_Dia<-length(levels(sub$line.ID))
  results<-choosemodel(sub)
  final<-results[[1]]
  sub$study[1]

      
  #possible values of "choice" and their meaning
  # NA "no model possible due to lack of df"
  #1 upper and lower parameter fixed at study mean
  #2 upper parameter fixed
  #3 lower parameter fixed
  #4 both limits vary
  if(is.na(results[[2]])){next
  }else if (results[[2]]==1){
    #plot study for visual validation
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep="")) 
    plot(final, xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="upper and lower limit fixed at global mean", log="", col=TRUE)
    dev.off()
  }else if (results[[2]]==2){
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep="")) 
    plot(final, xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="upper limit fixed at global mean", log="", col=TRUE)
    dev.off()
  }else if(results[[2]]==3){
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep=""))
    plot(final,xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="lower limit fixed at global mean", log="", col=TRUE)
    dev.off()
  }else{
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep=""))
    plot(final, xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="upper and lower limit estimated for each pop", log="", col=TRUE)
    dev.off()
    }


    #write these into results table
    coffs<-coeftest(final,vcov = sandwich)[,1:2] #provides estimate and SE
    coffs[,2]<-1/coffs[,2] #SE becomes 1/SE, as these are later weights
    coffs<-as.data.frame(coffs)
    #save slope coefficients
    coffs$group<-substr(rownames(coffs),1,1)
    b<-coffs[coffs$group=="b",]
    c<-coffs[coffs$group=="c",]
    d<-coffs[coffs$group=="d",]
    e<-coffs[coffs$group=="e",]
    


    new_data<-data.frame(b,c,d,e)
    new_data<-new_data[,c(1,2,4,5,7,8,10,11)]
    names(new_data)<-c("b","b-se","c","c-se","d","d_se","e","e_se")
    new_data<-new_data[order(rownames(new_data)),]
    old_data<-ddply(sub, "line.ID", function(z) tail(z,1))
    old_data<-old_data[order(old_data$line.ID),c(1:10,14)]
    results<-cbind(new_data,old_data)
  

write.table(results, "02studies/02output/slopes.txt",append=T,sep="\t",col.names=FALSE)
}#next study




```

```{r singlestudy}
sub<-data[data$study==unique(data$study)[i],] 
sub<-droplevels(sub)
sub$n2<-round(sub$n2)
sub$number<-round(sub$n2 * sub$perc/100)
sub$number[sub$number>sub$n2]<-sub$n2[sub$number>sub$n2]
sub$number[sub$number<0]<-0
sub$pops_with_Dia<-length(levels(sub$line.ID))

aics <- c(NA,NA,NA,NA) #will store AIcs of up to four possible models 
input<-sub
estimates <- nrow(input)
pops<-length(unique(input$line.ID))
if (length(unique(input$pops_with_Dia))>1){print(paste("something went wrong in study ",ipnut$study[1],"\n"))}
  
#model1
res_df1 <- estimates - (2 + 2*pops)>3
drm1<- drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA), lowerl=c(NA,0,NA,NA), weights=n2,  pmodels=data.frame(line.ID,1,1,line.ID))

aics[1]<-AIC(drm1)
    
#model2 and 3
res_df2<-estimates - (1+ 3* pops)>3
drm2<-drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA), lowerl=c(NA,0,NA,NA), weights=n2, pmodels=data.frame(line.ID,line.ID,1,line.ID))  

aics[2]<-AIC(drm2)

drm3<-drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA), lowerl=c(NA,0,NA,NA), weights=n2, pmodels=data.frame(line.ID,1,line.ID,line.ID))
aics[3] <- AIC(drm3)
       
       
#model 4
res_df3 <- estimates - (4*pops)>3
drm4<-drm((number/n2)~dl2, curveid=line.ID, data=input, fct=LL.4(), type="binomial", upperl=c(NA,NA,1,NA),lowerl=c(NA,0,NA,NA), weights=n2)
 aics[4]<-AIC(drm4)
 
 
 res_df1
 res_df2
 res_df3
```
```{r}
plot(drm1)
plot(drm2)
plot(drm3)
plot(drm4)
aics
summary(drm1)
summary(drm2)
summary(drm3)
summary(drm4)
```

```{r}

choice <-3
final<-drm3
results<-list(final,choice)
```

```{r}
  #possible values of "choice" and their meaning
  # NA "no model possible due to lack of df"
  #1 upper and lower parameter fixed at study mean
  #2 upper parameter fixed
  #3 lower parameter fixed
  #4 both limits vary
 if (results[[2]]==1){
    #plot study for visual validation
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep="")) 
    plot(final, xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="upper and lower limit fixed at global mean", log="", col=TRUE)
    dev.off()
  }else if (results[[2]]==2){
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep="")) 
    plot(final, xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="upper limit fixed at global mean", log="", col=TRUE)
    dev.off()
  }else if(results[[2]]==3){
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep=""))
    plot(final,xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="lower limit fixed at global mean", log="", col=TRUE)
    dev.off()
  }else{
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep=""))
    plot(final, xlab = "Day length", ylab = "percentage diapause", main = sub$study[1], sub="upper and lower limit estimated for each pop", log="", col=TRUE)
    dev.off()
    }


    #write these into results table
    coffs<-coeftest(final,vcov = sandwich)[,1:2] #provides estimate and SE
    coffs[,2]<-1/coffs[,2] #SE becomes 1/SE, as these are later weights
    coffs<-as.data.frame(coffs)
    #save slope coefficients
    coffs$group<-substr(rownames(coffs),1,1)
    b<-coffs[coffs$group=="b",]
    c<-coffs[coffs$group=="c",]
    d<-coffs[coffs$group=="d",]
    e<-coffs[coffs$group=="e",]
    


    new_data<-data.frame(b,c,d,e)
    new_data<-new_data[,c(1,2,4,5,7,8,10,11)]
    names(new_data)<-c("b","b-se","c","c-se","d","d_se","e","e_se")
    new_data<-new_data[order(rownames(new_data)),]
    old_data<-ddply(sub, "line.ID", function(z) tail(z,1))
    old_data<-old_data[order(old_data$line.ID),c(1:7,11)]
    results<-cbind(new_data,old_data)
  

write.table(results, "02studies/02output/slopes.txt",append=T,sep="\t",col.names=FALSE)
 print(paste(i,"|",results$study[1],"||",choice,sep=""))
```
i|study |best models|chosen|impossible  |notes
1|1     |3          |3      |4
2|5     |3          |3
3|6     |3          |3
4|6b    |3          |3
5|6c    |3          |3      |           |removed 6c-SM
6|9     |1          |1      |2,3,4      |needed to remove UW and box constraints. 
7|10    |           |       |           |1 line only, needs removal
8|11    |3,4,1      |1      |           |missing value in 1 pop causes different upper limit
9|17    |2,4        |2
10|18   |2          |2
11|20   |           |       |1-4        |removed
12|21   |3          |3
13|22   |3          |3
14|23   |1,3        |1
15|24   |3          |3      |2           |model 2 would have pops with 1 estimate on slope
16|27   |4,4        |4
17|29   |2          |2
18|30   |1          |1      |3          | 3 did not converge
19|33   |3,4        |3
20|35   |3,4        |3                  |ishigaki removed, n set to 100
21|37   |2,4(3)     |4                  |AICs: 107,102.5,105.5,101.3
22|42   |           |2      |3,4        |removed lower box constraints
23|45   |           |3
24|46   |           |       |1-4        |exclude
25|47   |           |       |1-4        |exclude
26|48   |3          |3      |4          |removed lower limit constraint
27|49   |           |       |1-4        |exclude
28|51   |1          |1      |4
29|53   |3          |3
30|54   |           |1      |2-4
31|55   |           |4                  |c estimates 0-0.06;1 pop NA in drm1/2
32|56   |           |3      |4          |1 pop NA in drm4
33|57   |1,3        |1
34|60   |3,4        |3
35|64   |           |       |1-4        |1 pop has only one point on slope, leaving 2 pops only
36|65   |           |       |1-4        |only 2pops
37|66   |           |       |1-4        |only 2 pops
38|70   |1,3        |1      |           |



Now the slope and cdl estimates are done. After combining with climate data it turned out that the CDL data is quite far away (2 months) from the mean winter onset. This chunk explains the calculation of the julian date that is most consistent with onset of diapause
```{r}
results <- read.table("02studies/02output/slopes.txt",sep = "\t")
names(results)<-c("ID","b","b_se","c","c_se","d","d_se","e","e_se","ID2","study","pop","spec","order","degN","degE","py")
results<-results[order(results$degN),]

#1. Let us assume that winter onset is on day 330 (an arbitrary day). Then one can calculate the "optimal" CDL response given latitude and day 330:
plot(results$e~results$degN,main = "CDL vs latitude, red= expectation if winter onset =180")
dl<-daylength(results$degN,330)
points(dl~results$degN,col=2)
#a model of the form (expected ~ observed) should give a quite good fit, because there is a good (negative) correlation. But this is not quite what I want, as they should not only correlate but be more or less identical. An alternative model of form (expted~observed - intercept) should give, on the other hand, a really bad fit

plot(dl~results$e,main = "expected(for day=180) vs observed.",sub="setting intercept to 0")
M1<-lm(dl~results$e)
M2<-lm(dl~results$e-1)
abline(M1,col=1,lty=2)
abline(M2,col=2)

#bringing that back to the CDL~latitude plot:
plot(results$e~results$degN,main = "CDL vs latitude", sub="red= expectation if winter onset =180\nblue = model predictions without intercept",ylim=c(4,22),xlab="")
points(dl~results$degN,col=2)
#points(predict(M)~results$degN,col="green")
points(predict(M2)~results$degN,col=4)
#this model is indeed a bad fit to the data. 

#the same can now be done for all 365 days, and then the model with the highest log-likelihood should be selected


```

```{r}
logliks<-rep(NA,365)
for ( i in 1:365){
  dl<-daylength(results$degN,i)
  M<-lm(dl~results$e-1)
  logliks[i]<-logLik(M)
  #abline(M)
}
plot(logliks,type="l", main ="logLikelihood profile for different dates",xlab = "Julian date", ylab = "LogLikelihood")
points(logliks,pch=22,cex=0.3,bg=1)#160-183
order(logliks,decreasing=T)[1:10]
#135, 211,  212,134,136
plot(results$e~results$degN,main = "CDL vs latitude", sub="red= expectation if winter onset =135\nblue = 211\ngreen =180",ylim=c(4,22),xlab="")
dlbest<-daylength(results$degN,135)
dlsecond<-daylength(results$degN,211)
dlbad=daylength(results$degN,180)

points(dlbest~results$degN,col=2)
points(dlsecond~results$degN,col=4)
points(dlbad~results$degN,col="green")
#best and second best are equal
M<-lm(dlbest~results$e-1)
M2<-lm(dlsecond~results$e-1)
```
The best estimates by this procedure are day 135 (may 15th) and day 211 (jul 30th), these estimates are exactly equal, as they are both 38 days away from summer solstice. 

checking whether calculation is correct with https://www.esrl.noaa.gov/gmd/grad/solcalc/
```{r}
plot(results$e~results$degN,main = "CDL vs latitude", sub="red= expectation if winter onset =30jul\nblue = 1.dec",ylim=c(4,22),xlab="")
dlbest<-daylength(results$degN,135)
dlmeteorolog<-daylength(results$degN,305)
points(dlsecond~results$degN,col=2)
points(dlmeteorolog~results$degN,col=4)
Nvec<-10*(1:7)
dlvec<-c(18,18,18,19,19,20,22)+c(23,38,55,16,46,35,58)/60 - (c(5,5,5,4,4,3,1)+c(49,35,18,56,26,36,05)/60) #taken from noaa calculator for Nvec °N, 0°E
dlvec2<-c(17,17,17,16,16,15)+c(37,19,0,35,1,3)/60 - 
  (c(6,6,6,7,7,8)+c(1,19,38,2,37,35)/60)
dlvec2<-c(dlvec2,0)

points(dlvec~Nvec,col="green")
points(dlvec2~Nvec,col="black",pch=22,bg=1) # NOAA uses "apparent sunrise", could be civil sunrise/sunset
```

