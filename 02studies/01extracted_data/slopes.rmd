---
title: "read slopes"
author: "Jens Joschinski"
date: "March 15, 2018"
output: 
  md_document:
  variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
library(tidyverse)
library(textreadr)
library(drc)
library(sandwich)
library(lmtest)
```


# General description  
## Aim  
The aim of this project is to correlate climate variability with variability in seasonal timing. Is the slope in seasonal responses a bet-hedging trait, i.e., is it adaptive to spread one's timing in more variable conditions?  


### Overview  
I searched in the web of Science database for studies that measure photoperiodic response curves of invertebrates (folder 02studies/00raw) and extracted the x- and y-coordinates of the points within these curves (folder 02studies/01extracted_data). After adding metadata (latitudes, longitudes,sample sizes, "extracted.xlsx"") I copied a subset of the data into a csv file. The script now calculates the slope and other parameters of the photopeirodic response curve. It uses dose-response curves analysis with package "drc".  

### Specific description  

The data was generated with R version `r getRversion()`. Slope estimates derived with package drc, `r citation('drc')`.
The script first fits 4-parameter dose-response curves to each population within each study. It then tries to reduce to a 3-parameter drc with lower limit fixed at 0. The 3-parameter model is preferred when either the degrees of freedom for the LL4 are smaller than 4, or when deltaAIC is >2. 
If the model can be reduced to LL3, I try to eliminate the estimation of the upper limit as well, but not by a fixed value (LL2), but by a global estimate based on the populations within each study. See separate .r script for detailed explanation.
If the model cannot be reduced, I compare the LL4 with models that replace the upper limit , the lower limit, or both limits by the average of all populations. The model with lowest AIC is chosen (again only if delta AIC >2).


###Script  

#### function to decide between LL.4/LL.3 and LL.3/LL.3*
This function works on a subset of the data, that has one study with all its popultaions.


```{r choosefun}
choosemodel<-function(data){
   drm_4<-drm(number/n2~dl2,curveid=line.ID,data=data,fct=LL.4(),type="binomial",upperl=c(NA,NA,1,NA),lowerl=c(NA,0,NA,NA), weights=n2)
  #drm weighted by samplesize and ranging from 0 to 1 (the range is estimated between 0 and 1,   not fixed)
  drm_3<-drm(number/n2~dl2,curveid=line.ID,data=data,fct=LL.3(),type="binomial",upperl=c(NA,1,NA), weights=n2) # a competing model with lower limit fixed at 0%

  
  if((drm_4$df.residual>3)&(AIC(drm_4)-AIC(drm_3)>2)){#can reduce to LL.3
    drm_3_est<-try(drm(number/n2~dl2,curveid=line.ID,data=sub,fct=LL.3(),type="binomial",upperl=c(NA,1,NA), weights=n2,pmodels = data.frame(line.ID,1,line.ID)))#competing model with upper limit estimated as mean of all populations
    
    if ((class(drm_3_est)=="drc") & (AIC(drm_3)-AIC(drm_3_est)>2)){
      final<-drm_3_est
      choice <-0}
    else{
      final<-drm_3
      choice <- 1}
    
  }
  else{#in case LL.4 needs to be fitted - 3 reductions possible
       drm_4_est_l<-drm(number/n2~dl2,curveid=line.ID,data=data,fct=LL.4(),type="binomial",upperl=c(NA,NA,1,NA),lowerl=c(NA,0,NA,NA), weights=n2, pmodels=data.frame(line.ID,1,line.ID,line.ID))#global average of lower boundary
       drm_4_est_u<-drm(number/n2~dl2,curveid=line.ID,data=data,fct=LL.4(),type="binomial",upperl=c(NA,NA,1,NA),lowerl=c(NA,0,NA,NA),weights=n2, pmodels=data.frame(line.ID,line.ID,1,line.ID))#global average of upper boundary
       drm_4_est_b<-drm(number/n2~dl2,curveid=line.ID,data=data,fct=LL.4(),type="binomial",upperl=c(NA,NA,1,NA),lowerl=c(NA,0,NA,NA),weights=n2, pmodels=data.frame(line.ID,1,1,line.ID))#global average of both boundaries
       
       
       AIClist<-c(AIC(drm_4),AIC(drm_4_est_l),AIC(drm_4_est_u),AIC(drm_4_est_b))
       diff<-AIClist[1]-AIClist
       if(max(diff)>2){
         if(which.max(diff)==2){
           final<-drm_4_est_l
           choice = 2}
         else if(which.max(diff)==3){
           final<-drm_4_est_u
           choice = 3}
         else{
           final<-drm_4_est_b
           choice = 4}
       }
         else{
           final<-drm_4
           choice = 5}
     }
    
  return(final,choice)
 #possible values of choice and their meaning
   #0 "LL3 with upper limit replaced by average"
  #1 "LL3"
 # 2 "LL4 with lower limit replaced by average"
 # 3 "LL4 with upper limit replaced by average"
  #4 "LL4 with both limits replaced by average"
 # 5 "LL4"
}
```

load data
```{r}
data<-read.table("02studies/01extracted_data/forslopes.csv", header=T,sep="\t")
data<-data[data$cdl=="x",]
data<-separate(data,col=1, into = c("study","pop"), sep ="-",remove=FALSE)
length(unique(data$study)) #52 studies that can be used for CDL calculation
length(unique(data$line.ID)) #353 populations
length(unique(data$study[data$slope=="x"])) # 30 studies can be used for slope calculation
length(unique(data$line.ID[data$slope=="x"]))#170 populations

r<-data.frame(NA,NA,NA,NA,NA,NA,NA,NA,NA)
names(r)<-c("name","b","b_rel","c","c_rel","d","d_rel","e","e_rel") #the results will be stored in a file with these columns
```


```{r}
for (i in 1:length(unique(data$study))){
  sub<-data[data$study==unique(data$study)[i],] #calculate dose response curves for each study   seperately
  sub<-droplevels(sub)
  sub$perc[sub$perc<0]<-0
  sub$perc[sub$perc>100]<-100
  sub$number<-round(sub$n2 * sub$perc/100)
  
  results<-choosemodel(sub)
  final<-results[[1]]
 #possible values of choice and their meaning
   #0 
  #1 "LL3"
 # 2 "LL4 with lower limit replaced by average"
 # 3 "LL4 with upper limit replaced by average"
  #4 "LL4 with both limits replaced by average"
 # 5 "LL4"
  if (results[[2]]==0){#"LL3 with upper limit replaced by average"
    png(paste("02studies/01extracted_data/",i,"-",unique(data$study)[i],".png",sep="")) #plot study for visual validation
    plot(final,xlab = "Day length", ylab = "percentage diapause",main = sub$study[1],sub ="LL3 with upper limit replaced by average" ,log="",col=TRUE)
    #dev.off()
    coffs<-coeftest(final,vcov = sandwich)[,1:2] #provides estimate and SE
    coffs[,2]<-1/coffs[,2] #SE becomes 1/SE, as these are later weights

    #write these into results table
    

    nam<-rownames(coffs)[substr(rownames(coffs),1,1)=="b"]
    b<-coffs[substr(rownames(coffs),1,1)=="b",]
    c<-coffs[substr(rownames(coffs),1,1)=="c",]
    d<-coffs[substr(rownames(coffs),1,1)=="d",]
    e<-coffs[substr(rownames(coffs),1,1)=="e",]
    
    if (class(c) =="numeric"){
      x<-c
      for(i in 1:(nrow(b)-1)){
        c<-rbind(c,x)
      }
    }
    if (nrow(c)==0){c<-matrix(NA,nrow(b),2)}

    if (class(d) =="numeric"){
      x<-d
      for(i in 1:(nrow(b)-1)){
        d<-rbind(d,x)
      }
    }    
    if (nrow(d)==0){d<-matrix(NA,nrow(b),2)}

    new_data<-data.frame(nam,b,c,d,e)
    names(new_data)<-c("name","b","b-se","c","c-se",)
    )
  
    npop=length(unique(sub$line.ID))
n<-unique(sub$line.ID)
for (j in 1:npop){
  r[nrow(r)+1,]<-c(as.character(n[j]),coffs[j,],coffs[j+npop,],coffs[j+2*npop,],coffs[j+3*npop,])#writes results for each pop in this study into results: ID, b,e, and the weights of each
}
}#next study


#transport all other metadata from csv file to results file
r$degN<-NA
r$degE<-NA
r$order<-NA
r$genus<-NA
r$species<-NA
r$pops_with_dia<-NA
r$n_dls<-NA
r$py<-NA
r$slopable<-NA

for(i in 1:nrow(r)){
  r[i,10]<-as.character(data[data$line.ID == r[i,1],10][1])#degN
  r[i,11]<-as.character(data[data$line.ID == r[i,1],11][1])#degE
  r[i,12]<-as.character(data[data$line.ID == r[i,1],9][1])#order
  r[i,13]<-as.character(data[data$line.ID == r[i,1],7][1])#genus
  r[i,14]<-as.character(data[data$line.ID == r[i,1],8][1])#species
  r[i,15]<-as.character(data[data$line.ID == r[i,1],5][1])#pops_with_dia
  r[i,16]<-as.character(data[data$line.ID == r[i,1],6][1])#n_dls
  r[i,17]<-as.character(data[data$line.ID == r[i,1],15][1])#py
  r[i,18]<-as.character(data[data$line.ID == r[i,1],17][1])#slope
}

write.table(r, "02studies/02output/slopes.txt")

#testing
npop=length(unique(sub$line.ID))
#predict curves by hand
b<-coef(moo)[1:npop] # there are three parameters per pop - the first third are the b estimates, the second third the d estimates (upper bound), and the last third the e estimate (critical day length)
c<- coef(moo)[(npop+1):(2*npop)]
d<- coef(moo)[(npop*2+1):(3*npop)]
e<- coef(moo)[(npop*3+1):length(coef(moo))]

lin <- function(x,b,c,d,e){
  upper<-d-c
  lower <-1 + exp(b*(log(x)-log(e)))
  c+ (upper/lower)
}

bm<-b-coffs[1:npop,2]
cm<-c-coffs[(npop+1):(npop*2),2]
dm<-d-coffs[(npop*2+1):(npop*3),2]
em<-e-coffs[(npop*3+1):(npop*4),2]
plot(moo)
lines(x=1:16,y = lin(1:16,b[i],c[i],d[i],e[i]),col=2)
lines(x=1:16,y = lin(1:16,bm[i],cm[i],dm[i],em[i]),col=4)
```

