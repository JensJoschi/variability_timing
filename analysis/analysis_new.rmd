---
title: "analysis"
author: "Jens Joschinski"
date: "April 5, 2018"
output:     
  md_document:
        variant: markdown_github
---

```{r setup, include=FALSE}
library(tidyverse)
#library(maps)
library(geosphere)
library(fcuk)
library(metafor)

```


# General description  
## Project aim  
To understand the evolvability of phenological strategies such as plasticity and bet-hedging, we correlate reaction norm properties with climate parameters. 

## Script overview  

Previous scripts calculated winter onset means and predictability based on climate station data (30k stations), and various parameters of photoperiodic response curves from published studies (447 reaction norms). This script analyses these datasets.


### Specific description  

The data was generated with R version `r getRversion()` (3.4.3). It requires the datasets "/lit_extract/mcmcresults.txt", "/clim_calc/output/beta.txt" and "clim_calc/output/results_100_5.txt", and the locations.txt file from the NOAA server.
...

 
### statistical approaches  
The correct statistical approach should be:

estimate ~ climate data, random = order/genus/species/study/population)

with the estimate weighted by the inverse variance. However, there is little replication on the species level (usually 1 study per species, if more then by same authors) and on the genus level (usually very few genera per order, or each genus with its own species), so the terms study and genus will be dropped.

# Script  
## load data

The data with the mcmc results needs to be loaded. This has for each of the 447 reaction norms the estimate of mean, vairance within and variance among environments, the ratio, the sum and of course credible intervals for all. var between = sd(percentages)^2 across environments, var within = sum(percentages * (1-percentages))/n.

```{r load_studies}
studies <- read.table("lit_extract/mcmcresults.txt")
studies<-studies[order(studies$order),]
studies$col<-as.numeric(studies$order)
studies$col<-hsv(studies$col/10,1,1)
##constrain to between tropics and polar circle
#studies <- studies[between(studies$degN, 23.434, 66.57),]

#data structure: 447 rows, 33 variables

#names of cols:
#popid: unique identifier of the reaction norm (447 levels)
#order.x: insect or mite order (9 levels)
#ID: first author of study from which reaction norm comes. 57 levels, because each study has multiple reaction norms
#PY: publication year of study
#pops_left_drc: number of populations within each study. Not necessarily equal to number of reaction norms, e.g. lehmann has 6 reaction norms from 5 populations (in total there are 447 reaction norms for 402 populations)
#region: larger geographical region from which population comes (e.g. Europe, Japan...)
#genus: genus name
#spec: species name
#nmethod: how detailed are sample sizes described in the study? usually "global average", e.g. "on average there were 100 beetles used for each population and day length"
#degN: Latitude of sampling location; range = 14.3 : 69.05
#degE: Longitude of sampling location; range = -123 : 144 (US to Japan)
#n_pp: number of available photoperiod treatments for this reaction norm. The reaction norm was reconstructed based on 3-21 data points, average 7.12

#col: color gradient based on order as defined above

#med_cdl: cdl estimate (parameter e in the logit curve, eq.1)
#upper_cdl, lower_cdl: credible interval range of med_cdl
#med_e: estimate of mean timing, based on diapause reaction norm (day length reaction norm transformed to julian days)
#med_r: variance composition estimate (among/(within + among), eq. 4). based on diapause reaction norm
#med_s: estimate for sum of variance components (phenotypic variance, eq. 5)
#med_b: variance among estimate, eq.3
#med_w: variance_within estimate, eq. 2
#n: became meaningless, not required anymore
names(studies)[5]<-"order"
```



#### climate data  
As climate dataset I chose the parameters (5 days below 10°C), a combination that is close to e.g. halkett 2004, and results in a mean winter onset in mid-october (when many animals start their diapause). the climate dataset "results_100-5.txt" has mean winter onset, standard deviation in winter onset ( measure of day length predictbaility), and predictability based on standard deviation of slopes of a temperature regression. The dataset "beta.txt" adds a colour of noise approach. the file ghcnd-stations.txt has latitudes and longitutes. These files will now be merged

```{r load_climate}
url<-"ghcnd-stations.txt"
#"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
#this dataset is fixed-width delimited, requiring a few additional steps
locations<-read.fwf(
  file=url
  ,sep="!",na.strings=c("NA","-999.9"), #sep = ! because ! does not exist in dataset - > dataset is fixed-width and should have no additional separators
  widths=c(11, 9, 10, 7,2,35)
)

reslist<-read.table("clim_calc/output/results_100-5.txt",na.string = c("NA","-9999","-999.9"))
names(reslist)<-c("ID","meanwinter","sd_winter","p","nyears","ndays_300","ndays_350","ndays_365")
reslist<-reslist[1:26804,] #the same data was appended twice
climate<-merge(locations,reslist,by=1)
rm(reslist)
names(climate)<-c("ID","lat","lon","alt","name","no_idea","meanwinter","sd_winter", "p",  "nyears" ,  "ndays_300"  ,"ndays_350",  "ndays_365" )

climate<-climate[!is.na(climate$meanwinter),] #because these cannot be used anyway
beta<-read.table("clim_calc/output/beta.txt",header=T)
climate<-merge(climate,beta,by=1)

climate<-climate[climate$lat<70,] #at higher latitudes winter onset is at midsummer

#calculate day length:
#Day length changes not only with latitude but also with day of year
#The correct calculation of day length at a given latitude for a given day is difficult: https://en.wikipedia.org/wiki/Sunrise_equation
#luckily there is a package that solves that.
climate$dl <- daylength(climate$lat,climate$meanwinter+182)
```



## 1. maps  
Making worldwide maps of winter onset, sd(winter onset) etc 

```{r all_maps}
plotmap<-function(r,g,b){
  map("world",xlim= c(-160, 150),ylim = c(0,75), interior=T, fill=T, bg = "white",col ="darkgrey")
  points(x= climate$lon, y= climate$lat, col = NA, bg = rgb(r,g,b,maxColorValue = 255), pch = 22,  cex=0.5)
  points(x = studies$degE, y= studies$degN, col =1, pch=4, cex = 0.5)
}

svg("all.svg", width = 14*360/310, height = 7*2.4, pointsize=12)
  par(fg = "darkgrey", mfrow = c(3,1),mar=c(0,0,0,0))


### day length at winter onset###
x<-climate$dl
length(x[x>16])/length(x)
x[x>16]<-16
x<-24-x #x is night length now, high values = short days
#high values should be red ( winter very late in year, under very short days)
x<-x-min(x)
x<-x/(max(x)) #values between 0 and 1

r<- x * 162
r <- r + 30
g<-100 - (x * 100)
b<-200 - (x * 200)
plotmap(r,g,b)
rect(-163,0-1.38,153,75+1.38,col=NA,border = 1 ,xpd=T)
text(-160,10,"A",pos=4,cex=4, col=1)

###winter predictability by day length###
x<-climate$sd_winter
x[x>30]<-30 #capped to make plotting sensible
x<-x-min(x)
x<-x/(max(x)) #values between 0 and 1
#large values (high standard deviation) should be red

r<- x * 162
r <- r + 30
g<-100 - (x * 100)
b<-200 - (x * 200)
plotmap(r,g,b)
rect(-163,0-1.38,153,75+1.38,col=NA,border = 1 ,xpd=T)
text(-160,10,"B",pos=4,cex=4, col=1)



###predictability as colour of noise###
x<-climate[!is.na(climate$beta),]
nrow(x[x$beta>2,])/nrow(x)
x$beta[x$beta>2]<-2 #capped to make plotting sensible
x$beta[x$beta<(-2)]<-(-2) #capped to make plotting sensible
x$beta<-x$beta-min(x$beta)
x$beta<-x$beta/(max(x$beta)) #values between 0 and 1
#large values (high standard deviation) should be red

r<- x$beta * 162
r <- r + 30
g<-100 - (x$beta * 100)
b<-200 - (x$beta * 200)
plotmap(r,g,b)
rect(-163,0-1.38,153,75+1.38,col=NA,border = 1 ,xpd=T)
text(-160,10,"C",pos=4,cex=4, col=1)


```



## 2. Critical day length and latitude  

According to Danilevsky, day  length should shift by 1-1.5 hours per 5°N. Let's see if that holds for the data in this meta-analysis.

#### the full model  
```{r degN_full}
r<-studies$upper_cdl-studies$lower_cdl
quantile(r,0.2)#20% have credible interval < 10 minutes

r[r<(1/6)]<-1/6  #all reaction norms with credible interval of 10 min or less have same weight
vi <- (r / (2*1.96))^2 #calculation of variance from CI


metaf<-rma.mv(yi = med_cdl ~ degN, V=1, random = ~1|order/genus/spec/ID/popid,data = studies) 
#this model does not actuallz use vi, but is an unweighted version. But general problems should be similar in weighted model
#profile(metaf,sigma2 = 1)
#profile(metaf,sigma2 = 2)
#profile(metaf,sigma2 = 3)
#profile(metaf,sigma2 = 4)
#this model has very little vraiance explained by ID and popid, because spec and genus absorb most of it

```

There are just not enough replicate studies per species, not enough species per genus (usually), and not enough genera per order. studies on the smae species were usually conducted by the same authors, so ID can be safely removed. This assumes that different studies on the same species will give the same results. Genus can also be removed.

#### the reduced model
```{r degN_models}

metaf<-rma.mv(yi = med_cdl ~ degN, V=vi, random = ~(1|order/spec/popid), data = studies)



#null models and ML models (weighted)
metanull<-rma.mv(yi = med_cdl ~ 1, V=vi, random = ~(1|order/spec/popid), data = studies)
metaf.ml<-rma.mv(yi = med_cdl ~ degN, V=vi, random = ~1|order/spec/popid,data = studies, method = "ML") 
metanull.ml<-rma.mv(yi = med_cdl ~ 1, V=vi, random = ~1|order/spec/popid,data = studies,method = "ML") 


n<-table(studies$order)
names(n)<- paste(names(n)," (", n, ")", sep = "") #will be used for plotting later, better laod it together with the model so it wont get lost
```

_summary statistics_    
```{r degN_sumstat}
#summary statistics
quantile(studies$degN)
#      0%      25%      50%      75%     100% 
#14.30000 34.55186 38.92000 44.88400 69.04917 

mean(studies$degN) #  41.38953 mean latitude of studies
mean(studies$med_cdl) # 13.72918 mean day length of diapause induction

x<-daylength(41,1:360)  #day length throughout the year at 41°N
which(x>13.7&x<13.8) #day 230 at 41 °N = Aug 18

#estimate +se
summary(metaf)
#Model Results:#

#         estimate      se     zval    pval   ci.lb   ci.ub     
#intrcpt    7.0405  0.3917  17.9720  <.0001  6.2727  7.8083  ***
#degN       0.1615  0.0067  24.1000  <.0001  0.1484  0.1747  ***
#48.45 min per 5 deg N

plot(resid(metaf))

#nakagawas R²
(metanull$sigma2-metaf$sigma2)/metanull$sigma2 # -3.467628e+06        0.66        0.59
(sum(metanull$sigma2)-sum(metaf$sigma2))/sum(metanull$sigma2) #0.55

#significance testing
anova(metaf.ml,metanull.ml) #LRT ratio = 364.1214, p<.0001
AIC(metaf.ml)-AIC(metanull.ml)#    -362.1214
```




__plot__    
Plot critical day length vs latitude, with character size proportional to weight, with credible intervals around the points, and different colours for different orders.
```{r degN_plot}
studies$r<-r

svg("CDL_lat.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)

max.size<-((1/6)/(2*1.96))^2; max.size <- 1/max.size #minimum credible interval range was capped at 1/6 (10 min) to prevent infinite weights. this line calculates variance for this value; it will be used to control the point cex in the plot
plot(x=studies$degN, y=studies$med_cdl, pch=21, cex=0.3+1.5*(1/vi)/max.size, col=1, bg=studies$col, main = "", xlab = "Latitude (°N)", ylab = "Critical photoperiod (h)",bty="n", xaxt="n", cex.axis = 1.5, cex.lab=1.5) #cex ranges from 0.3 to 1.5, with 1.5 for those with heighest weight (ci = 10 min)
legend("topleft",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
coffs <-  coef(metaf)
coffs
#  intrcpt      degN 
#7.040500 0.161515 

lines(x= range(studies$degN),y = coffs[1]+coffs[2]*range(studies$degN),lwd=3,lty=1)


axis(1,at=c(0,20,30,40,50,60,70,80),cex.axis=1.5, cex.lab = 1.5)


segments(x0=studies$degN[studies$r<2], y0 = studies$upper_cdl[studies$r<2], y1=studies$lower_cdl[studies$r<2] ,col="darkgrey") #only credible intervals <2 hours are printed, otherwise fig would be cluttered

ord<-studies[order(studies$r,as.numeric(studies$order),decreasing = c(T,F), method = "radix"),] #to make sure smalles points are printed last, on top of the larger points. order is included so that dipterans do not completely dominate pic
vi.new <- (ord$r / (2*1.96))^2
for (i in 1:nrow(ord)){
  points(x=ord$degN[i] ,y=ord$med_cdl[i], pch=21, col=1, bg=ord$col[i], cex=(0.3+1.5*(1/vi.new)/max.size)[i])
}

dev.off()

#many points add very little to the graph - how many exactly?
x<-cumsum(1/vi[order(1/vi,decreasing = T)])#order 1/vi, calculate cumSum
#plot(x) the first ~180 points have large influence, then influence decreases rapidly
which.min(x<sum(1/vi)*0.9) #the points 1:186 account for 90% of the total weight
189/447 #42% of the points account for 90% of the total weight
```
In contrast to Danilevsky, we find only a linear change of 48 minutes per 5°N. 




## add climate data to studies

Climate data stations were not necdssarily close to the sampling sites. Solution: Take average climate data from stations within 5° latitude, weighted by euclidian distance
```{r combine}
studies$meanwinter<-NA
studies$sd_winter<-NA
studies$p<-NA
studies$nyears<-NA
studies$beta<-NA 
studies$sd_sd<-NA #standard deviation in winter predictabilities of nearby stations
studies$n_s<-NA

for ( i in 1:nrow(studies)){
  #reduce to +-5 °
  sub<-climate[between(climate$lat,studies[i,"degN"]-5,studies[i,"degN"]+5)& between(climate$lon,studies[i,"degE"]-5,studies[i,"degE"]+5),]

    sub$diffN<-sub$lat-studies[i,"degN"] #calculate distance in latitude
    sub$diffE<-sub$lon-studies[i,"degE"] #same for longitude
    sub$diff<-sqrt(sub$diffN^2+sub$diffE^2) #euclidian distance

    sub<-arrange(sub,diff)[1:5,] #sort and take 5 lowest values = 5 closest stations
  

  
  studies$meanwinter[i]<-weighted.mean(sub$meanwinter,1/sub$diff)
  studies$sd_winter[i]<-weighted.mean(sub$sd_winter,1/sub$diff)
  studies$p[i]<-weighted.mean(sub$p,1/sub$diff)
  studies$nyears[i]<-weighted.mean(sub$nyears,1/sub$diff)
  studies$beta[i]<-weighted.mean(sub$beta,1/sub$diff)
  studies$sd_sd[i]<-sd(sub$sd_winter) #quality control. the predictability of nearby stations should be similar to each other
  studies$n_s <- nrow(sub) #a location may not have 5 stations around

}
studies[is.na(studies$meanwinter)|is.na(studies$med_e),]
#for 22 studies the calculation of diapause reaction norms was not reasonable( studies conducted at unreasonable day lengths), 12 do not have any climate station nearby. for 2 of those (beach 14°N; musolin okinawa), both criteria apply, so there are 32 reaction norms to remove
#mostly small japanese islands missing

studies$meanwinter<-studies$meanwinter + 180
```

```{r remove_noclim}
studies<-studies[!(is.na(studies$meanwinter)|is.na(studies$med_e)),]#415 left
```


## correlation day length at winter onset with latitude  

The relationship of CDL ~ latitude was smaller than expected. Given the climate data, what is the optimal diapause shift with latitude?

```{r cor}
svg("corr_dl_lat_10C5d.svg")
par(mar=c(5,5,3,2)+0.1)
plot(climate$dl[!between(climate$lat, 21, 69)]~climate$lat[!between(climate$lat, 21, 69)], pch=22,cex=0.2,xlab = "Latitude",ylab = "Day length at winter onset",main="",col=NA,bg="darkgrey",bty="n",yaxt="n",cex.axis=1.5,cex.lab=1.5,ylim = c(9,24))
axis(2,at=c(4,8,12,16,20,24),cex.axis=1.5)
climred<-climate[between(climate$lat, 21,69),]
points(climred$dl~climred$lat, pch=22, cex=0.2, bg=1, col=NA)
M<-lm(climred$dl~climred$lat)
lines(x=c(21,69),y=coef(M)[1]+c(21,69)*coef(M)[2],lwd=4,col="darkgrey")

dev.off()
coef(M)[2]*5 *60#    46.3433 

#once more, but only for study sites
studies$expdl<-daylength(studies$degN,studies$meanwinter+182)
par(mar=c(5,5,3,2)+0.1)
plot(studies$expdl~studies$degN,pch=22,cex=1,xlab = "Latitude",ylab = "Day length at winter onset",main="",bty="n",yaxt="n",cex.axis=1.5,cex.lab=1.5,bg=1,col=1)
axis(2,at=c(4,8,12,16,20,24),cex.axis=1.5)


M<-lm(studies$expdl~studies$degN)
lines(x=c(20,70),y=coef(M)[1]+c(20,70)*coef(M)[2],lwd=4,col="darkgrey")
coef(M)[2]*5*60 # 45.04283 

```
We calculated the optimal response based on climate data as 0.74 h/5°N = 46.34 min. If only the study sites are included, this changes to 44.68 min.  Oviously the estimates are very coarse because they are exponential, but danilevskys values of 1h - 90 min are definitely too high. Indeed the expected values are very close to the observed response of 48 minutes /5°N.


## 3. Mean winter onset and mean diapaue timing
In the following chunks we will corerlate mean timing with mean winter conditions, expecting a close relationship due to genetic tracking

#### mean winter  ~ latitude
This is mostly a copy of the cdl ~ latitude part, with only minor changes
```{r mw_degN}
mean(studies$med_cdl)#13.72
c(13.72-1/6, 13.72+1/6) #mean +/- 10 minutes = 13.55, 13.89
daylength(mean (studies$degN), 226:236)
#day length change of 10 minutes is approx 7 days

r<-studies$upper_e-studies$lower_e
quantile(r,0.465)#46.5% have credible interval < 7 days (10 minutes in cdl)

r[r<7]<-7 #changes < 1 wk are irrelevant  
vi <- (r / (2*1.96))^2


mw_N<-rma.mv(yi = med_e ~ degN, V=vi, random = ~(1|order/spec/popid), data = studies)

#estimate +se
summary(mw_N)
#Model Results:#

#         estimate      se     zval    pval   ci.lb   ci.ub     
#intrcpt  317.8246  8.4949   37.4137  <.0001  301.1750  334.4742  ***
#degN      -1.8891  0.1462  -12.9230  <.0001   -2.1757   -1.6026  ***


plot(resid(mw_N))

metanull<-rma.mv(yi = med_e ~ 1, V=vi, random = ~(1|order/spec/popid), data = studies)
metaf.ml<-rma.mv(yi = med_e ~ degN, V=vi, random = ~1|order/spec/popid,data = studies, method = "ML") 
metanull.ml<-rma.mv(yi = med_e ~ 1, V=vi, random = ~1|order/spec/popid,data = studies,method = "ML") 


#nakagawas R²
(metanull$sigma2-mw_N$sigma2)/metanull$sigma2 # -0.138245857       -0.007524803         0.348698927
(sum(metanull$sigma2)-sum(mw_N$sigma2))/sum(metanull$sigma2) #0.1103475
#significance testing
anova(metaf.ml,metanull.ml) #LRT ratio =  136.9356, p<.0001
AIC(metaf.ml)-AIC(metanull.ml)#    -134.9356

n<-table(studies$order) #numbers differ!
names(n)<- paste(names(n)," (", n, ")", sep = "")
```

__plot__  
```{r plot_mw_N}
studies$r<-r

svg("mw_degN.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)


max.size<-(7/(2*1.96))^2; max.size <- 1/max.size 

plot(x=studies$degN, y=studies$med_e, pch=21, cex= 0.3+1.5*(1/vi)/max.size , col=1, bg=studies$col, main = "", xlab = "Latitude (°N)", ylab = "Mean diapause timing",bty="n", cex.axis = 1.5, cex.lab=1.5, ylim=c(170,360)) #cex again set so that max ptsize = 2

legend("topright",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
 
coffs <-  coef(mw_N)
coffs
#   intrcpt degN
#317.824584  -1.889139 
lines(x= range(studies$degN),y = coffs[1]+coffs[2]*range(studies$degN),lwd=3,lty=1)

segments(x0=studies$degN[r<30],y0 = studies$lower_e[r<30],y1=studies$upper_e[r<30],col="darkgrey") #credible intervals > 1 month are not shown

ord<-studies[order(studies$r,as.numeric(studies$order),decreasing = c(T,F), method = "radix"),] 
vi.new <- (ord$r / (2*1.96))^2

for (i in 1:nrow(ord)){
  points(x=ord$degN[i] ,y=ord$med_e[i], pch=21, col=1, bg=ord$col[i],cex=(0.3+1.5*(1/vi.new)/max.size)[i])
}


dev.off()

#many points add very little to the graph - how many exactly?
x<-cumsum(1/vi[order(1/vi,decreasing = T)])
which.min(x<sum(1/vi)*0.9) 
217/447 #49% of the points account for 90% of the total weight
```

#### model mean winter ~ winter_onset  

```{r model_mw}
mw<-rma.mv(yi = med_e ~ meanwinter, V=vi, random = ~(1|order/spec/popid), data = studies)

#null models and ML models (weighted)
mwnull<-rma.mv(yi = med_e ~         1, V=vi, random = ~(1|order/spec/popid), data = studies)
mw.ml<-rma.mv(yi = med_e ~ meanwinter, V=vi, random = ~1|order/spec/popid,data = studies, method = "ML") 
mwnull.ml<-rma.mv(yi = med_e ~      1, V=vi, random = ~1|order/spec/popid,data = studies,method = "ML") 
```

_summary statistics_    
```{r mw_sumstat}
#estimate +se
summary(mw)
#Model Results:#

#            estimate       se     zval    pval    ci.lb     ci.ub     
#intrcpt      86.4068  12.3836   6.9775  <.0001  62.1354  110.6782  ***
#meanwinter    0.5002   0.0354  14.1157  <.0001   0.4308    0.5697  ***

plot(resid(mw))

#nakagawas R²
(mwnull$sigma2-mw$sigma2)/mwnull$sigma2  #-0.08537631  0.07625613   0.38816284
(sum(mwnull$sigma2)-sum(mw$sigma2))/sum(mwnull$sigma2) # 0.1703643

#significance testing
anova(mw.ml,mwnull.ml) #LRT ratio =  158.9401, p<.0001
AIC(mw.ml)-AIC(mwnull.ml)#     -156.9401

```

Okay the R² is actually worse than for CDL ~ latitude, but more relevant for fitness.

__plot__  
```{r plot_mw}
studies$r<-r

svg("mw_meanwinter.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)


max.size<-(7/(2*1.96))^2; max.size <- 1/max.size 

plot(x=studies$meanwinter, y=studies$med_e, pch=21, cex= 0.3+1.5*(1/vi)/max.size , col=1, bg=studies$col, main = "", xlab = "Mean winter onset", ylab = "Mean diapause timing",bty="n", cex.axis = 1.5, cex.lab=1.5,xlim=c(170,400), ylim=c(170,400)) #cex again set so that max ptsize = 2

legend("topleft",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
 
coffs <-  coef(mw)
coffs
#   intrcpt meanwinter 
#77.4392099  0.5201638 
lines(x= range(studies$meanwinter),y = coffs[1]+coffs[2]*range(studies$med_e),lwd=3,lty=1)

segments(x0=studies$meanwinter[r<30],y0 = studies$lower_e[r<30],y1=studies$upper_e[r<30],col="darkgrey") #credible intervals > 1 month are not shown

ord<-studies[order(studies$r,as.numeric(studies$order),decreasing = c(T,F), method = "radix"),] 
vi.new <- (ord$r / (2*1.96))^2

for (i in 1:nrow(ord)){
  points(x=ord$meanwinter[i] ,y=ord$med_e[i], pch=21, col=1, bg=ord$col[i],cex=(0.3+1.5*(1/vi.new)/max.size)[i])
}
dev.off()
```

Mean winter onset increases roughly linearly with latitude. The critical day length that is associated with it, however, increases exponentially. The insects only respond linearly, so the gap between mean winter onset and mean timing widens with increasing latitude.  This explains why the curve is bent. the ideal line would roughly follow that of mites (which is much steeper) with a slope of 1. My interpretation: either insects cannot their CDL "far enough", i.e. evolutionary constraints, or they co-opt other mechanisms such as cold tolerance
In any case there is a strange intercept that requires explanation, mean diapause timing is ~ 77 days earlier than one would expect. 


## variance composition

```{r}
png("variance_composition.png")
plot(studies$med_s~studies$med_r,xlab="variance composition",ylab ="responsiveness",pch=22, cex=0.5,bg=1)
text(1,0,"plasticity",pos=2)
text(0,0,"bet-hedging",pos=4,xpd=T)
dev.off()

```


## 4. correlation of responsiveness with winter severity  
Phenotypic variation only makes sense if there is sufficient envrionmental change. Thus responses by either plasticity or bet-hedging should only occur in environments with harsh enough winters (or actually a difference between summer and winter). But there is not enough variation in responsiveness to do any model:

```{r responsiveness}
hist(studies$med_s,breaks=100)
```

## 5. variance composition vs day length predictability  

```{r varcomp_sdw}
x<-studies # a backup

r <- studies$upper_r-studies$lower_r
r[r<0.05]<-0.05 #changes < 0.05 are irrelevant
vi<- (r / (2*1.96))^2 


mod <- rma.mv(med_r ~ sd_winter,vi, random = ~ 1 | order/spec/popid, data=studies)
plot(rstandard(mod)$z, ylim=c(-3,3), pch=19) #not very nice
studies$yti <- transf.logit(studies$med_r)
studies$vti <- vi / (studies$med_r * (1 - studies$med_r))^2
mod <- rma.mv(yti ~ sd_winter, vti, random = ~ 1 | order/spec/popid, data=studies)

mod
plot(rstandard(mod)$z, pch=19)
plot(studies$sd_winter, studies$yti, pch=19)
x<-seq(5,25,length.out=1000) #will be used to plot prediction line
 y=coef(mod)[1]+x*coef(mod)[2] #inverse logit transform this to get prediction

 
 #null models and ML models (weighted)
modnull<-rma.mv(yti  ~ 1, vi, random = ~(1|order/spec/popid), data = studies)
mod.ml<- rma.mv(yti ~ sd_winter,vi, random = ~ 1 | order/spec/popid, data=studies, method = "ML") 
modnull.ml<-rma.mv(yti ~ 1, vi, random = ~(1|order/spec/popid), data = studies, method = "ML") 
```
_summary statistics_    
```{r sdw_sumstat}

#estimate +se
summary(mod)
#Model Results:
#intrcpt      1.6362  0.2747   5.9567  <.0001   1.0978   2.1746  ***
#sd_winter   -0.1061  0.0178  -5.9753  <.0001  -0.1409  -0.0713  ***
transf.ilogit(-0.1061)# 0.4734999


#nakagawas R²
(modnull$sigma2-mod$sigma2)/modnull$sigma2   #-5.388152e+06  3.142705e-01  6.164752e-01
(sum(modnull$sigma2)-sum(mod$sigma2))/sum(modnull$sigma2) #0.4932114

#significance testing
anova(mod.ml,modnull.ml) #LRT ratio =  30.9318, p<.0001
AIC(mod.ml)-AIC(modnull.ml)# -28.9318

```
__plot__ 
```{r plot_sdw}

max.size<-(0.05/(2*1.96))^2; max.size <- 1/max.size 


studies$r <- r
svg("varc.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)

plot(x=studies$sd_winter, y=studies$med_r, pch=21, cex= 0.3+1.5*(1/vi)/max.size , col=1, bg=studies$col, main = "", xlab = "Winter unpredictability", ylab = "Ratio of varaiance components",bty="n", cex.axis = 1.5, cex.lab=1.5,xlim=c(0,25), ylim=c(0,1)) #cex again set so that max ptsize = 2
#legend("bottomright",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
coffs <-  coef(mod)
lines(x= x,y=transf.ilogit(y),lwd=2)

#433*(1/0.1)/sum(r) = 0.8869712
segments(x0=studies$sd_winter[studies$r< 0.1],y0 = studies$lower_r[studies$r<.1],y1=studies$upper_r[studies$r<0.1],col="darkgrey") #credible intervals > 0.1 not shown 
studies$cex <- 0.3+1.5*(1/vi)/max.size
ord<-studies[order(studies$r,as.numeric(studies$order),decreasing = c(T,F), method = "radix"),] #to make sure smalles points are printed last, on top of the larger points. order is included so that dipterns do not completely dominate pic

for (i in 1:nrow(ord)){
  points(x=ord$sd_winter[i] ,y=ord$med_r[i], pch=21, col=1, bg=ord$col[i], cex=ord$cex[i])
}
dev.off()
```



### 6. Variance composition vs. temperature predictability  
```{r varcomp_sdt}

varc_tp <- rma.mv(yti ~ beta, vti, random = ~ 1 | order/spec/popid, data=studies)

plot(rstandard(varc_tp)$z, pch=19)
plot(studies$beta, studies$yti, pch=19)
x<-seq(5,25,length.out=1000) #will be used to plot prediction line
 y=coef(varc_tp)[1]+x*coef(varc_tp)[2] #inverse logit transform this to get prediction

 
 #null models and ML models (weighted)
modnull <- rma.mv(yti ~ 1, vti, random = ~ 1 | order/spec/popid, data=studies)
modnull.ml <- rma.mv(yti ~ 1, vti, random = ~ 1 | order/spec/popid, data=studies, method="ML")
varc_tp.ml<- rma.mv(yti ~ beta ,vti, random = ~ 1 | order/spec/popid, data=studies, method = "ML") 


#summary statistics
#estimate +se
summary(varc_tp)
#intrcpt    0.5690  0.1922   2.9599  0.0031   0.1922  0.9458  **
#beta      -0.1127  0.3056  -0.3689  0.7122  -0.7116  0.4862    
transf.ilogit(-0.1127)# 0.4718548


#nakagawas R²
(modnull$sigma2-varc_tp$sigma2)/modnull$sigma2  #   -0.0224784137 -0.0000118826 -0.0026317557
(sum(modnull$sigma2)-sum(varc_tp$sigma2))/sum(modnull$sigma2) #-0.001381472

#significance testing
anova(varc_tp.ml,modnull.ml) #LRT ratio =  0.1372 , p  = 0.7111
AIC(varc_tp.ml)-AIC(modnull.ml)#  1.862777
x<-seq(min(studies$beta),max(studies$beta),length.out=1000)
 y=coef(mod)[1]+x*coef(varc_tp)[2] #inverse logit transform this to get prediction
```
__plot__  
```{r plot_sdt}

max.size<-(0.05/(2*1.96))^2; max.size <- 1/max.size 


studies$r <- r
svg("var_beta.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)

plot(x=studies$beta, y=studies$med_r, pch=21, cex= 0.3+1.5*(1/vi)/max.size , col=1, bg=studies$col, main = "", xlab = "Temperature unpredictability", ylab = "Ratio of varaiance components",bty="n", cex.axis = 1.5, cex.lab=1.5,xlim=c(-1,1.5), ylim=c(0,1)) #cex again set so that max ptsize = 2
#legend("bottomright",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
lines(x= x,y=transf.ilogit(y),lwd=2)


segments(x0=studies$beta[studies$r< 0.1],y0 = studies$lower_r[studies$r<.1],y1=studies$upper_r[studies$r<0.1],col="darkgrey") #credible intervals > 0.1 not shown 
studies$cex <- 0.3+1.5*(1/vi)/max.size
ord<-studies[order(studies$r,as.numeric(studies$order),decreasing = c(T,F), method = "radix"),] #to make sure smalles points are printed last, on top of the larger points. order is included so that dipterns do not completely dominate pic

for (i in 1:nrow(ord)){
  points(x=ord$beta[i] ,y=ord$med_r[i], pch=21, col=1, bg=ord$col[i], cex=ord$cex[i])
}
dev.off()
```


### 7. conservative bet-hedging 
```{r}
#3 models: 
# mean winter residuals vs predictability by day length
# mean winter residuals vs predictability by temperature
# mean winter residuals vs variance composition residuals , test whether dbh and cbh trade off against each other

r<-studies$upper_e-studies$lower_e
r[r<7]<-7 #changes < 1 wk are irrelevant  
vi <- (r / (2*1.96))^2


studies$res_mw<-rstandard(mw)$z
cbh_dl <- rma.uni(res_mw~sd_winter, vi = vi, data= studies)
cbh_t <- rma.uni(res_mw ~ beta, vi = vi , data=studies)

studies$res_varc <- rstandard(mod)$z
cbh_dbh<- rma.uni(res_mw ,vi, mod  = res_varc ,data=studies) 



summary(cbh_dl)
#           estimate      se     zval    pval    ci.lb   ci.ub   
#intrcpt      0.3169  0.3223   0.9833  0.3255  -0.3147  0.9485   
#sd_winter   -0.0117  0.0293  -0.3998  0.6893  -0.0692  0.0457    

#R² = 0
anova(cbh_dl)# 0.1598, p =  0.6893
#AIC diff:  -1.65269


svg("cbh_dl.svg", width = 10, pointsize=12)
par(mar = c(5,5,0,0)+0.1)
plot(studies$res_mw ~ studies$sd_winter, pch=21, cex= 0.3+1.5*(1/vi)/(max(1/vi)) , col=1, bg=studies$col, main = "", ylab = "Residulas diapause timing", xlab = "Winter Unpredictability (day length)",bty="n", cex.axis = 1.5, cex.lab=1.5,xlim=c(0,26), ylim=c(-3,4)) #cex again set so that max ptsize = 2
#legend("bottomright",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
abline(coef(cbh_dl),lwd=2)
dev.off()


summary(cbh_t)
#         estimate      se    zval    pval    ci.lb   ci.ub   
#intrcpt    0.2211  0.2294   0.9638  0.3351  -0.2286  0.6708   
#beta      -0.0709  0.5755  -0.1231  0.9020  -1.1989  1.0572   

anova(cbh_t)
# 0.0152, p = 0.9020

svg("cbh_t.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)
plot(studies$res_mw ~ studies$beta, pch=21, cex= 0.3+1.5*(1/vi)/(max(1/vi)) , col=1, bg=studies$col, main = "", ylab = "Residulas diapause timing", xlab = "Winter unpredictability (temperature)",bty="n", cex.axis = 1.5, cex.lab=1.5,xlim=c(-1,1.5), ylim=c(-3,4)) #cex again set so that max ptsize = 2
#legend("bottomright",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
abline(cbh_t,lwd=2)
dev.off()

svg("cbh_dbh.svg",width=10,pointsize=12)
par(mar = c(5,5,0,0)+0.1)
plot(studies$res_mw ~ studies$res_varc, pch=21, cex= 0.3+1.5*(1/vi)/(max(1/vi)) , col=1, bg=studies$col, main = "", ylab = "Residulas diapause timing", xlab = "Residuals variance composition",bty="n", cex.axis = 1.5, cex.lab=1.5,xlim=c(-3,3.5), ylim=c(-3,3)) #cex again set so that max ptsize = 2
#legend("bottomright",legend=names(n), col=rep(1,8), pt.bg=unique(studies$col), pch=21, bty="n", ncol=1,cex=1.5)
x<-seq(min(studies$res_varc),max(studies$res_varc), length.out=1000)
y<-coef(cbh_dbh)[1]+coef(cbh_dbh)[2]*x
lines(y~x,lwd=2)
dev.off()
```





### how do these climate pics change with parameters?  
The following chunk correlates day length at winter onset with latitude, for a variety of parameter combinations  
```{r}
url<-"ghcnd-stations.txt"
#"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
#this dataset is fixed-width delimited, requiring a few additional steps
locations<-read.fwf(
  file=url
  ,sep="!",na.strings=c("NA","-999.9"), #sep = ! because ! does not exist in dataset - > dataset is fixed-width and should have no additional separators
  widths=c(11, 9, 10, 7,2,35)
)

nams<-seq(0,150,5)
rsq<-rep(NA,length(nams))
rsq2<-rsq

for ( t in 1:length(rsq)){
#get data
studies <- read.table("lit_extract/mcmcresults.txt") #reload for each i because some with meanwinter= NA get erased every time
studies<-studies[order(studies$order),]
studies$col<-as.numeric(studies$order)
studies$col<-hsv(studies$col/10,1,1)

reslist<-read.table(paste("clim_calc/output/results_",nams[t],"-5.txt", sep =""),na.string = c("NA","-9999","-999.9"))
names(reslist)<-c("ID","meanwinter","sd_winter","p","nyears","ndays_300","ndays_350","ndays_365")
reslist<-reslist[1:26804,] # if the same data was appended twice
climate<-merge(locations,reslist,by=1)
rm(reslist)
names(climate)<-c("ID","lat","lon","alt","name","no_idea","meanwinter","sd_winter", "p",  "nyears" ,  "ndays_300"  ,"ndays_350",  "ndays_365" )
climate<-climate[!is.na(climate$meanwinter),] #because these cannot be used anyway
climate<-climate[climate$lat<70,] #at higher latitudes winter onset is at midsummer
climate$dl <- daylength(climate$lat,climate$meanwinter+182)

studies$meanwinter<-NA
studies$sd_winter<-NA
studies$nyears<-NA
studies$sd_sd<-NA #standard deviation in winter predictabilities of nearby stations
studies$n_s<-NA


#combine with climate data
for ( i in 1:nrow(studies)){
  #reduce to +-5 °
  sub<-climate[between(climate$lat,studies[i,"degN"]-5,studies[i,"degN"]+5)& between(climate$lon,studies[i,"degE"]-5,studies[i,"degE"]+5),]

    sub$diffN<-sub$lat-studies[i,"degN"] #calculate distance in latitude
    sub$diffE<-sub$lon-studies[i,"degE"] #same for longitude
    sub$diff<-sqrt(sub$diffN^2+sub$diffE^2) #euclidian distance

    sub<-arrange(sub,diff)[1:5,] #sort and take 5 lowest values = 5 closest stations
  

  
  studies$meanwinter[i]<-weighted.mean(sub$meanwinter,1/sub$diff)
  studies$sd_winter[i]<-weighted.mean(sub$sd_winter,1/sub$diff)
  studies$nyears[i]<-weighted.mean(sub$nyears,1/sub$diff)
  studies$sd_sd[i]<-sd(sub$sd_winter) #quality control. the predictability of nearby stations should be similar to each other
  studies$n_s <- nrow(sub) #a location may not have 5 stations around

}
studies <- studies[!(is.na(studies$meanwinter)|is.na(studies$upper_e)),]
studies$meanwinter <- studies$meanwinter + 182 #was counted in days since midsummer


#model mean winter
r<-studies$upper_e-studies$lower_e 
r[r<7]<-7 #changes < 1 wk are irrelevant  
vi <- (r / (2*1.96))^2
mw<-rma.mv(yi = med_e ~ meanwinter, V=vi, random = ~(1|order.x/spec/popid), data = studies)
mwnull<-rma.mv(yi = med_e ~         1, V=vi, random = ~(1|order.x/spec/popid), data = studies)
rsq[t]<-(sum(mwnull$sigma2)-sum(mw$sigma2))/sum(mwnull$sigma2)

#model variance composition
r <- studies$upper_r-studies$lower_r
r[r<0.05]<-0.05 #changes < 0.05 are irrelevant
vi<- (r / (2*1.96))^2 
studies$yti <- transf.logit(studies$med_r)
studies$vti <- vi / (studies$med_r * (1 - studies$med_r))^2
mod <- rma.mv(yti ~ sd_winter, vti, random = ~ 1 | order.x/spec/popid, data=studies)
modnull<-rma.mv(yti  ~ 1, vi, random = ~(1|order.x/spec/popid), data = studies)
rsq2[t]<-(sum(modnull$sigma2)-sum(mod$sigma2))/sum(modnull$sigma2)
}
write.table( rsq, "rsq.txt",row.names=F)
write.table( rsq2, "rsq2.txt",row.names=F)
```


```{r}
plot(rsq,pch=19, xlab ="Temperature threshold",xaxt="n", ylab = "R² diapause timing - winter onset",bty="n")
lines(rsq)
axis(1, at= 1:length(rsq2),labels=nams/10)
abline(v=21)

plot(rsq2,pch=19, xlab ="Temperature threshold",xaxt="n", ylab = "R² variance composition - winter predictability", bty = "n")
lines(rsq2)
axis(1, at= 1:length(rsq2),labels=nams/10)
abline(v=21)
```




