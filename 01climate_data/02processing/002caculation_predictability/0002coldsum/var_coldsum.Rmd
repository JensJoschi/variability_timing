---
title: "var_cold_sums"
author: "Jens Joschinski"
date: "February 1, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# General description  

## Aim  
The aim of this project is to correlate climate variability with variability in seasonal timing. Is the slope in seasonal responses a bet-hedging trait, i.e., is it adaptive to spread one's timing in more variable conditions?  

### Overview  

This script uses data from the GHCN dataset, which was processed with a perl script (folder 001data_conversion/conversion.pl), and has been merged with a climate station description from the NOAA server. This script calculates variability in winter onset for each station:

- The data should (over all years) follow a sine-curve. Find the local maxima of this curve (summer)
- starting from each summer, count the number of cold days (defined as days with average temperature below 5°C). Winter arrived at the 10th cold day
- calculate circular variance in winter arrival


### Specific description  

The data was generated with R version `r getRversion()`. It uses the GHCN-daily dataset by NOAA:
```{r, echo =F}
library(textreadr)
text<- read_document("01raw/ghcnd_all/ghcnd-version.txt")
print (text[1])
```


### Script  

```{r}
load(paste(getwd(),"/02processing/001data_conversion/Rworkspace.RData",sep=""))
```


For testing purposes, only a small subset of is used (e.g. 20-60°N, -1 to +1 °E)
```{r}
#testset<-newset[newset$lat>-20,]
#testset<-testset[testset$lat<60,]
testset<-newset[newset$lon>(20),]
testset<-testset[testset$lon<(30),]
#table(testset$ID)
#testset<-droplevels(testset)
#testset<-newset

```



The function "daily_t" will use the data provided by one station. It will append all daily temperature recordings of all years (up to 145 years \* 12 months \* 31 days ) into a single vector, filling up with NAs as needed. 

```{r}
daily_t <- function (station){
station<-station[order(station[,2],station[,3],na.last=F),] #sorts by year and month
station<-droplevels(station)

vals<-NA
#for each year:
for(y in 1:length(unique(station$year))){
    year<-station[station[,2]==unique(station[,2])[y],] #reduces dataset to 1 station, 1 year (max 31*12 points)
  
#make 12*31 matrix and fill it with daily data
  mat <- matrix(NA,12,31)
  
   for (i in 1:nrow(year)){ #i=month
    mon<-as.numeric(year[i,3])
    mat[mon,1:31]<-as.numeric(year[i,4:34])
   }
  vals<-c(vals,as.numeric(t(mat)))
}
return (vals)
}


```



The function 'get_nls' takes the daily temperatures of one station (which is supplied as single vector), and applies a non-linear least squares model which estimates intercept, phase angle and amplitude of a sine curve.

```{r}
get_nls <- function (vals,s_A=400,s_phi=pi/2,s_c=200){#s_... are starting values for nls function
  
x<-1:length(vals)
data<-data.frame(x,vals)

res <- nls(vals ~ A*cos(x*2*pi/372+phi)+C, data=data, start=list(A=s_A,phi=s_phi,C=s_c),upper=c(500,2*pi,300),algorithm="port",lower=c(0,0,0)) #372 and not 365.25, because a vector of 12*31 was used before (filling up e.g. 31.feb with NA). This made coping with leap years easier

co <- coef(res)
return(co)
}
```

The following chunk will apply a nls regression on the climate data of each station. The daily temperatures over ~20 years are expected to follow a sine-curve pattern with a period of 1 year. The curve is determined by the following parameters
- a constant c that defines the average temperature throughout the year. It is around 20°C in temperate climates, around 30°C at the equator.
- the amplitude A, which quantifies the difference between winter and summer temperatures. A should decrease with proximity to the poles
- the phase angle phi. Phi defines at what time of the year maximum temperatures occur. It should be close to midsummer in all stations of the northern hemisphere, and around midwinter in the southern hemisphere. june 25 is the julian day 176/177. BEcause the function daily_t assumes 12*31 = 372 days, it is around day 170 in this dataset. This corresponds to a phase angle of 170/372 \*(2\*pi) = 2.87.  


```{r}
#,error=TRUE}
co_avg=NA
lat=NA
lon=NA
phi<-data.frame(co_avg,lon,lat)

wrap_error = function (vals,s_A,s_phi,s_c) {
  tryCatch(get_nls(vals,s_A,s_phi,s_c),
                     warning = function (w)  {return(FALSE)},#print(paste("warning at ", i))
                     error   = function (e)  {return(FALSE)})#print(paste("error at: ",i));
}

for (i in 1:length(unique(testset$ID))){

temp_set<-testset[testset$ID==unique(testset$ID)[i],]
vals<-daily_t(temp_set)

co<-wrap_error(vals,s_A=400,s_phi=pi/2,s_c=200)
if (co[1]==FALSE){co<-wrap_error(vals,s_A=40,s_phi=pi,s_c=200)}#print ("retry1");
if (co[1]==FALSE){co<-wrap_error(vals,s_A=40,s_phi=2*pi,s_c=200)}#print ("retry2");
if (co[1]==FALSE){print (paste("failed in ",i));co[2]<-99}
phi[i,1]<-co[2]
phi[i,2]<-temp_set[1,35]
phi[i,3]<-temp_set[1,36]
}

phi<-phi[is.na(phi[,1])==F,]
plot(phi[,2]~phi[,3],bg=rgb(sin(phi[,1])+1,1,sin(phi[,1])+1,maxColorValue = 2),pch=21,col=NA)
#add legend
for (i in seq(0,2*pi,0.1)){
  points(x=20 + i/2,y = 0,bg=rgb(sin(i)+1,1,sin(i)+1,maxColorValue = 2),col=NA,pch=22)
}
#left side: phi =0, right side: phi = 2pi

```
