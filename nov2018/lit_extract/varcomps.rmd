---
title: "read slopes"
author: "Jens Joschinski"
date: "March 15, 2018"
output: 
  md_document:
  variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
#library(plyr)
library(tidyr)
#library(textreadr)
#library(drc)
#library(sandwich)
#library(lmtest)
#library(geosphere)
#library(metafor)
library(rjags)
```


# General description  
## Project aim  
The aim of this project is to correlate means and variance of diapause timing with climate means and climate predictability.

## Script overview  
We searched the Web of Science database for photoperiodic response curves of arthropods and selected 57 studies with individual reaction norms (dose-response curves) for 426 populations. The data was extracted with webplotdigitizer. For each population the most important columns are data$number ~ data$dl2.
This script does an MCMC to get estimates fo slopes, midpoints and upper and lower limit. It then calculates the variance within and between datapoints based on the same MCMC approach.


## load data  
One study (7 populations) reported the slope and midpoint from drc analyiss directly. The script concentrates on the remaining populations

```{r load_data}
data<-read.table("nov2018/lit_extract/variance_comp.csv", header=T,sep=";")
#changes to .xlsx: Diatraea had gen + sp in genus column; Laodelphax has added space in hou
length(unique(data$ID)) #57 studies that can be used for slope calculation
length(unique(data$spec)) #45 species
length(unique(data$genus)) #32 genera
data<-unite(data,"popid",c("ID","pop","genus","spec"),sep=".",remove=F)
length(unique(data$popid)) #433 populations (not 440 because lankinen 2013 is not in here)


#summary of #pops per region and level of detail for sample sizes

t<-data.frame(unique(data$popid))
t$reg<-NA
t$nMethod<-NA
#each unique pop has multiple rows in dataset (1 per day length)
#get this subset, take region and nMethod from first line (or use unique)
for ( i in 1:nrow(t)){ 
   t$reg[i]<-unique(data[data$popid==t[i,1],5])
   t$nMethod[i]<-unique(data[data$popid==t[i,1],9])
}
table(t$reg) #unfortunately, the information was converted to values
levels(data$region)
#Asia 16
#Europe (including caucasus): 117
#Japan 242
#US 58
#japan has 55.6% of the populations, 46.8 % of the data


table(t$nMethod)
levels(data$nmethod)

#accurate: 96
#global average:288
#pop level: 16
#NA 33


#check whether some studies have <3 pops
t<-data.frame(unique(data$ID))
t$pop<-NA
for ( i in 1:nrow(t)){ 
  t$pop[i]<-length(unique(data[data$ID==t[i,1],1]))
}


data$n2[is.na(data$n2)]<-100
#data$n2[data$n2<10]<-data$n2[data$n2<10]*10 #n = 5 may mean 5 replicates with 200 individuals each --> percentages may be 86.5% and n=5 will lose those an make it 100%.


data$perc[data$perc<0]<-0
data$perc[data$perc>100]<-100
data$n2<-round(data$n2)
data$number<-(data$perc/100) * data$n2
data$number<-floor(data$number)
number<-length(unique(data$popid))#433
data$n<-data$number/data$n2

#check whether some studies have <4 dls
#sort (table(data$popid))
#get a vector of form "ID-population" for later labelling
nams<-unite(data,"nams",c("ID","pop"), sep = "-", remove=T)$nams 
```

## own algorithm  

This is only for testing purposes and will beerased eventually. 
```{r own_algorithm}
#trying with self-made algorithm

logcurve<-function(x,b,c,d,e){(d-c)/(1+exp(b*(x-e)))+c} #4-paramter dose-response curve

build_proposfunc <- function(input,jump,dl2){ #lets the four parameters of the dose-response curve vary, but imposes box constraints (0-100%)
  out<-rnorm(4,input,jump)
  #replace limits outside 0 and 100%:
  if (out[2]<0){out[2]<- -1*out[2]}
  if (out[2]>1){out[2]<-1}
  
  if (out[3]>1){out[3]<- 2-out[3]}
  if (out[3]<out[2]){out[3]<-out[2]}
  
  #constrain midpoint to fall within data limits
  if (out[4]>max(dl2)){out[4] <- max(dl2)}
  if (out[4]<min(dl2)){out[4] <- min(dl2)}
  return(out)
}
  
mcmc<-function(test, iter, jump){
  
  accept = F
  tracer<-data.frame(rep(NA,iter),rep(NA,iter), rep(NA,iter), rep(NA,iter))
  #names(tracer)<- c("b","c","d","e") #this will store the results, 1 line = 1 markov chain step

  #initialize with b=2,c= 0, d= 1, e = 15
  tracer[1,]<-c(2,0,1,15) 
  pred <- logcurve(x=test$dl2,b=tracer[1,1], c=tracer[1,2],d=tracer[1,3],e = tracer[1,4])
  ll_old<-sum(dbinom(test$number,test$n2,pred,log=T))


  for (i in 2:iter){
    propos<-build_proposfunc(as.numeric(tracer[i-1,]),jump, test$dl2) #proposes new fit, but this fit has still to be evaluated against the last one
  
    #calculate fit with new combination
    pred <- logcurve(x=test$dl2,b=propos[1], c=propos[2],d=propos[3],e = propos[4])
    ll_new<-sum(dbinom(test$number,test$n2,pred,log=T))
  
   #compare LLs

   if (ll_new>ll_old){ 
  accept <-T
   }else{
     p <- exp(ll_new-ll_old)#diff not ratio because these are log-likelihoods
      if (runif(1) < p) {accept<-T}
   }
  
   if (accept == T){    
     ll_old<- ll_new
     tracer[i,]<-propos
    }else{
        tracer[i,]<-tracer[i-1,]
      }
  

  accept<-F
  }
#remove burn-in
  tracer<-tracer[(iter/10):iter,]

  #1-mean(duplicated(tracer))

  return(tracer)
}

calc_var<-function(tracer){
  
  within <- rep(NA,nrow(tracer))
  between <- rep(NA,nrow(tracer))


  for ( i in 1:nrow(tracer)){
   x<-seq(tracer[i,4]-12,tracer[i,4]+12, length.out =1000)
   y<-logcurve(x,tracer[i,1],tracer[i,2],tracer[i,3],tracer[i,4])

   within[i]<- sum(y*(1-y))/1000
   between[i]<-sd(y)^2 
  }


  tracer[,5]<-within
  tracer[,6]<-between
  return(tracer)
}


#iter <-100000
iter<-1000#for testing purposes
jump <-c(1,0.1,0.1,0.1)

number<-10 #for testing purposes
for (dataset  in 1:number) {
  currpop <- unique(data$popid)[dataset]
  currdat<-data[data$popid==currpop,]
  tracer <- mcmc(currdat, iter, jump)
  tracer<-calc_var(tracer)
  write.table(tracer,paste(currpop,".txt"))
}  
```

```{r}
summary<-data.frame(popid=rep(NA,number), e_l=rep(NA,number), e_m = rep(NA,number), e_h=rep(NA,number), w_l=rep(NA,number), w_m=rep(NA,number), w_h=rep(NA,number), bet_l=rep(NA,number), bet_m=rep(NA,number), bet_h=rep(NA,number))
for (dataset in 1:number){
  t<-read.table(paste(unique(data$popid)[dataset],".txt"))
  summary$popid[dataset] <- unique(data$popid)[dataset]
  summary$e_l[dataset] <- quantile(t[,4],0.025)
  summary$e_m[dataset] <- quantile(t[,4],0.5)
  summary$e_h[dataset] <- quantile(t[,4],0.975)
  
  summary$w_l[dataset] <- quantile(t[,5],0.025)
  summary$w_m[dataset] <- quantile(t[,5],0.5)
  summary$w_h[dataset] <- quantile(t[,5],0.975)
  
  summary$bet_l[dataset] <- quantile(t[,6],0.025)
  summary$bet_m[dataset] <- quantile(t[,6],0.5)
  summary$bet_h[dataset] <- quantile(t[,6],0.975)
  


}

summary$range = summary$e_h-summary$e_l
plot(NA,xlim= c(5,20),ylim= c(1,number),xlab = "CDL", ylab = "study index")
segments(x0 = summary$e_l,y0=1:number,x1 = summary$e_h,y1=1:number,col=1) #"lightgrey")
points(x=summary$e_m,y = 1:number,pch=22,bg=1)

summary$range = summary$w_h-summary$w_l
plot(NA,xlim= c(0,0.25),ylim= c(1,number),xlab = "variance within environments (bet-hedging)",ylab = "Index")
segments(x0 = summary$w_l,y0=1:number,x1 = summary$w_h,y1=1:number,col=1) #"lightgrey")
points(x=summary$w_m,y = 1:number,pch=22,bg=1)


summary$range = summary$bet_h-summary$bet_l
plot(NA,xlim= c(0,0.25),ylim= c(1,number),xlab = "variance between environments (plasticity)",ylab = "Index")
segments(x0 = summary$bet_l,y0=1:number,x1 = summary$bet_h,y1=1:number,col=1,xpd=T) #"lightgrey")
points(x=summary$bet_m,y = 1:number,pch=22,bg=1)
  
```



### rjags  

Markov Chain Monte Carlo simulation. Data is saved as .rds objects, so this chunkdoes not need to be repeated
```{r jags}
#the model in BUGS code for jags
#instead of saving as separate file this is put into a string, and later opened with textConnection(model_string)

model.string <- 
"model {
  
  #likelihood function
	for (i in 1:N){
		y[i] ~ dbin(success[i],trials[i])     #this incorporates sample size per point (number of individuals per day length)
		success[i] <- (d-c)/(1+exp(b*(x[i]-e)))+c #4-parameter logit curve
	}

	#priors
	b ~dunif(-100,100)       
	c ~dunif(0,1)
	d ~dunif(c,1)             #constrained to be bigger than c
	e ~dunif(min(x),max(x))   #constrained within range(day lengths)

}"


iter<-10000
chains <-4
#number<-2 #for testing purposes

for (dataset  in (1:number)) {
  currpop <- unique(data$popid)[dataset]
  currdat<-data[data$popid==currpop,]
  
  
  model <- jags.model(textConnection(model.string), 
                    data = list(y=currdat$number, x= currdat$dl2, N = nrow(currdat),trials = currdat$n2), 
                    n.chains=chains, n.adapt=1000)

  out <- coda.samples(model,   c( 'b', 'c', 'd', 'e'), iter)
  outname <- paste("model_", currpop, sep="")
  assign(outname, out)
  save(list = outname ,file = paste(outname, ".rds", sep = ""))
  rm(list= outname)
}

```


## calculation of variance components
We follow the trace of the MCMC (which was saved in previous step), and calculate the variance at each iteration. The frequency distribution of variance estimates is used to get estimate  + credible interval.
```{r calc_variance}

logcurve<-function(x,b,c,d,e){(d-c)/(1+exp(b*(x-e)))+c} #4-paramter dose-response curve

calc_var <- function(row){
  b<-row[1]
  c<-row[2]
  d<-row[3]
  e<-row[4]
  
  x<-seq(e-12,e+12, length.out =1000)
  y<-(d-c)/(1+exp(b*(x-e)))+c
  w <- sum(y*(1-y))/1000 #variance within
  b <- sd(y)^2  #variance between
  c(w, b,  b+w, b/(b+w)) #retursn variance within, variance between, their sum, and the ratio of plasticity 
}


   #between[i]<-sd(y)^2 


for (dataset in 1:number){
  currpop <- unique(data$popid)[dataset]
  outname <- paste("model_", currpop, sep="")
  load(paste(outname, ".rds", sep=""))
  sav <- data.frame(rep(NA, iter))
  for (i in (1:chains)){
    dat <- get(outname)[[i]]
    temp <- apply(dat, 1, calc_var)
    temp<-t(temp)

    sav <- cbind(sav, temp, dat[,4]) #order: within, between, sum, ratio, e, within ...[4 times]
  }
  sav<-sav[,-1]
  rm(list=outname)
  write.table(sav, file = paste("res_", currpop, ".txt", sep = "" ), row.names=F, col.names=F)
}

```


### forest plots
```{r}

plot_forest <- function (column, xlab, xlim, ylim, num = c(1,40), scale ){
r <- num[2] - num[1]
plot(NA, xlim = xlim, xlab = xlab, ylim = ylim, ylab = "", bty="n", yaxt="n" )
abline(h=1:r, col="lightgrey")

h<--1 #tracks line of the forest plot
for (dataset in (num[1]:num[2])){
  h<-h+1
  currpop <- unique(data$popid)[dataset]
  res<-read.table(file = paste("res_", currpop, ".txt", sep = "" ))

   for ( i in 1:chains){
    dens<-density(res[,5*(i-1)+column])
    lines(x=dens$x,y = h+ scale * dens$y/max(dens$y),col=5-i)
   }
  abline(h=h,col="lightgrey")
  segments (x0 = quantile(res[,column], 0.025), x1= quantile(res[,column], 0.975), y0 = h,y1 = h,col=4) #draw 95% credible interval for first chain
  points(x =median (res[,column]), y = h, cex=0.5, pch=22, bg=1)
  text(x=xlim[2], y = h+0.5, pos = 2, labels = unique(data$ID[data$popid == currpop]), cex = 0.8, col ="darkgrey") #author
  text(x=xlim[1], y = h+0.5, pos = 4, labels = unique(data$pop[data$popid==currpop]), cex = 0.8, col = "darkgrey") #pop
}

}



## variance within environments
l <- 50*0:9
pdf("forest_within.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 1, xlab = "Variance within", xlim = c(0,0.25),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[3]+1,l[4]), 0.9)
#next page
plot_forest(1, "Variance within",c(0,0.25), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(1, "Variance within",c(0,0.25), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[6]+1,l[7]), 0.9)
#next page
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(1, "Variance within",c(0,0.25), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

## Variance between environemnts
l <- 50*0:9
pdf("forest_between.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 2, xlab = "Variance between", xlim = c(0,0.25),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(2, "Variance between",c(0,0.25), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(2, "Variance between",c(0,0.25), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(2, "Variance between",c(0,0.25), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

#sum of variance components
l <- 50*0:9
pdf("forest_sum.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 3, xlab = "Responsiveness", xlim = c(0,0.25),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(3, "Responsiveness",c(0,0.25), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(3, "Responsiveness",c(0,0.25), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(3, "Responsiveness",c(0,0.25), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

#ratio of variance components
l <- 50*0:9
pdf("forest_ratio.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 4, xlab = "Percentage Plasticity", xlim = c(0,1),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(4, "Percentage Plasticity",c(0,1), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(4, "Percentage Plasticity",c(0,1), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(4, "Percentage Plasticity",c(0,1), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

#CDL plots
#need to plot 433/50 = 9 cols
l <- 50*0:9
pdf("forest_cdl.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 5, xlab = "CDL", xlim = c(8,24),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(5, "CDL", c(8,24), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(5, "CDL", c(8,24), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[9]+1,433), 0.9)
dev.off()
```


## comparison. are the results stored in res_ reliable enough?
```{r}
estimates <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
for (dataset in 1:10){
  currpop <- unique(data$popid)[dataset]
  res<-read.table(file = paste("res_", currpop, ".txt", sep = "" ))
  estimates[dataset,]<-quantile(res[,3], c(0.025,0.5,0.975))
}


est2<-data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
for (dataset in 1:10){
  currpop <- unique(data$popid)[dataset]
  nam <-paste("model_", currpop, sep="")
  load(file = paste(nam, ".rds", sep=""))
  est2[dataset,] <- summary(get(nam))$quantile[4,c(1,3,5)]
}
(est2-estimates)/est2 #diff is negligible
```



## get estimates and ci
```{r}
num<-number
estimates_w <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_b <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_s <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_r <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_e <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))

for (dataset in 1:num){
  currpop <- unique(data$popid)[dataset]
  res<-read.table(file = paste("res_", currpop, ".txt", sep = "" ))
  estimates_w[dataset,]<-quantile(res[,1], c(0.025,0.5,0.975))
  estimates_b[dataset,]<-quantile(res[,2], c(0.025,0.5,0.975))
  estimates_s[dataset,]<-quantile(res[,3], c(0.025,0.5,0.975))
  estimates_r[dataset,]<-quantile(res[,4], c(0.025,0.5,0.975))
  estimates_e[dataset,]<-quantile(res[,5], c(0.025,0.5,0.975))

}

estimates_w$popid <- unique(data$popid)
estimates_w$order<-sapply(estimates_w$popid,function(x){unique(data$order[data$popid == x])})
estimates_b$popid <- unique(data$popid)
estimates_b$order<-sapply(estimates_b$popid,function(x){unique(data$order[data$popid == x])})
estimates_s$popid <- unique(data$popid)
estimates_s$order<-sapply(estimates_s$popid,function(x){unique(data$order[data$popid == x])})
estimates_r$popid <- unique(data$popid)
estimates_r$order<-sapply(estimates_r$popid,function(x){unique(data$order[data$popid == x])})
estimates_e$popid <- unique(data$popid)
estimates_e$order<-sapply(estimates_e$popid,function(x){unique(data$order[data$popid == x])})

```

#forest plot, simplified
```{r}

ordered_e<-estimates_e[order(estimates_e$order),]
n<-table(ordered_e$order)
png("forest_e_simple.png",height = 480*2)
plot(NA, xlim = c(7.8,24), ylim = c(1,433),xlab = "CDL", ylab="", yaxt ="n", bty="n",xaxt="n")
axis(1, at= seq(8,24,2))
segments (x0 = ordered_e$lower, x1 = ordered_e$upper, y0=1:433,col="lightgrey")
points(x= ordered_e$med, y= 1:433, pch=22, cex=0.4 ,bg=ordered_e$order,col=ordered_e$order)
text(x=22,y = n[1]/2, labels = names(n[1]),col=1)
text(x=22,y = cumsum(n)[1:8]+n[2:9]/2, labels = names(n[2:9]),col=1)
abline(v=median(ordered_e$med),lty=2)
dev.off()

ordered_w<-estimates_w[order(estimates_w$order),]
png("forest_w_simple.png",height = 480*2)
plot(NA, xlim = c(0,0.25), ylim = c(1,433),xlab = "variance within", ylab="", yaxt ="n", bty="n",xaxt="n")
axis(1, at= seq(0,0.25,length.out = 5))
segments (x0 = ordered_w$lower, x1 = ordered_w$upper, y0=1:433,col="lightgrey")
points(x= ordered_w$med, y= 1:433, pch=22, cex=0.4 ,bg=ordered_w$order,col=ordered_w$order)
text(x=0.19,y = n[1]/2, labels = names(n[1]),col=1)
text(x=0.19,y = cumsum(n)[1:8]+n[2:9]/2, labels = names(n[2:9]),col=1)
abline(v=median(ordered_w$med),lty=2)
dev.off()



ordered_b<-estimates_b[order(estimates_b$order),]
png("forest_b_simple.png",height = 480*2)
plot(NA, xlim = c(0,0.25), ylim = c(1,433),xlab = "variance between", ylab="", yaxt ="n", bty="n",xaxt="n")
axis(1, at= seq(0,0.25,length.out = 5))
segments (x0 = ordered_b$lower, x1 = ordered_b$upper, y0=1:433,col="lightgrey")
points(x= ordered_b$med, y= 1:433, pch=22, cex=0.4 ,bg=ordered_b$order,col=ordered_b$order)
text(x=0.05,y = n[1]/2, labels = names(n[1]),col=1)
text(x=0.05,y = cumsum(n)[1:8]+n[2:9]/2, labels = names(n[2:9]),col=1)
abline(v=median(ordered_b$med),lty=2)
dev.off()

png("within_between.png")
plot(estimates_w$med~estimates_b$med,pch=22,bg=1, xlab = "variance between environments", ylab = "variance within environments",cex=0.5)
dev.off()
```





```{r funnel_plots}
a <- rep(NA, number)
  for (dataset in 1:number){
  currpop <- unique(data$popid)[dataset]
  a[dataset] <- nrow(data[data$popid==currpop,])
  }
png("funnel_plots.png",height = 480*1.3, pointsize = 12)
par(mfrow = c(3,1), mar = c(1,4,2,1)+0.1)
r <- estimates_e$upper-estimates_e$lower
plot(r~jitter(a),pch=21, cex=1, bg = 1, col=1, xlab = "", ylab = "",bty="n", xaxt="n", yaxt="n", cex.lab = 1.5, cex.axis=1.5) 
axis(1, at = c(-3,5,10,15,20,25),cex.lab = 1.5, cex.axis=1.5)
axis(2, at = c(-4,0,5,10,15),cex.lab = 1.5, cex.axis=1.5)
text(4,max(r)*0.9,"A",cex=2)
r <- estimates_s$upper-estimates_s$lower
par(mar = c(1,4,1,1)+0.1)
plot(r~jitter(a),pch=21, cex=1, bg = 1, col=1, xlab = "", ylab = "Credible interval range",bty="n",xaxt="n", yaxt="n",cex.lab = 1.5, cex.axis=1.5) 
axis(1, at = c(-3,5,10,15,20,25),cex.lab = 1.5, cex.axis=1.5)
axis(2, at = c(-8,0,0.05,0.1,0.15),cex.lab = 1.5, cex.axis=1.5)
text(4,max(r)*0.9,"B",cex=2)
r <- estimates_r$upper-estimates_r$lower
par(mar=c(4,4,1,1)+0.1)
plot(r~jitter(a),pch=21, cex=1, bg = 1, col=1, xlab = "Number day length treatments", ylab = "",bty="n",xaxt="n", yaxt="n" ,cex.lab = 1.5, cex.axis=1.5)
axis(1, at = c(-3,5,10,15,20,25),cex.lab = 1.5, cex.axis=1.5)
axis(2, at = c(-8,0,0.2,0.4,0.6),cex.lab = 1.5, cex.axis=1.5)
text(4,max(r)*0.9,"C",cex=2)
dev.off()

py <- rep(NA, number)
  for (dataset in 1:number){
  currpop <- unique(data$popid)[dataset]
  py[dataset] <- unique(data[data$popid==currpop,3])
  }

jpy <-jitter(py)
png("publication_year.png", pointsize =12)
par(mfrow=c(3,1), mar = c(2,4,1,1)+0.1)
plot(estimates_e$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1, xlab = "", ylab = "Mean timing", bty= "n", cex.lab = 1.5, cex.axis = 1.5, xaxt = "n", yaxt = "n")
axis(1, at = c(1970,1980,1990,2000,2010,2020),cex.lab = 1.5, cex.axis = 1.5)
axis(2, at = c(0,10,16,22),cex.lab = 1.5, cex.axis = 1.5)
segments(x0 = jpy, y0 =estimates_e$lower, y1 = estimates_e$upper,col="darkgrey")
points(estimates_e$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1)

par(mar = c(2,4,1,1)+0.1)
plot(estimates_s$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1, xlab = "", ylab = "Responsiveness", bty= "n", cex.lab = 1.5, cex.axis = 1.5, xaxt = "n", yaxt = "n")
axis(1, at = c(1970,1980,1990,2000,2010,2020),cex.lab = 1.5, cex.axis = 1.5)
axis(2, at = c(-1,0,0.125,0.25), labels = c(NA,0,0.125,0.25),cex.lab = 1.5, cex.axis = 1.5)
segments(x0 = jpy, y0 =estimates_s$lower, y1 = estimates_s$upper,col="darkgrey")
points(estimates_s$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1)

par(mar= c(4,4,1,1)+0.1)
plot(estimates_r$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1, xlab = "Publication year", ylab = "Variance composition", bty= "n", cex.lab = 1.5, cex.axis = 1.5, xaxt = "n", yaxt = "n")
axis(1, at = c(1970,1980,1990,2000,2010,2020),cex.lab = 1.5, cex.axis = 1.5)
axis(2, at = c(-1,0,0.5,1),labels = c(NA, 0, 0.5,1 ),cex.lab = 1.5, cex.axis = 1.5)
segments(x0 = jpy, y0 =estimates_r$lower, y1 = estimates_r$upper,col="darkgrey")
points(estimates_r$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1)

dev.off()

```


## lankinen 
One publication is misssing so far, that is lankinen 2013. They gave b and CDL estimates directly so there was no need to extract data and do the MCMC. They give only a SD though, needs to be converted into credible intervals

```{r lankinen}
cdlvec<-seq(19.22-0.46*2,19.22+0.46*2,length.out=1000)
bvec <- seq(35.59-11.61*2,35.59+11.61,length.out=1000)
x<-seq(19.22-6,19.22+6,length.out=1000)

res<-data.frame(w = rep(NA,100*100), b = rep(NA,100*100))
for ( i in 1:100){
  for(j in 1:100){

    res[i*100 +j,]<-    calc_var(c(bvec[i],0,1,cdlvec[j]))
  }
}
quantile(res[,1],c(0.025,0.975),na.rm=T)

lank <- data.frame(
  row = c("b:lankinen_13-Pelkosenniemi-Drosophila-montana", "b:lankinen_13-Oulanka-Drosophila-montana", "b:lankinen_13-Kemi-Drosophila-montana", "b:lankinen_13-Pudasjarvi-Drosophila-montana", "b:lankinen_13-Paltamo-Drosophila-montana", "b:lankinen_13-ivaskila-Drosophila-montana","b:lankinen_13-lahti-Drosophila-montana"),
  set=rep("byhand",7),
  popid=c("b:lankinen_13-Pelkosenniemi-Drosophila-montana", "b:lankinen_13-Oulanka-Drosophila-montana", "b:lankinen_13-Kemi-Drosophila-montana", "b:lankinen_13-Pudasjarvi-Drosophila-montana", "b:lankinen_13-Paltamo-Drosophila-montana", "b:lankinen_13-ivaskila-Drosophila-montana","b:lankinen_13-lahti-Drosophila-montana"),
  ID = rep("lankinen_13",7), PY = rep(2013,7), region = rep ("Europe",7), pops_left= rep(7,7), genus = rep("Drosophila",7), spec = rep("montana",7), order = rep("Diptera",7), 
  pop = c("Pelkosenniemi", "Oulanka", "Kemi", "Pudasjarvi", "Paltamo", "ivaskila","lahti"), 
  degN =c(67.1, 66.4, 65.7, 65.4, 64.3, 62.2, 61.1),
  degE = c(27.3, 29.2, 24.7, 27.0, 27.9, 25.7, 25.7),
  nmethod = rep(NA,7), perc = rep(NA,7), n2 = rep(NA,7), dl2= rep(NA,7), number= rep(NA,7),nslop=rep(NA,7),inc2=rep(NA,7),
  b=c(35.59, 26.40, 39.38, 27.91, 43.03, 36.72, 45.38),
  bse = rep(NA,7),# c(11.61, 7.04, 19.64, 7.25, 13.84, 14.22, 12.81),
  c = rep(0,7),cse = rep(NA,7),d=rep(1,7),dse = rep(NA,7),
  e = c(19.22, 19.38, 18.63, 19.46, 18.78, 18.32, 17.70),
  ese = rep(NA,7), #c(0.46,0.72,1.13, 1.00, 0.42, 0.75, 0.34)),
  col = rep( "#FFBF00",7),
  npoints = rep(4,7))

results<-rbind(results,lank)
                   
#write.table(results,"02studies/02output/slopes_clean.txt",sep = "\t",row.names=F)
```


## combine with degN etc
```{r}
alone <- data[1,]
for (dataset in 1: number){
  currpop <- unique(data$popid)[dataset]
  alone[dataset,]<-data[data$popid==currpop,][1,]
}
alone<-alone[,-c(10,14:18)]

names(estimates_w)<-c("lower_w","med_w","upper_w","popid","order")
names(estimates_b)<-c("lower_b","med_b","upper_b","popid","order")
names(estimates_s)<-c("lower_s","med_s","upper_s","popid","order")
names(estimates_r)<-c("lower_r","med_r","upper_r","popid","order")
names(estimates_e)<-c("lower_e","med_e","upper_e","popid","order")


together <- merge(estimates_e,alone)
together <- merge(estimates_w,together, by = "popid")
together <- merge(estimates_b,together, by = "popid")
together <- merge(estimates_s,together, by = "popid")
together <- merge(estimates_r,together, by = "popid")

plot(together$med_e~together$degN)
segments(x0=together$degN,x1 = together$degN, y0 = together$lower_e, y1 = together$upper_e)
```



```{r save_data}
write.table(estimates_e, "estimates_e.txt",append=T,sep="\t",col.names=FALSE)
write.table(estimates_w, "estimates_w.txt",append=T,sep="\t",col.names=FALSE)
write.table(estimates_b, "estimates_b.txt",append=T,sep="\t",col.names=FALSE)
write.table(together, "mcmcresults.txt",append=F,sep="\t")

```
