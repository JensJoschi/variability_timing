---
title: "read slopes"
author: "Jens Joschinski"
date: "March 15, 2018"
output: 
  md_document:
  variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
#library(plyr)
library(tidyr)
#library(textreadr)
#library(drc)
#library(sandwich)
#library(lmtest)
#library(geosphere)
#library(metafor)
library(rjags)
```


# General description  
## Project aim  
To understand the evolvability of phenological strategies such as plasticity and bet-hedging, we correlate variance components and means of reaction norms with climate parameters. 

## Script overview  
We searched the Web of Science database for photoperiodic response curves of arthropods and selected 57 studies with individual reaction norms (dose-response curves) for 426 populations. The data was extracted with webplotdigitizer, and can be found in "lit_search/search_2018_11.xlsx".
This script does an MCMC to get estimates fo slopes, midpoints and upper and lower limit. It then calculates the variance within and between datapoints based on the same MCMC approach.


## load data  
One study (7 populations) reported the slope and midpoint from drc analyiss directly. The script concentrates on the remaining populations

```{r load_data}
data<-read.table("lit_extract/variance_comp.csv", header=T,sep=";")
#changes to .xlsx: Diatraea had gen + sp in genus column; Laodelphax has added space in hou
length(unique(data$ID)) #57 studies that can be used for slope calculation
length(unique(data$spec)) #45 species
length(unique(data$genus)) #32 genera
data<-unite(data,"popid",c("ID","pop","genus","spec"),sep=".",remove=F)
(number <- length(unique(data$popid))) #433 populations (not 440 because lankinen 2013 is not in here)


#summary of #pops per region and level of detail for sample sizes

t<-data.frame(unique(data$popid))
t$reg<-NA
t$nMethod<-NA
#each unique pop has multiple rows in dataset (1 per day length)
#get this subset, take region and nMethod from first line (or use unique)
for ( i in 1:nrow(t)){ 
   t$reg[i]<-unique(data[data$popid==t[i,1],5])
   t$nMethod[i]<-unique(data[data$popid==t[i,1],9])
}
table(t$reg) #unfortunately, the information was converted to values
levels(data$region)
#Asia 16
#Europe (including caucasus): 117
#Japan 242
#US 58
#japan has 55.6% of the populations, 46.8 % of the data


table(t$nMethod)
levels(data$nmethod)

#accurate: 96
#global average:288
#pop level: 16
#NA 33


#check whether some studies have <3 pops
t<-data.frame(unique(data$ID))
t$pop<-NA
for ( i in 1:nrow(t)){ 
  t$pop[i]<-length(unique(data[data$ID==t[i,1],1]))
}
#table t$pop

data$n2[is.na(data$n2)]<-100


data$perc[data$perc<0]<-0 #sometimes percentages are estimated as e.g. -0.3% or 101%. these are rounded here to prevent errors
data$perc[data$perc>100]<-100
data$n2<-round(data$n2)
data$number<-(data$perc/100) * data$n2
data$number<-floor(data$number)
number<-length(unique(data$popid))#433
data$n<-data$number/data$n2

#check whether some studies have <4 dls
#sort (table(data$popid))
#get a vector of form "ID-population" for later labelling
nams<-unite(data,"nams",c("ID","pop"), sep = "-", remove=T)$nams 

```



### MCMC

Markov Chain Monte Carlo simulation. Data is saved as .rds objects, so this chunk does not need to be repeated
```{r jags}
#the model in BUGS code for jags
#instead of saving as separate file this is put into a string, and later opened with textConnection(model_string)

model.string <- 
"model {
  
  #likelihood function
	for (i in 1:N){
		y[i] ~ dbin(success[i],trials[i])     #this incorporates sample size per point (number of individuals per day length)
		success[i] <- (d-c)/(1+exp(b*(x[i]-e)))+c #4-parameter logit curve
	}

	#priors
	b ~dunif(-100,100)       
	c ~dunif(0,1)
	d ~dunif(c,1)             #constrained to be bigger than c
	e ~dunif(min(x),max(x))   #constrained within range(day lengths)

}"


iter<-10000
chains <-4

for (dataset  in (1:number)) {
  currpop <- unique(data$popid)[dataset]
  currdat<-data[data$popid==currpop,]
  
  
  model <- jags.model(textConnection(model.string), 
                    data = list(y=currdat$number, x= currdat$dl2, N = nrow(currdat),trials = currdat$n2), 
                    n.chains=chains, n.adapt=1000)

  out <- coda.samples(model,   c( 'b', 'c', 'd', 'e'), iter)
  outname <- paste("model_", currpop, sep="")
  assign(outname, out)
  save(list = outname ,file = paste(outname, ".rds", sep = ""))
  rm(list= outname)
}

```


## calculation of variance components  
We follow the trace of the MCMC (which was saved in previous step), and calculate the variance components at each iteration. The frequency distribution of variance estimates is used to get estimate  + credible interval.

```{r calc_variance}

logcurve<-function(x,b,c,d,e){(d-c)/(1+exp(b*(x-e)))+c} #4-paramter dose-response curve, eq.1

calc_var <- function(row){
  b<-row[1]
  c<-row[2]
  d<-row[3]
  e<-row[4]
  
  x<-seq(e-12,e+12, length.out =1000)
  y<-(d-c)/(1+exp(b*(x-e)))+c #produces logitcurve along a segment of mean +-12 h
  w <- sum(y*(1-y))/1000 #variance within, eq.2
  b <- sd(y)^2  #variance among, eq.3
  c(w, b,  b+w, b/(b+w)) #returns variance within, variance among, their sum (eq.5), and the ratio (eq.4)
}


for (dataset in 1:number){
  currpop <- unique(data$popid)[dataset]
  outname <- paste("model_", currpop, sep="")
  load(paste(outname, ".rds", sep=""))
  sav <- data.frame(rep(NA, iter))
  for (i in (1:chains)){
    dat <- get(outname)[[i]]
    temp <- apply(dat, 1, calc_var)
    temp<-t(temp)

    sav <- cbind(sav, temp, dat[,4]) #order: within, between, sum, ratio, e, within ...[4 times]
  }
  sav<-sav[,-1]
  rm(list=outname)
  write.table(sav, file = paste("res_", currpop, ".txt", sep = "" ), row.names=F, col.names=F)
}

```


## forest plots  
The following chunk creates forest plots of all estimates. It shows not only estimate + credible interval, but also frequency distribution, independently for the four chains. There are 5 different forest plots to make: variance among, within, their sum, ratio, and the mean timing. Each forest plot has 433 entries, which is too long for a single figure. Thus, there will be 3 columns of 50 points per page, which makes 3 pages for each of the 5 forest plots. 

```{r}
plot_forest <- function (column, xlab, xlim, ylim, num = c(1,50), scale ){ #this function will be used for all 5 forest plots
  #column = column of the dataset, 1 = variance within, 2 = between, 3 = sum, 4 = ratio, 5 = mean
  #num = rows of the dataset that should be plotted. 
  #scale = scaling factor that shrinks the historgrams so they do not touch. should be smaller than 1
r <- num[2] - num[1]
plot(NA, xlim = xlim, xlab = xlab, ylim = ylim, ylab = "", bty="n", yaxt="n" )
abline(h=1:r, col="lightgrey")

h<--1 #tracks line of the forest plot
for (dataset in (num[1]:num[2])){
  h<-h+1
  currpop <- unique(data$popid)[dataset]
  res<-read.table(file = paste("res_", currpop, ".txt", sep = "" ))

   for ( i in 1:chains){
    dens<-density(res[,5*(i-1)+column])
    lines(x=dens$x,y = h+ scale * dens$y/max(dens$y),col=5-i)
   }
  abline(h=h,col="lightgrey")
  segments (x0 = quantile(res[,column], 0.025), x1= quantile(res[,column], 0.975), y0 = h,y1 = h,col=4) #draw 95% credible interval. this is only based on first chain
  points(x =median (res[,column]), y = h, cex=0.5, pch=22, bg=1)
  text(x=xlim[2], y = h+0.5, pos = 2, labels = unique(data$ID[data$popid == currpop]), cex = 0.8, col ="darkgrey") #author
  text(x=xlim[1], y = h+0.5, pos = 4, labels = unique(data$pop[data$popid==currpop]), cex = 0.8, col = "darkgrey") #pop
}

}



## variance within environments
l <- 50*0:9
pdf("forest_within.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 1, xlab = "Variance within", xlim = c(0,0.25),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[3]+1,l[4]), 0.9)
#next page
plot_forest(1, "Variance within",c(0,0.25), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(1, "Variance within",c(0,0.25), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[6]+1,l[7]), 0.9)
#next page
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(1, "Variance within",c(0,0.25), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(1, "Variance within", c(0,0.25), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

## Variance between environemnts
l <- 50*0:9
pdf("forest_between.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 2, xlab = "Variance between", xlim = c(0,0.25),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(2, "Variance between",c(0,0.25), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(2, "Variance between",c(0,0.25), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(2, "Variance between",c(0,0.25), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(2, "Variance between", c(0,0.25), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

#sum of variance components
l <- 50*0:9
pdf("forest_sum.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 3, xlab = "Responsiveness", xlim = c(0,0.25),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(3, "Responsiveness",c(0,0.25), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(3, "Responsiveness",c(0,0.25), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(3, "Responsiveness",c(0,0.25), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(3, "Responsiveness", c(0,0.25), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

#ratio of variance components
l <- 50*0:9
pdf("forest_ratio.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 4, xlab = "Percentage Plasticity", xlim = c(0,1),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(4, "Percentage Plasticity",c(0,1), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(4, "Percentage Plasticity",c(0,1), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(4, "Percentage Plasticity",c(0,1), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(4, "Percentage Plasticity", c(0,1), c(1,52), c(l[9]+1,433), 0.9)
dev.off()

#CDL plots
#need to plot 433/50 = 9 cols
l <- 50*0:9
pdf("forest_cdl.pdf",width=7, height = 7*2, pointsize=12)
par(mfrow = c(1,3),mar = c(4,2,1,0))
plot_forest(column = 5, xlab = "CDL", xlim = c(8,24),ylim = c(1,52), num = c(l[1]+1,l[2]),scale=  0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[2]+1,l[3]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[3]+1,l[4]), 0.9)

plot_forest(5, "CDL", c(8,24), c(1,52), c(l[4]+1,l[5]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[5]+1,l[6]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[6]+1,l[7]), 0.9)

plot_forest(5, "CDL", c(8,24), c(1,52), c(l[7]+1,l[8]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[8]+1,l[9]), 0.9)
plot_forest(5, "CDL", c(8,24), c(1,52), c(l[9]+1,433), 0.9)
dev.off()
```


## comparison. are the results stored in res_ reliable enough?  
```{r}
estimates <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
for (dataset in 1:10){
  currpop <- unique(data$popid)[dataset]
  res<-read.table(file = paste("res_", currpop, ".txt", sep = "" ))
  estimates[dataset,]<-quantile(res[,3], c(0.025,0.5,0.975))
}


est2<-data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
for (dataset in 1:10){
  currpop <- unique(data$popid)[dataset]
  nam <-paste("model_", currpop, sep="")
  load(file = paste(nam, ".rds", sep=""))
  est2[dataset,] <- summary(get(nam))$quantile[4,c(1,3,5)]
}
(est2-estimates)/est2 #diff is negligible
```



## get estimates and ci
This chunk saves the estimats (within, between, sum, ration, mean) in one common table
```{r}
num<-number
estimates_w <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_b <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_s <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_r <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))
estimates_e <- data.frame(lower = rep(NA,num), med = rep(NA,num), upper = rep(NA,num))

for (dataset in 1:num){
  currpop <- unique(data$popid)[dataset]
  res<-read.table(file = paste("res_", currpop, ".txt", sep = "" ))
  estimates_w[dataset,]<-quantile(res[,1], c(0.025,0.5,0.975))
  estimates_b[dataset,]<-quantile(res[,2], c(0.025,0.5,0.975))
  estimates_s[dataset,]<-quantile(res[,3], c(0.025,0.5,0.975))
  estimates_r[dataset,]<-quantile(res[,4], c(0.025,0.5,0.975))
  estimates_e[dataset,]<-quantile(res[,5], c(0.025,0.5,0.975))

}

estimates_w$popid <- unique(data$popid)
estimates_w$order<-sapply(estimates_w$popid,function(x){unique(data$order[data$popid == x])})
estimates_b$popid <- unique(data$popid)
estimates_b$order<-sapply(estimates_b$popid,function(x){unique(data$order[data$popid == x])})
estimates_s$popid <- unique(data$popid)
estimates_s$order<-sapply(estimates_s$popid,function(x){unique(data$order[data$popid == x])})
estimates_r$popid <- unique(data$popid)
estimates_r$order<-sapply(estimates_r$popid,function(x){unique(data$order[data$popid == x])})
estimates_e$popid <- unique(data$popid)
estimates_e$order<-sapply(estimates_e$popid,function(x){unique(data$order[data$popid == x])})

```

#forest plot, simplified
```{r}

ordered_e<-estimates_e[order(estimates_e$order),]
n<-table(ordered_e$order)
png("forest_e_simple.png",height = 480*2)
plot(NA, xlim = c(7.8,24), ylim = c(1,433),xlab = "CDL", ylab="", yaxt ="n", bty="n",xaxt="n")
axis(1, at= seq(8,24,2))
segments (x0 = ordered_e$lower, x1 = ordered_e$upper, y0=1:433,col="lightgrey")
points(x= ordered_e$med, y= 1:433, pch=22, cex=0.4 ,bg=ordered_e$order,col=ordered_e$order)
text(x=22,y = n[1]/2, labels = names(n[1]),col=1)
text(x=22,y = cumsum(n)[1:8]+n[2:9]/2, labels = names(n[2:9]),col=1)
abline(v=median(ordered_e$med),lty=2)
dev.off()

ordered_w<-estimates_w[order(estimates_w$order),]
png("forest_w_simple.png",height = 480*2)
plot(NA, xlim = c(0,0.25), ylim = c(1,433),xlab = "variance within", ylab="", yaxt ="n", bty="n",xaxt="n")
axis(1, at= seq(0,0.25,length.out = 5))
segments (x0 = ordered_w$lower, x1 = ordered_w$upper, y0=1:433,col="lightgrey")
points(x= ordered_w$med, y= 1:433, pch=22, cex=0.4 ,bg=ordered_w$order,col=ordered_w$order)
text(x=0.19,y = n[1]/2, labels = names(n[1]),col=1)
text(x=0.19,y = cumsum(n)[1:8]+n[2:9]/2, labels = names(n[2:9]),col=1)
abline(v=median(ordered_w$med),lty=2)
dev.off()



ordered_b<-estimates_b[order(estimates_b$order),]
png("forest_b_simple.png",height = 480*2)
plot(NA, xlim = c(0,0.25), ylim = c(1,433),xlab = "variance between", ylab="", yaxt ="n", bty="n",xaxt="n")
axis(1, at= seq(0,0.25,length.out = 5))
segments (x0 = ordered_b$lower, x1 = ordered_b$upper, y0=1:433,col="lightgrey")
points(x= ordered_b$med, y= 1:433, pch=22, cex=0.4 ,bg=ordered_b$order,col=ordered_b$order)
text(x=0.05,y = n[1]/2, labels = names(n[1]),col=1)
text(x=0.05,y = cumsum(n)[1:8]+n[2:9]/2, labels = names(n[2:9]),col=1)
abline(v=median(ordered_b$med),lty=2)
dev.off()

png("within_between.png")
plot(estimates_w$med~estimates_b$med,pch=22,bg=1, xlab = "variance between environments", ylab = "variance within environments",cex=0.5)
dev.off()
```





```{r funnel_plots}
a <- rep(NA, number)
  for (dataset in 1:number){
  currpop <- unique(data$popid)[dataset]
  a[dataset] <- nrow(data[data$popid==currpop,])
  }
png("funnel_plots.png",height = 480*1.3, pointsize = 12)
par(mfrow = c(3,1), mar = c(1,4,2,1)+0.1)
r <- estimates_e$upper-estimates_e$lower
plot(r~jitter(a),pch=21, cex=1, bg = 1, col=1, xlab = "", ylab = "",bty="n", xaxt="n", yaxt="n", cex.lab = 1.5, cex.axis=1.5) 
axis(1, at = c(-3,5,10,15,20,25),cex.lab = 1.5, cex.axis=1.5)
axis(2, at = c(-4,0,5,10,15),cex.lab = 1.5, cex.axis=1.5)
text(4,max(r)*0.9,"A",cex=2)
r <- estimates_s$upper-estimates_s$lower
par(mar = c(1,4,1,1)+0.1)
plot(r~jitter(a),pch=21, cex=1, bg = 1, col=1, xlab = "", ylab = "Credible interval range",bty="n",xaxt="n", yaxt="n",cex.lab = 1.5, cex.axis=1.5) 
axis(1, at = c(-3,5,10,15,20,25),cex.lab = 1.5, cex.axis=1.5)
axis(2, at = c(-8,0,0.05,0.1,0.15),cex.lab = 1.5, cex.axis=1.5)
text(4,max(r)*0.9,"B",cex=2)
r <- estimates_r$upper-estimates_r$lower
par(mar=c(4,4,1,1)+0.1)
plot(r~jitter(a),pch=21, cex=1, bg = 1, col=1, xlab = "Number day length treatments", ylab = "",bty="n",xaxt="n", yaxt="n" ,cex.lab = 1.5, cex.axis=1.5)
axis(1, at = c(-3,5,10,15,20,25),cex.lab = 1.5, cex.axis=1.5)
axis(2, at = c(-8,0,0.2,0.4,0.6),cex.lab = 1.5, cex.axis=1.5)
text(4,max(r)*0.9,"C",cex=2)
dev.off()

py <- rep(NA, number)
  for (dataset in 1:number){
  currpop <- unique(data$popid)[dataset]
  py[dataset] <- unique(data[data$popid==currpop,3])
  }

jpy <-jitter(py)
png("publication_year.png", pointsize =12)
par(mfrow=c(3,1), mar = c(2,4,1,1)+0.1)
plot(estimates_e$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1, xlab = "", ylab = "Mean timing", bty= "n", cex.lab = 1.5, cex.axis = 1.5, xaxt = "n", yaxt = "n")
axis(1, at = c(1970,1980,1990,2000,2010,2020),cex.lab = 1.5, cex.axis = 1.5)
axis(2, at = c(0,10,16,22),cex.lab = 1.5, cex.axis = 1.5)
segments(x0 = jpy, y0 =estimates_e$lower, y1 = estimates_e$upper,col="darkgrey")
points(estimates_e$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1)

par(mar = c(2,4,1,1)+0.1)
plot(estimates_s$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1, xlab = "", ylab = "Responsiveness", bty= "n", cex.lab = 1.5, cex.axis = 1.5, xaxt = "n", yaxt = "n")
axis(1, at = c(1970,1980,1990,2000,2010,2020),cex.lab = 1.5, cex.axis = 1.5)
axis(2, at = c(-1,0,0.125,0.25), labels = c(NA,0,0.125,0.25),cex.lab = 1.5, cex.axis = 1.5)
segments(x0 = jpy, y0 =estimates_s$lower, y1 = estimates_s$upper,col="darkgrey")
points(estimates_s$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1)

par(mar= c(4,4,1,1)+0.1)
plot(estimates_r$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1, xlab = "Publication year", ylab = "Variance composition", bty= "n", cex.lab = 1.5, cex.axis = 1.5, xaxt = "n", yaxt = "n")
axis(1, at = c(1970,1980,1990,2000,2010,2020),cex.lab = 1.5, cex.axis = 1.5)
axis(2, at = c(-1,0,0.5,1),labels = c(NA, 0, 0.5,1 ),cex.lab = 1.5, cex.axis = 1.5)
segments(x0 = jpy, y0 =estimates_r$lower, y1 = estimates_r$upper,col="darkgrey")
points(estimates_r$med ~ jpy, pch= 21, cex= 1, bg= 1, col= 1)

dev.off()

```


## lankinen 
One publication is misssing so far, that is lankinen 2013. They gave b and CDL estimates directly so there was no need to extract data and do the MCMC. They give only a SD though, needs to be converted into credible intervals

```{r lankinen}
cdlvec<-seq(19.22-0.46*2,19.22+0.46*2,length.out=1000)
bvec <- seq(35.59-11.61*2,35.59+11.61,length.out=1000)
x<-seq(19.22-6,19.22+6,length.out=1000)

res<-data.frame(w = rep(NA,100*100), b = rep(NA,100*100))
for ( i in 1:100){
  for(j in 1:100){

    res[i*100 +j,]<-    calc_var(c(bvec[i],0,1,cdlvec[j]))
  }
}
quantile(res[,1],c(0.025,0.975),na.rm=T)

lank <- data.frame(
  row = c("b:lankinen_13-Pelkosenniemi-Drosophila-montana", "b:lankinen_13-Oulanka-Drosophila-montana", "b:lankinen_13-Kemi-Drosophila-montana", "b:lankinen_13-Pudasjarvi-Drosophila-montana", "b:lankinen_13-Paltamo-Drosophila-montana", "b:lankinen_13-ivaskila-Drosophila-montana","b:lankinen_13-lahti-Drosophila-montana"),
  set=rep("byhand",7),
  popid=c("b:lankinen_13-Pelkosenniemi-Drosophila-montana", "b:lankinen_13-Oulanka-Drosophila-montana", "b:lankinen_13-Kemi-Drosophila-montana", "b:lankinen_13-Pudasjarvi-Drosophila-montana", "b:lankinen_13-Paltamo-Drosophila-montana", "b:lankinen_13-ivaskila-Drosophila-montana","b:lankinen_13-lahti-Drosophila-montana"),
  ID = rep("lankinen_13",7), PY = rep(2013,7), region = rep ("Europe",7), pops_left= rep(7,7), genus = rep("Drosophila",7), spec = rep("montana",7), order = rep("Diptera",7), 
  pop = c("Pelkosenniemi", "Oulanka", "Kemi", "Pudasjarvi", "Paltamo", "ivaskila","lahti"), 
  degN =c(67.1, 66.4, 65.7, 65.4, 64.3, 62.2, 61.1),
  degE = c(27.3, 29.2, 24.7, 27.0, 27.9, 25.7, 25.7),
  nmethod = rep(NA,7), perc = rep(NA,7), n2 = rep(NA,7), dl2= rep(NA,7), number= rep(NA,7),nslop=rep(NA,7),inc2=rep(NA,7),
  b=c(35.59, 26.40, 39.38, 27.91, 43.03, 36.72, 45.38),
  bse = rep(NA,7),# c(11.61, 7.04, 19.64, 7.25, 13.84, 14.22, 12.81),
  c = rep(0,7),cse = rep(NA,7),d=rep(1,7),dse = rep(NA,7),
  e = c(19.22, 19.38, 18.63, 19.46, 18.78, 18.32, 17.70),
  ese = rep(NA,7), #c(0.46,0.72,1.13, 1.00, 0.42, 0.75, 0.34)),
  col = rep( "#FFBF00",7),
  npoints = rep(4,7))

results<-rbind(results,lank)
                   
#write.table(results,"02studies/02output/slopes_clean.txt",sep = "\t",row.names=F)
```


## combine with degN etc
```{r}
alone <- data[1,]
for (dataset in 1: number){
  currpop <- unique(data$popid)[dataset]
  alone[dataset,]<-data[data$popid==currpop,][1,]
}
alone<-alone[,-c(10,14:18)]

names(estimates_w)<-c("lower_w","med_w","upper_w","popid","order")
names(estimates_b)<-c("lower_b","med_b","upper_b","popid","order")
names(estimates_s)<-c("lower_s","med_s","upper_s","popid","order")
names(estimates_r)<-c("lower_r","med_r","upper_r","popid","order")
names(estimates_e)<-c("lower_e","med_e","upper_e","popid","order")


together <- merge(estimates_e,alone)
together <- merge(estimates_w,together, by = "popid")
together <- merge(estimates_b,together, by = "popid")
together <- merge(estimates_s,together, by = "popid")
together <- merge(estimates_r,together, by = "popid")

plot(together$med_e~together$degN)
segments(x0=together$degN,x1 = together$degN, y0 = together$lower_e, y1 = together$upper_e)
```



```{r save_data}
write.table(estimates_e, "estimates_e.txt",append=T,sep="\t",col.names=FALSE)
write.table(estimates_w, "estimates_w.txt",append=T,sep="\t",col.names=FALSE)
write.table(estimates_b, "estimates_b.txt",append=T,sep="\t",col.names=FALSE)
write.table(together, "mcmcresults.txt",append=F,sep="\t")

```
